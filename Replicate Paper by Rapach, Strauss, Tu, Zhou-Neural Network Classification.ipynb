{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate [Dynamic Return Dependencies Across Industries: A Machine Learning Approach](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3120110&download=yes) by David Rapach, Jack Strauss, Jun Tu and Guofu Zhou.\n",
    "\n",
    "1) Use Keras NN classification instead of linear regression\n",
    "\n",
    "2) Add additional variables, 3 and 12-month MA, interest rate change, yield curve, Mkt-RF, seasonal dummy variables. With cross-validation and regularization we hope to do that without overfitting and possibly produce a better result.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "np.random.seed(1764)\n",
    "import pandas as pd\n",
    "\n",
    "import time \n",
    "import datetime\n",
    "import copy\n",
    "import random\n",
    "random.seed(1764)\n",
    "from itertools import product\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy numpy warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, explained_variance_score, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, lasso_path, lars_path, LassoLarsIC\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1764)\n",
    "print(tf.__version__)\n",
    "# confirm GPU is in use\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.regularizers import l1\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "    \n",
    "import ffn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly as py\n",
    "# print (py.__version__) # requires version >= 1.9.0\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import *\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "(697, 60)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Food.lead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yyyymm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195912</th>\n",
       "      <td>2.01</td>\n",
       "      <td>-4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196001</th>\n",
       "      <td>-4.49</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196002</th>\n",
       "      <td>3.35</td>\n",
       "      <td>-1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196003</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196004</th>\n",
       "      <td>1.17</td>\n",
       "      <td>8.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196005</th>\n",
       "      <td>8.20</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196006</th>\n",
       "      <td>5.39</td>\n",
       "      <td>-2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196007</th>\n",
       "      <td>-2.11</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196008</th>\n",
       "      <td>4.57</td>\n",
       "      <td>-3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196009</th>\n",
       "      <td>-3.88</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196010</th>\n",
       "      <td>1.02</td>\n",
       "      <td>9.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196011</th>\n",
       "      <td>9.46</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196012</th>\n",
       "      <td>4.51</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196101</th>\n",
       "      <td>4.70</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196102</th>\n",
       "      <td>4.21</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196103</th>\n",
       "      <td>4.64</td>\n",
       "      <td>-1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196104</th>\n",
       "      <td>-1.39</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196105</th>\n",
       "      <td>4.20</td>\n",
       "      <td>-2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196106</th>\n",
       "      <td>-2.17</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196107</th>\n",
       "      <td>2.72</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196108</th>\n",
       "      <td>4.92</td>\n",
       "      <td>-0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196109</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196110</th>\n",
       "      <td>3.73</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196111</th>\n",
       "      <td>5.28</td>\n",
       "      <td>-3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196112</th>\n",
       "      <td>-3.69</td>\n",
       "      <td>-6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196201</th>\n",
       "      <td>-6.67</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196202</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196203</th>\n",
       "      <td>0.98</td>\n",
       "      <td>-4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196204</th>\n",
       "      <td>-4.59</td>\n",
       "      <td>-11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196205</th>\n",
       "      <td>-11.25</td>\n",
       "      <td>-8.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201507</th>\n",
       "      <td>4.03</td>\n",
       "      <td>-4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201508</th>\n",
       "      <td>-4.37</td>\n",
       "      <td>-1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201509</th>\n",
       "      <td>-1.19</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201510</th>\n",
       "      <td>5.81</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201511</th>\n",
       "      <td>0.11</td>\n",
       "      <td>1.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201512</th>\n",
       "      <td>1.96</td>\n",
       "      <td>-1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0.95</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>4.69</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.63</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>2.06</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>4.75</td>\n",
       "      <td>-0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201607</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201608</th>\n",
       "      <td>-0.52</td>\n",
       "      <td>-2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201610</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>-4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>-4.41</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>4.43</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201701</th>\n",
       "      <td>0.95</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201702</th>\n",
       "      <td>1.71</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201703</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201704</th>\n",
       "      <td>0.76</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201705</th>\n",
       "      <td>1.63</td>\n",
       "      <td>-2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201706</th>\n",
       "      <td>-2.65</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201707</th>\n",
       "      <td>1.52</td>\n",
       "      <td>-2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201708</th>\n",
       "      <td>-2.77</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201709</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201710</th>\n",
       "      <td>0.71</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201711</th>\n",
       "      <td>4.15</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201712</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food  Food.lead\n",
       "yyyymm                  \n",
       "195912   2.01      -4.49\n",
       "196001  -4.49       3.35\n",
       "196002   3.35      -1.67\n",
       "196003  -1.67       1.17\n",
       "196004   1.17       8.20\n",
       "196005   8.20       5.39\n",
       "196006   5.39      -2.11\n",
       "196007  -2.11       4.57\n",
       "196008   4.57      -3.88\n",
       "196009  -3.88       1.02\n",
       "196010   1.02       9.46\n",
       "196011   9.46       4.51\n",
       "196012   4.51       4.70\n",
       "196101   4.70       4.21\n",
       "196102   4.21       4.64\n",
       "196103   4.64      -1.39\n",
       "196104  -1.39       4.20\n",
       "196105   4.20      -2.17\n",
       "196106  -2.17       2.72\n",
       "196107   2.72       4.92\n",
       "196108   4.92      -0.62\n",
       "196109  -0.62       3.73\n",
       "196110   3.73       5.28\n",
       "196111   5.28      -3.69\n",
       "196112  -3.69      -6.67\n",
       "196201  -6.67      -0.25\n",
       "196202  -0.25       0.98\n",
       "196203   0.98      -4.59\n",
       "196204  -4.59     -11.25\n",
       "196205 -11.25      -8.75\n",
       "...       ...        ...\n",
       "201507   4.03      -4.37\n",
       "201508  -4.37      -1.19\n",
       "201509  -1.19       5.81\n",
       "201510   5.81       0.11\n",
       "201511   0.11       1.96\n",
       "201512   1.96      -1.67\n",
       "201601  -1.67       0.95\n",
       "201602   0.95       4.69\n",
       "201603   4.69       0.63\n",
       "201604   0.63       2.06\n",
       "201605   2.06       4.75\n",
       "201606   4.75      -0.51\n",
       "201607  -0.51      -0.52\n",
       "201608  -0.52      -2.92\n",
       "201609  -2.92      -0.33\n",
       "201610  -0.33      -4.41\n",
       "201611  -4.41       4.43\n",
       "201612   4.43       0.95\n",
       "201701   0.95       1.71\n",
       "201702   1.71       0.52\n",
       "201703   0.52       0.76\n",
       "201704   0.76       1.63\n",
       "201705   1.63      -2.65\n",
       "201706  -2.65       1.52\n",
       "201707   1.52      -2.77\n",
       "201708  -2.77       0.43\n",
       "201709   0.43       0.71\n",
       "201710   0.71       4.15\n",
       "201711   4.15      -0.10\n",
       "201712  -0.10       2.27\n",
       "\n",
       "[697 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "data = pd.read_csv(\"30_Industry_Portfolios.csv\")\n",
    "data = data.set_index('yyyymm')\n",
    "industries = list(data.columns)\n",
    "# map industry names to col nums\n",
    "ind_reverse_dict = dict([(industries[i], i) for i in range(len(industries))])\n",
    "\n",
    "rfdata = pd.read_csv(\"F-F_Research_Data_Factors.csv\")\n",
    "rfdata = rfdata.set_index('yyyymm')\n",
    "data['rf'] = rfdata['RF']\n",
    "\n",
    "# subtract risk-free rate\n",
    "# create a response variable led by 1 period to predict\n",
    "for ind in industries:\n",
    "    data[ind] = data[ind] - data['rf']\n",
    "\n",
    "#for ind in industries:\n",
    "#    data[ind+\".3m\"] = pd.rolling_mean(data[ind],3)\n",
    "    \n",
    "#for ind in industries:\n",
    "#    data[ind+\".6m\"] = pd.rolling_mean(data[ind],6)\n",
    "\n",
    "#for ind in industries:\n",
    "#    data[ind+\".12m\"] = pd.rolling_mean(data[ind],12)\n",
    "    \n",
    "for ind in industries:\n",
    "    data[ind+\".lead\"] = data[ind].shift(-1)\n",
    "\n",
    "data = data.loc[data.index[data.index > 195911]]\n",
    "data = data.drop(columns=['rf'])    \n",
    "data = data.dropna(axis=0, how='any')\n",
    "\n",
    "nresponses = len(industries)\n",
    "npredictors = data.shape[1]-nresponses\n",
    "\n",
    "predictors = list(data.columns[:npredictors])\n",
    "predictor_reverse_dict = dict([(predictors[i], i) for i in range(len(predictors))])\n",
    "\n",
    "responses = list(data.columns[-nresponses:])\n",
    "response_reverse_dict = dict([(responses[i], i) for i in range(len(responses))])\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data[['Food', 'Food.lead']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Games</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>Chems</th>\n",
       "      <th>Txtls</th>\n",
       "      <th>...</th>\n",
       "      <th>Telcm.lead</th>\n",
       "      <th>Servs.lead</th>\n",
       "      <th>BusEq.lead</th>\n",
       "      <th>Paper.lead</th>\n",
       "      <th>Trans.lead</th>\n",
       "      <th>Whlsl.lead</th>\n",
       "      <th>Rtail.lead</th>\n",
       "      <th>Meals.lead</th>\n",
       "      <th>Fin.lead</th>\n",
       "      <th>Other.lead</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yyyymm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195912</th>\n",
       "      <td>2.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-3.02</td>\n",
       "      <td>1.64</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.87</td>\n",
       "      <td>-1.97</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-7.93</td>\n",
       "      <td>-9.41</td>\n",
       "      <td>-4.31</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>-6.09</td>\n",
       "      <td>-10.08</td>\n",
       "      <td>-4.68</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196001</th>\n",
       "      <td>-4.49</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>-2.05</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>-7.84</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-6.68</td>\n",
       "      <td>-10.03</td>\n",
       "      <td>-4.77</td>\n",
       "      <td>...</td>\n",
       "      <td>8.07</td>\n",
       "      <td>9.13</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>6.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196002</th>\n",
       "      <td>3.35</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.39</td>\n",
       "      <td>9.31</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>3.34</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-3.88</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196003</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>2.18</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>7.14</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>8.86</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196004</th>\n",
       "      <td>1.17</td>\n",
       "      <td>-2.16</td>\n",
       "      <td>1.35</td>\n",
       "      <td>6.46</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.49</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>11.90</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196005</th>\n",
       "      <td>8.20</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>2.44</td>\n",
       "      <td>7.28</td>\n",
       "      <td>11.67</td>\n",
       "      <td>7.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>13.50</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-8.07</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.17</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.72</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196006</th>\n",
       "      <td>5.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>4.73</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.38</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-6.16</td>\n",
       "      <td>-2.99</td>\n",
       "      <td>-1.25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196007</th>\n",
       "      <td>-2.11</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>4.60</td>\n",
       "      <td>-4.72</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-3.99</td>\n",
       "      <td>-6.80</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.94</td>\n",
       "      <td>5.69</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.98</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.85</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196008</th>\n",
       "      <td>4.57</td>\n",
       "      <td>3.24</td>\n",
       "      <td>5.20</td>\n",
       "      <td>7.16</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.09</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>-7.61</td>\n",
       "      <td>-7.37</td>\n",
       "      <td>-7.07</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>-8.57</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>-4.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196009</th>\n",
       "      <td>-3.88</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>-6.20</td>\n",
       "      <td>-9.18</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-6.70</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-3.40</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-4.54</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196010</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.54</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.38</td>\n",
       "      <td>6.48</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.06</td>\n",
       "      <td>9.49</td>\n",
       "      <td>8.19</td>\n",
       "      <td>5.31</td>\n",
       "      <td>5.35</td>\n",
       "      <td>9.72</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.40</td>\n",
       "      <td>7.71</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196011</th>\n",
       "      <td>9.46</td>\n",
       "      <td>6.57</td>\n",
       "      <td>5.44</td>\n",
       "      <td>13.91</td>\n",
       "      <td>10.11</td>\n",
       "      <td>9.13</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.25</td>\n",
       "      <td>2.04</td>\n",
       "      <td>...</td>\n",
       "      <td>12.29</td>\n",
       "      <td>8.18</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.57</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.56</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196012</th>\n",
       "      <td>4.51</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>3.54</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.28</td>\n",
       "      <td>6.06</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.52</td>\n",
       "      <td>...</td>\n",
       "      <td>7.70</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.56</td>\n",
       "      <td>8.35</td>\n",
       "      <td>7.93</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.08</td>\n",
       "      <td>7.12</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196101</th>\n",
       "      <td>4.70</td>\n",
       "      <td>5.23</td>\n",
       "      <td>8.77</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.47</td>\n",
       "      <td>4.36</td>\n",
       "      <td>5.94</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.46</td>\n",
       "      <td>11.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4.54</td>\n",
       "      <td>6.83</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.31</td>\n",
       "      <td>4.82</td>\n",
       "      <td>8.23</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196102</th>\n",
       "      <td>4.21</td>\n",
       "      <td>8.16</td>\n",
       "      <td>5.41</td>\n",
       "      <td>22.33</td>\n",
       "      <td>2.15</td>\n",
       "      <td>5.90</td>\n",
       "      <td>7.84</td>\n",
       "      <td>5.05</td>\n",
       "      <td>2.13</td>\n",
       "      <td>6.81</td>\n",
       "      <td>...</td>\n",
       "      <td>7.23</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>2.31</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4.45</td>\n",
       "      <td>5.76</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.34</td>\n",
       "      <td>7.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196103</th>\n",
       "      <td>4.64</td>\n",
       "      <td>2.55</td>\n",
       "      <td>5.60</td>\n",
       "      <td>7.18</td>\n",
       "      <td>4.77</td>\n",
       "      <td>6.34</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196104</th>\n",
       "      <td>-1.39</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-5.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.39</td>\n",
       "      <td>4.74</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>4.31</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196105</th>\n",
       "      <td>4.20</td>\n",
       "      <td>5.38</td>\n",
       "      <td>3.39</td>\n",
       "      <td>-3.91</td>\n",
       "      <td>2.71</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.50</td>\n",
       "      <td>5.47</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-3.31</td>\n",
       "      <td>-4.46</td>\n",
       "      <td>-4.57</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-5.63</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196106</th>\n",
       "      <td>-2.17</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>3.97</td>\n",
       "      <td>-5.87</td>\n",
       "      <td>-3.85</td>\n",
       "      <td>3.43</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.35</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196107</th>\n",
       "      <td>2.72</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.95</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>1.97</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>8.99</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.37</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.65</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196108</th>\n",
       "      <td>4.92</td>\n",
       "      <td>3.20</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>10.45</td>\n",
       "      <td>5.21</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.35</td>\n",
       "      <td>5.77</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-6.04</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-6.21</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196109</th>\n",
       "      <td>-0.62</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.24</td>\n",
       "      <td>6.53</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.16</td>\n",
       "      <td>4.30</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196110</th>\n",
       "      <td>3.73</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>7.05</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>8.28</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.11</td>\n",
       "      <td>...</td>\n",
       "      <td>8.34</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>5.65</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.08</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196111</th>\n",
       "      <td>5.28</td>\n",
       "      <td>4.47</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.51</td>\n",
       "      <td>5.30</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.49</td>\n",
       "      <td>7.37</td>\n",
       "      <td>...</td>\n",
       "      <td>3.14</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196112</th>\n",
       "      <td>-3.69</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-6.12</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-3.66</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.32</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>-6.91</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>2.52</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-9.56</td>\n",
       "      <td>-3.90</td>\n",
       "      <td>-4.99</td>\n",
       "      <td>-3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196201</th>\n",
       "      <td>-6.67</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>-13.23</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-7.37</td>\n",
       "      <td>-5.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>-4.76</td>\n",
       "      <td>0.57</td>\n",
       "      <td>...</td>\n",
       "      <td>3.89</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>3.59</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196202</th>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-2.02</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>-2.13</td>\n",
       "      <td>-1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196203</th>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-6.67</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>0.41</td>\n",
       "      <td>4.31</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-12.01</td>\n",
       "      <td>-7.93</td>\n",
       "      <td>-6.27</td>\n",
       "      <td>-5.78</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>-2.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196204</th>\n",
       "      <td>-4.59</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-12.99</td>\n",
       "      <td>-11.04</td>\n",
       "      <td>-8.74</td>\n",
       "      <td>-7.03</td>\n",
       "      <td>-8.01</td>\n",
       "      <td>-11.23</td>\n",
       "      <td>-6.23</td>\n",
       "      <td>-7.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-10.97</td>\n",
       "      <td>-13.19</td>\n",
       "      <td>-11.03</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>-11.34</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>-7.46</td>\n",
       "      <td>-10.02</td>\n",
       "      <td>-11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196205</th>\n",
       "      <td>-11.25</td>\n",
       "      <td>-9.05</td>\n",
       "      <td>-14.14</td>\n",
       "      <td>-11.39</td>\n",
       "      <td>-14.87</td>\n",
       "      <td>-10.19</td>\n",
       "      <td>-10.01</td>\n",
       "      <td>-11.14</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>-7.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.72</td>\n",
       "      <td>-13.11</td>\n",
       "      <td>-12.59</td>\n",
       "      <td>-9.62</td>\n",
       "      <td>-7.81</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>-10.43</td>\n",
       "      <td>-12.90</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-14.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201407</th>\n",
       "      <td>-5.83</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-2.62</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>-5.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.49</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.38</td>\n",
       "      <td>4.57</td>\n",
       "      <td>4.87</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.81</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201408</th>\n",
       "      <td>6.38</td>\n",
       "      <td>5.46</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>2.64</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.39</td>\n",
       "      <td>10.14</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-3.49</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-2.29</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201409</th>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>-7.29</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.44</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.83</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.22</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201410</th>\n",
       "      <td>1.70</td>\n",
       "      <td>3.28</td>\n",
       "      <td>6.13</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.71</td>\n",
       "      <td>1.57</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>2.08</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.47</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>1.83</td>\n",
       "      <td>8.91</td>\n",
       "      <td>5.57</td>\n",
       "      <td>1.93</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201411</th>\n",
       "      <td>5.68</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.23</td>\n",
       "      <td>8.89</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.21</td>\n",
       "      <td>7.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.25</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201412</th>\n",
       "      <td>-2.48</td>\n",
       "      <td>-4.30</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>-4.60</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.89</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>-2.43</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-7.61</td>\n",
       "      <td>-4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201501</th>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>1.56</td>\n",
       "      <td>-2.01</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.12</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.43</td>\n",
       "      <td>6.68</td>\n",
       "      <td>3.10</td>\n",
       "      <td>5.37</td>\n",
       "      <td>5.58</td>\n",
       "      <td>6.82</td>\n",
       "      <td>7.93</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201502</th>\n",
       "      <td>4.44</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.87</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>5.43</td>\n",
       "      <td>4.31</td>\n",
       "      <td>8.10</td>\n",
       "      <td>13.34</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.20</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>-3.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201503</th>\n",
       "      <td>-0.72</td>\n",
       "      <td>-2.07</td>\n",
       "      <td>-8.82</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>3.33</td>\n",
       "      <td>...</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201504</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>5.94</td>\n",
       "      <td>3.75</td>\n",
       "      <td>-4.11</td>\n",
       "      <td>-2.41</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-5.95</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.56</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201505</th>\n",
       "      <td>2.03</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>4.89</td>\n",
       "      <td>1.24</td>\n",
       "      <td>4.37</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201506</th>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-2.57</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>4.09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41</td>\n",
       "      <td>5.22</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>3.27</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>5.79</td>\n",
       "      <td>4.17</td>\n",
       "      <td>1.97</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201507</th>\n",
       "      <td>4.03</td>\n",
       "      <td>3.51</td>\n",
       "      <td>9.59</td>\n",
       "      <td>6.09</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>0.71</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.66</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.42</td>\n",
       "      <td>-5.29</td>\n",
       "      <td>-6.50</td>\n",
       "      <td>-5.69</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-4.13</td>\n",
       "      <td>-5.44</td>\n",
       "      <td>-6.48</td>\n",
       "      <td>-6.54</td>\n",
       "      <td>-5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201508</th>\n",
       "      <td>-4.37</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-7.35</td>\n",
       "      <td>-8.61</td>\n",
       "      <td>-6.94</td>\n",
       "      <td>-3.86</td>\n",
       "      <td>-8.37</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-2.66</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-6.04</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201509</th>\n",
       "      <td>-1.19</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.37</td>\n",
       "      <td>-9.94</td>\n",
       "      <td>-5.32</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-7.28</td>\n",
       "      <td>-8.38</td>\n",
       "      <td>-5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>8.84</td>\n",
       "      <td>11.26</td>\n",
       "      <td>8.16</td>\n",
       "      <td>10.19</td>\n",
       "      <td>6.48</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201510</th>\n",
       "      <td>5.81</td>\n",
       "      <td>8.06</td>\n",
       "      <td>10.90</td>\n",
       "      <td>14.61</td>\n",
       "      <td>12.21</td>\n",
       "      <td>5.81</td>\n",
       "      <td>0.98</td>\n",
       "      <td>7.74</td>\n",
       "      <td>16.62</td>\n",
       "      <td>7.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201511</th>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-2.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.03</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-5.02</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201512</th>\n",
       "      <td>1.96</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>1.86</td>\n",
       "      <td>-4.38</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>-2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-5.09</td>\n",
       "      <td>-7.95</td>\n",
       "      <td>-5.27</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-8.68</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-9.63</td>\n",
       "      <td>-3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>4.28</td>\n",
       "      <td>-8.15</td>\n",
       "      <td>-5.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.52</td>\n",
       "      <td>-9.43</td>\n",
       "      <td>-11.10</td>\n",
       "      <td>-5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>1.15</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.99</td>\n",
       "      <td>6.89</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>2.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0.95</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.25</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.86</td>\n",
       "      <td>8.18</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.18</td>\n",
       "      <td>5.99</td>\n",
       "      <td>5.36</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>4.69</td>\n",
       "      <td>5.61</td>\n",
       "      <td>5.04</td>\n",
       "      <td>8.61</td>\n",
       "      <td>6.88</td>\n",
       "      <td>4.65</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>8.33</td>\n",
       "      <td>3.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-2.55</td>\n",
       "      <td>-5.46</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-6.30</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-2.27</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-2.18</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>2.15</td>\n",
       "      <td>-2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>2.06</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.42</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-4.96</td>\n",
       "      <td>2.46</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>2.06</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>4.75</td>\n",
       "      <td>5.31</td>\n",
       "      <td>6.87</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.27</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.20</td>\n",
       "      <td>2.52</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>4.04</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201607</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>1.82</td>\n",
       "      <td>-2.79</td>\n",
       "      <td>6.15</td>\n",
       "      <td>7.38</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.62</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.29</td>\n",
       "      <td>8.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>4.88</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201608</th>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.37</td>\n",
       "      <td>-3.24</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4.33</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>2.86</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-1.45</td>\n",
       "      <td>-3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201609</th>\n",
       "      <td>-2.92</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>4.62</td>\n",
       "      <td>-3.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-6.92</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.85</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>-5.49</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-8.18</td>\n",
       "      <td>-3.59</td>\n",
       "      <td>-1.96</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201610</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>4.59</td>\n",
       "      <td>5.59</td>\n",
       "      <td>-10.28</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.21</td>\n",
       "      <td>12.75</td>\n",
       "      <td>9.29</td>\n",
       "      <td>2.99</td>\n",
       "      <td>8.47</td>\n",
       "      <td>12.84</td>\n",
       "      <td>8.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>-4.41</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-5.12</td>\n",
       "      <td>3.87</td>\n",
       "      <td>8.15</td>\n",
       "      <td>-4.18</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>4.65</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.34</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.58</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>4.43</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.39</td>\n",
       "      <td>-3.36</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.43</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.45</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food  Beer  Smoke  Games  Books  Hshld  Clths   Hlth  Chems  Txtls  \\\n",
       "yyyymm                                                                        \n",
       "195912   2.01  0.35  -3.02   1.64   7.29   0.67   1.87  -1.97   3.08   0.74   \n",
       "196001  -4.49 -5.71  -2.05   1.21  -5.47  -7.84  -8.53  -6.68 -10.03  -4.77   \n",
       "196002   3.35 -2.14   2.27   4.23   2.39   9.31   1.44  -0.02  -0.74   0.32   \n",
       "196003  -1.67 -2.94  -0.18  -0.65   2.18  -0.56  -2.59   1.26  -2.75  -6.79   \n",
       "196004   1.17 -2.16   1.35   6.46  -1.17  -1.27   0.21   1.49  -5.53  -1.10   \n",
       "196005   8.20 -0.52   2.44   7.28  11.67   7.74   1.74  13.50   3.40   2.10   \n",
       "196006   5.39  0.47   4.73   2.24   0.02   6.38  -1.59  -0.40   0.45   4.04   \n",
       "196007  -2.11 -0.79   4.60  -4.72   0.23  -0.60  -1.10  -3.99  -6.80  -3.14   \n",
       "196008   4.57  3.24   5.20   7.16   3.63   5.09   3.34   2.29   1.17  -0.84   \n",
       "196009  -3.88 -5.00  -2.09  -2.33  -6.20  -9.18  -4.23  -8.87  -6.70  -5.25   \n",
       "196010   1.02  0.54   3.87   0.11   2.38   6.48  -3.50  -3.71  -1.59  -3.06   \n",
       "196011   9.46  6.57   5.44  13.91  10.11   9.13   3.15   3.91   4.25   2.04   \n",
       "196012   4.51 -0.31   3.54   7.77   7.41   1.76   3.28   6.06   2.85   0.52   \n",
       "196101   4.70  5.23   8.77   0.56   9.47   4.36   5.94   5.86   6.46  11.21   \n",
       "196102   4.21  8.16   5.41  22.33   2.15   5.90   7.84   5.05   2.13   6.81   \n",
       "196103   4.64  2.55   5.60   7.18   4.77   6.34   3.08   3.60   0.92   5.92   \n",
       "196104  -1.39  1.40  -0.23  -2.21  -6.37   2.66   2.60  -0.47  -1.47  -5.31   \n",
       "196105   4.20  5.38   3.39  -3.91   2.71  -0.02   6.80   2.10   5.50   5.47   \n",
       "196106  -2.17 -3.12   3.97  -5.87  -3.85   3.43  -5.50  -3.58  -1.32  -3.36   \n",
       "196107   2.72  0.88   5.95  -1.21  -2.55   1.97   2.03   3.27   2.95   1.53   \n",
       "196108   4.92  3.20   7.74   0.89   0.89  10.45   5.21   3.70   2.35   5.77   \n",
       "196109  -0.62 -1.48  -0.07   1.24   0.75  -3.05  -1.14  -1.48  -4.45  -4.25   \n",
       "196110   3.73 -0.84   7.05  -5.26   0.99  -0.67   8.28   3.33   0.05   3.11   \n",
       "196111   5.28  4.47   8.03   0.25   3.75   4.51   5.30   3.12   2.49   7.37   \n",
       "196112  -3.69  1.41  -6.12   1.97  -3.66  -3.78   0.32  -2.21  -0.16  -1.17   \n",
       "196201  -6.67 -3.45  -4.28 -13.23  -3.44  -7.37  -5.89  -4.86  -4.76   0.57   \n",
       "196202  -0.25  0.28   0.68  -2.02  -0.52  -0.90   2.01   3.56   3.30   1.93   \n",
       "196203   0.98 -0.34  -6.67  -5.34   0.41   4.31  -1.18   0.34  -2.72  -0.74   \n",
       "196204  -4.59 -3.59 -12.99 -11.04  -8.74  -7.03  -8.01 -11.23  -6.23  -7.53   \n",
       "196205 -11.25 -9.05 -14.14 -11.39 -14.87 -10.19 -10.01 -11.14  -8.25  -7.50   \n",
       "...       ...   ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "201407  -5.83 -2.92  -3.48  -3.70  -1.60  -2.62  -0.62  -0.33  -3.26  -5.70   \n",
       "201408   6.38  5.46   5.08  -1.80   2.64   5.87   3.53   5.44   4.39  10.14   \n",
       "201409  -0.53  0.83   2.15  -4.38  -7.29   0.84   4.44  -0.08  -2.14  -2.38   \n",
       "201410   1.70  3.28   6.13   0.58   3.28   3.71   1.57   5.77  -1.09   2.08   \n",
       "201411   5.68  4.35   0.76  -0.40   1.11   3.23   8.89   2.67   2.21   7.53   \n",
       "201412  -2.48 -4.30  -3.11  -4.60   1.83   0.02  -0.82  -0.89   0.83  -0.31   \n",
       "201501  -1.64  0.90   2.95   0.25  -2.18  -4.92  -3.75   1.56  -2.01   2.02   \n",
       "201502   4.44  4.40   5.47   5.87   9.00   3.83   5.43   4.31   8.10  13.34   \n",
       "201503  -0.72 -2.07  -8.82  -2.60   0.56  -1.98   1.23   0.86  -3.55   3.33   \n",
       "201504  -0.17 -0.52   5.94   3.75  -4.11  -2.41  -1.53  -1.39   1.11  -5.95   \n",
       "201505   2.03  2.00   1.28   0.71   1.93   0.39   0.04   4.89   1.24   4.37   \n",
       "201506  -1.95 -1.71  -2.57   1.30  -0.84  -0.11   4.17   0.07  -2.72   4.09   \n",
       "201507   4.03  3.51   9.59   6.09  -2.90   0.71   5.96   3.66  -4.90  -0.72   \n",
       "201508  -4.37 -3.12  -4.06  -7.35  -8.61  -6.94  -3.86  -8.37  -7.15  -3.11   \n",
       "201509  -1.19  2.58   2.37  -9.94  -5.32  -0.53   1.18  -7.28  -8.38  -5.92   \n",
       "201510   5.81  8.06  10.90  14.61  12.21   5.81   0.98   7.74  16.62   7.96   \n",
       "201511   0.11 -0.71  -3.00  -0.41  -1.17  -1.10  -1.08   0.71   1.68  -2.59   \n",
       "201512   1.96  0.30   1.59  -1.70  -6.18   1.86  -4.38   0.39  -4.82  -2.65   \n",
       "201601  -1.67 -0.23   4.28  -8.15  -5.28   0.16   1.52  -9.43 -11.10  -5.33   \n",
       "201602   0.95 -2.34   0.93   4.25  -0.96   0.34   0.81  -1.09   6.79   0.63   \n",
       "201603   4.69  5.61   5.04   8.61   6.88   4.65   2.30   2.90   8.33   3.58   \n",
       "201604   0.63  0.31  -0.25  -6.30   1.82  -0.42  -2.27   3.55   3.77   1.55   \n",
       "201605   2.06 -0.91   0.83   5.42  -0.53  -0.09  -4.96   2.46  -1.42  -1.70   \n",
       "201606   4.75  5.31   6.87  -4.43  -0.34   3.16   1.63   0.11  -1.14  -4.67   \n",
       "201607  -0.51  1.82  -2.79   6.15   7.38   2.58   1.62   6.00   4.29   8.39   \n",
       "201608  -0.52 -0.90  -1.22   0.94   0.29   1.24   1.37  -3.24   2.48   1.03   \n",
       "201609  -2.92  1.63  -2.78   4.62  -3.95   0.00  -6.92   0.35  -1.76  -4.87   \n",
       "201610  -0.33 -1.65   4.59   5.59 -10.28  -2.96  -5.76  -7.45  -1.95  -4.17   \n",
       "201611  -4.41 -5.76  -5.12   3.87   8.15  -4.18   1.80   1.37   7.55   1.58   \n",
       "201612   4.43  3.00   5.39  -3.36   1.98   1.43  -0.44   0.82   0.32  -1.27   \n",
       "\n",
       "           ...      Telcm.lead  Servs.lead  BusEq.lead  Paper.lead  \\\n",
       "yyyymm     ...                                                       \n",
       "195912     ...            0.62       -6.18       -7.93       -9.41   \n",
       "196001     ...            8.07        9.13        5.09        3.00   \n",
       "196002     ...           -0.21       -0.31        3.34       -2.43   \n",
       "196003     ...           -1.24        7.14        1.77        0.41   \n",
       "196004     ...            3.05       -1.75       11.90        2.85   \n",
       "196005     ...           -0.58       -8.07        2.39        3.50   \n",
       "196006     ...           -0.03        2.84       -2.02       -4.10   \n",
       "196007     ...            6.94        5.69        2.71        1.18   \n",
       "196008     ...           -6.07       -3.53       -7.61       -7.37   \n",
       "196009     ...           -0.08        4.62       -3.40       -1.85   \n",
       "196010     ...            4.06        9.49        8.19        5.31   \n",
       "196011     ...           12.29        8.18        4.29        5.57   \n",
       "196012     ...            7.70        4.29        5.08        4.56   \n",
       "196101     ...            0.61        0.20        4.54        6.83   \n",
       "196102     ...            7.23       -0.20        2.31       -0.69   \n",
       "196103     ...            0.63       -0.12        2.19       -0.37   \n",
       "196104     ...           -1.22       -0.70        1.57        1.39   \n",
       "196105     ...           -4.19        0.13       -3.31       -4.46   \n",
       "196106     ...            6.25       -8.25        0.56       -0.50   \n",
       "196107     ...            0.12        8.99        5.11        5.37   \n",
       "196108     ...           -2.94       -6.04        1.01       -2.74   \n",
       "196109     ...            0.00        2.24        6.53        1.74   \n",
       "196110     ...            8.34        8.27        0.99        2.05   \n",
       "196111     ...            3.14       -0.68       -0.55       -2.65   \n",
       "196112     ...           -6.32       -4.88       -6.91       -5.22   \n",
       "196201     ...            3.89       -1.94       -0.07        3.87   \n",
       "196202     ...           -3.14       -1.41       -0.76        1.13   \n",
       "196203     ...           -4.93       -3.11      -12.01       -7.93   \n",
       "196204     ...           -7.35      -10.97      -13.19      -11.03   \n",
       "196205     ...           -8.72      -13.11      -12.59       -9.62   \n",
       "...        ...             ...         ...         ...         ...   \n",
       "201407     ...            0.52        3.49        5.10        3.38   \n",
       "201408     ...           -1.70       -1.20       -1.91       -3.49   \n",
       "201409     ...            1.42        0.46        2.83        6.42   \n",
       "201410     ...            3.03        2.05        6.47        4.80   \n",
       "201411     ...           -1.73       -0.60       -1.87        2.08   \n",
       "201412     ...           -4.89       -4.44       -2.14       -2.43   \n",
       "201501     ...            9.12        7.92        8.43        6.68   \n",
       "201502     ...           -2.20       -1.52       -3.12       -1.73   \n",
       "201503     ...            3.40        2.25        0.10       -2.65   \n",
       "201504     ...            0.81       -0.12        4.02        1.32   \n",
       "201505     ...           -0.48       -1.87       -4.92       -2.84   \n",
       "201506     ...            1.41        5.22       -0.91       -0.54   \n",
       "201507     ...           -8.42       -5.29       -6.50       -5.69   \n",
       "201508     ...           -2.63       -1.47       -1.72       -2.66   \n",
       "201509     ...            8.84       11.26        8.16       10.19   \n",
       "201510     ...           -1.92        1.99        0.12       -0.02   \n",
       "201511     ...           -3.03       -1.19       -4.64       -3.75   \n",
       "201512     ...           -0.36       -5.09       -7.95       -5.27   \n",
       "201601     ...            1.15       -2.45        1.45        2.99   \n",
       "201602     ...            6.00        7.76        8.86        8.18   \n",
       "201603     ...            0.59       -2.55       -5.46        0.80   \n",
       "201604     ...            0.30        4.67        5.64        1.79   \n",
       "201605     ...            3.10       -2.12       -1.63        2.06   \n",
       "201606     ...            2.27        7.33        8.20        2.52   \n",
       "201607     ...           -3.56        1.19        2.38        2.46   \n",
       "201608     ...            0.52        0.82        4.33       -0.64   \n",
       "201609     ...           -2.85       -0.55       -2.24       -5.49   \n",
       "201610     ...            6.25       -0.01        2.39        4.21   \n",
       "201611     ...            4.65       -0.19        2.07        1.86   \n",
       "201612     ...            3.36        5.45        3.20        2.28   \n",
       "\n",
       "        Trans.lead  Whlsl.lead  Rtail.lead  Meals.lead  Fin.lead  Other.lead  \n",
       "yyyymm                                                                        \n",
       "195912       -4.31       -5.33       -6.09      -10.08     -4.68       -3.98  \n",
       "196001       -0.94        1.42        4.00        1.81     -0.98        6.32  \n",
       "196002       -4.99       -1.37       -0.13       -3.88      0.05       -2.43  \n",
       "196003       -2.13        0.45       -0.53        8.86     -0.64        0.55  \n",
       "196004        0.90        1.65        3.11        0.80     -0.45        1.02  \n",
       "196005        2.17        5.96        3.41        1.03      3.72        6.41  \n",
       "196006       -3.11       -6.16       -2.99       -1.25      0.09       -5.95  \n",
       "196007        1.98        4.51        2.85        2.05      3.47        3.48  \n",
       "196008       -7.07       -8.44       -8.57       -1.90     -5.78       -4.21  \n",
       "196009       -1.02       -4.22        0.31       -4.54     -0.40        0.38  \n",
       "196010        5.35        9.72        6.50        4.40      7.71        4.01  \n",
       "196011        2.27        2.06        2.05        2.08      5.56        3.80  \n",
       "196012        8.35        7.93        2.28        4.08      7.12        8.23  \n",
       "196101        4.22        3.31        4.82        8.23      7.00        6.00  \n",
       "196102        0.86        4.45        5.76        4.06      4.34        7.08  \n",
       "196103       -1.62        3.08        0.22        4.23      1.38       -3.67  \n",
       "196104        4.74       -0.04        4.31       -1.90      4.00        3.32  \n",
       "196105       -4.57       -4.90        0.80       -5.63     -2.88        0.37  \n",
       "196106       -0.32       -0.01        2.45        2.69      3.35        5.37  \n",
       "196107        3.52        3.09        3.03        0.46      8.65        1.64  \n",
       "196108       -1.16       -4.22        0.66       -6.21     -0.40        3.14  \n",
       "196109        2.16        4.30        9.35        0.71      2.02        0.39  \n",
       "196110        0.47        5.65        4.90        1.08      7.22        1.69  \n",
       "196111       -0.24        0.46       -0.63       -2.21     -4.44       -0.77  \n",
       "196112        2.52       -0.79       -9.56       -3.90     -4.99       -3.62  \n",
       "196201        0.32       -0.09        1.58       -0.59      3.59        4.20  \n",
       "196202       -1.68       -2.30        0.90       -4.07     -2.13       -1.83  \n",
       "196203       -6.27       -5.78       -4.61       -9.09     -7.69       -2.12  \n",
       "196204       -5.17      -11.34       -9.09       -7.46    -10.02      -11.83  \n",
       "196205       -7.81      -11.11      -10.43      -12.90    -11.01      -14.25  \n",
       "...            ...         ...         ...         ...       ...         ...  \n",
       "201407        4.57        4.87        5.71        3.32      3.81        7.19  \n",
       "201408        0.71       -2.29       -1.50       -0.60     -0.59        0.16  \n",
       "201409        6.22        3.32        3.32        1.28      3.87        1.58  \n",
       "201410        5.88        1.83        8.91        5.57      1.93        4.55  \n",
       "201411        1.09        0.26        2.25       -0.43      2.08        0.17  \n",
       "201412       -4.53       -2.37       -0.29        0.66     -7.61       -4.11  \n",
       "201501        3.10        5.37        5.58        6.82      7.93        4.63  \n",
       "201502       -3.62        0.57        1.00       -0.29      0.11       -1.77  \n",
       "201503       -1.14       -1.23       -2.88        0.51      0.76       -0.23  \n",
       "201504       -3.06        1.44        0.54        1.56      3.09        0.92  \n",
       "201505       -3.25       -2.82       -0.49        0.29      1.34       -3.59  \n",
       "201506        3.27       -1.32        5.79        4.17      1.97        3.18  \n",
       "201507       -6.37       -4.13       -5.44       -6.48     -6.54       -5.20  \n",
       "201508       -0.71       -6.04       -1.75        0.44     -3.14       -1.87  \n",
       "201509        6.48        5.07        4.56        5.05      5.90        6.98  \n",
       "201510       -1.10        2.67        0.61       -1.01      2.16        0.05  \n",
       "201511       -5.02       -1.88        0.82       -0.95     -2.92        0.25  \n",
       "201512       -8.53       -8.68       -4.45       -0.94     -9.63       -3.20  \n",
       "201601        6.89        3.85       -0.36        1.03     -2.85        2.71  \n",
       "201602        6.86        6.18        5.99        5.36      6.65        6.68  \n",
       "201603       -1.08        0.49       -0.38       -2.38      3.96        0.67  \n",
       "201604       -2.18        1.78        1.19       -1.48      2.15       -2.02  \n",
       "201605       -2.53        1.81        0.71        1.16     -5.30        3.61  \n",
       "201606        5.39        3.65        3.78        2.19      4.04       -0.21  \n",
       "201607        1.09       -1.03       -1.69       -0.24      4.88        2.24  \n",
       "201608        2.86       -2.56       -0.18       -2.25     -1.45       -3.48  \n",
       "201609       -0.64       -8.18       -3.59       -1.96      1.40       -0.53  \n",
       "201610       12.75        9.29        2.99        8.47     12.84        8.29  \n",
       "201611        0.84        2.34       -0.98        0.58      3.80        2.57  \n",
       "201612        1.70        1.69        0.93        0.71      0.56       -0.87  \n",
       "\n",
       "[685 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exclude 2017 and later to tie to paper\n",
    "data = data.loc[data.index[data.index < 201701]]\n",
    "data = data.loc[data.index[data.index > 195911]]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>Beer</th>\n",
       "      <th>Smoke</th>\n",
       "      <th>Games</th>\n",
       "      <th>Books</th>\n",
       "      <th>Hshld</th>\n",
       "      <th>Clths</th>\n",
       "      <th>Hlth</th>\n",
       "      <th>Chems</th>\n",
       "      <th>Txtls</th>\n",
       "      <th>...</th>\n",
       "      <th>Telcm.lead</th>\n",
       "      <th>Servs.lead</th>\n",
       "      <th>BusEq.lead</th>\n",
       "      <th>Paper.lead</th>\n",
       "      <th>Trans.lead</th>\n",
       "      <th>Whlsl.lead</th>\n",
       "      <th>Rtail.lead</th>\n",
       "      <th>Meals.lead</th>\n",
       "      <th>Fin.lead</th>\n",
       "      <th>Other.lead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.690715</td>\n",
       "      <td>0.710613</td>\n",
       "      <td>0.982321</td>\n",
       "      <td>0.701708</td>\n",
       "      <td>0.528277</td>\n",
       "      <td>0.554190</td>\n",
       "      <td>0.669460</td>\n",
       "      <td>0.650905</td>\n",
       "      <td>0.519781</td>\n",
       "      <td>0.667416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520847</td>\n",
       "      <td>0.694234</td>\n",
       "      <td>0.584175</td>\n",
       "      <td>0.511241</td>\n",
       "      <td>0.582088</td>\n",
       "      <td>0.625562</td>\n",
       "      <td>0.662219</td>\n",
       "      <td>0.702730</td>\n",
       "      <td>0.609810</td>\n",
       "      <td>0.385620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.339811</td>\n",
       "      <td>5.090215</td>\n",
       "      <td>6.061582</td>\n",
       "      <td>7.180918</td>\n",
       "      <td>5.809314</td>\n",
       "      <td>4.759874</td>\n",
       "      <td>6.386027</td>\n",
       "      <td>4.928072</td>\n",
       "      <td>5.518477</td>\n",
       "      <td>7.022552</td>\n",
       "      <td>...</td>\n",
       "      <td>4.628520</td>\n",
       "      <td>6.527984</td>\n",
       "      <td>6.738979</td>\n",
       "      <td>5.055314</td>\n",
       "      <td>5.739306</td>\n",
       "      <td>5.605317</td>\n",
       "      <td>5.349341</td>\n",
       "      <td>6.104515</td>\n",
       "      <td>5.411766</td>\n",
       "      <td>5.815446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-18.150000</td>\n",
       "      <td>-20.190000</td>\n",
       "      <td>-25.320000</td>\n",
       "      <td>-33.400000</td>\n",
       "      <td>-26.560000</td>\n",
       "      <td>-22.240000</td>\n",
       "      <td>-31.500000</td>\n",
       "      <td>-21.060000</td>\n",
       "      <td>-28.600000</td>\n",
       "      <td>-33.110000</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.440000</td>\n",
       "      <td>-28.670000</td>\n",
       "      <td>-32.070000</td>\n",
       "      <td>-27.740000</td>\n",
       "      <td>-28.500000</td>\n",
       "      <td>-29.250000</td>\n",
       "      <td>-29.740000</td>\n",
       "      <td>-31.890000</td>\n",
       "      <td>-22.530000</td>\n",
       "      <td>-28.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.640000</td>\n",
       "      <td>-2.100000</td>\n",
       "      <td>-2.780000</td>\n",
       "      <td>-3.490000</td>\n",
       "      <td>-2.690000</td>\n",
       "      <td>-2.110000</td>\n",
       "      <td>-2.810000</td>\n",
       "      <td>-2.240000</td>\n",
       "      <td>-2.800000</td>\n",
       "      <td>-3.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.110000</td>\n",
       "      <td>-3.090000</td>\n",
       "      <td>-3.290000</td>\n",
       "      <td>-2.430000</td>\n",
       "      <td>-2.780000</td>\n",
       "      <td>-2.570000</td>\n",
       "      <td>-2.430000</td>\n",
       "      <td>-2.940000</td>\n",
       "      <td>-2.420000</td>\n",
       "      <td>-2.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.120000</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>5.310000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>3.560000</td>\n",
       "      <td>3.760000</td>\n",
       "      <td>4.490000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>4.590000</td>\n",
       "      <td>3.460000</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.890000</td>\n",
       "      <td>25.510000</td>\n",
       "      <td>32.380000</td>\n",
       "      <td>34.520000</td>\n",
       "      <td>33.130000</td>\n",
       "      <td>18.220000</td>\n",
       "      <td>31.790000</td>\n",
       "      <td>29.010000</td>\n",
       "      <td>21.680000</td>\n",
       "      <td>59.030000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.220000</td>\n",
       "      <td>23.380000</td>\n",
       "      <td>24.660000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>17.530000</td>\n",
       "      <td>26.490000</td>\n",
       "      <td>27.380000</td>\n",
       "      <td>20.590000</td>\n",
       "      <td>19.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Food        Beer       Smoke       Games       Books       Hshld  \\\n",
       "count  685.000000  685.000000  685.000000  685.000000  685.000000  685.000000   \n",
       "mean     0.690715    0.710613    0.982321    0.701708    0.528277    0.554190   \n",
       "std      4.339811    5.090215    6.061582    7.180918    5.809314    4.759874   \n",
       "min    -18.150000  -20.190000  -25.320000  -33.400000  -26.560000  -22.240000   \n",
       "25%     -1.640000   -2.100000   -2.780000   -3.490000   -2.690000   -2.110000   \n",
       "50%      0.740000    0.710000    1.280000    0.890000    0.510000    0.750000   \n",
       "75%      3.120000    3.660000    4.640000    5.310000    3.720000    3.550000   \n",
       "max     19.890000   25.510000   32.380000   34.520000   33.130000   18.220000   \n",
       "\n",
       "            Clths        Hlth       Chems       Txtls     ...      Telcm.lead  \\\n",
       "count  685.000000  685.000000  685.000000  685.000000     ...      685.000000   \n",
       "mean     0.669460    0.650905    0.519781    0.667416     ...        0.520847   \n",
       "std      6.386027    4.928072    5.518477    7.022552     ...        4.628520   \n",
       "min    -31.500000  -21.060000  -28.600000  -33.110000     ...      -16.440000   \n",
       "25%     -2.810000   -2.240000   -2.800000   -3.200000     ...       -2.110000   \n",
       "50%      0.690000    0.750000    0.670000    0.630000     ...        0.610000   \n",
       "75%      4.310000    3.560000    3.760000    4.490000     ...        3.360000   \n",
       "max     31.790000   29.010000   21.680000   59.030000     ...       21.220000   \n",
       "\n",
       "       Servs.lead  BusEq.lead  Paper.lead  Trans.lead  Whlsl.lead  Rtail.lead  \\\n",
       "count  685.000000  685.000000  685.000000  685.000000  685.000000  685.000000   \n",
       "mean     0.694234    0.584175    0.511241    0.582088    0.625562    0.662219   \n",
       "std      6.527984    6.738979    5.055314    5.739306    5.605317    5.349341   \n",
       "min    -28.670000  -32.070000  -27.740000  -28.500000  -29.250000  -29.740000   \n",
       "25%     -3.090000   -3.290000   -2.430000   -2.780000   -2.570000   -2.430000   \n",
       "50%      0.970000    0.560000    0.690000    0.860000    0.940000    0.470000   \n",
       "75%      4.290000    4.590000    3.460000    4.060000    3.880000    4.000000   \n",
       "max     23.380000   24.660000   21.000000   18.500000   17.530000   26.490000   \n",
       "\n",
       "       Meals.lead    Fin.lead  Other.lead  \n",
       "count  685.000000  685.000000  685.000000  \n",
       "mean     0.702730    0.609810    0.385620  \n",
       "std      6.104515    5.411766    5.815446  \n",
       "min    -31.890000  -22.530000  -28.090000  \n",
       "25%     -2.940000   -2.420000   -2.990000  \n",
       "50%      1.030000    0.820000    0.470000  \n",
       "75%      4.330000    4.000000    4.200000  \n",
       "max     27.380000   20.590000   19.960000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv(\"data.csv\")\n",
    "desc = data.describe()\n",
    "desc\n",
    "# min, max line up with Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Ann. Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>0.074020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beer</th>\n",
       "      <td>0.072005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>0.100147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Games</th>\n",
       "      <td>0.054031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>0.043953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hshld</th>\n",
       "      <td>0.054098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clths</th>\n",
       "      <td>0.057170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hlth</th>\n",
       "      <td>0.065463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chems</th>\n",
       "      <td>0.044917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Txtls</th>\n",
       "      <td>0.051888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnstr</th>\n",
       "      <td>0.041836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FabPr</th>\n",
       "      <td>0.045615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElcEq</th>\n",
       "      <td>0.062927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autos</th>\n",
       "      <td>0.027963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carry</th>\n",
       "      <td>0.063991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mines</th>\n",
       "      <td>0.032527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coal</th>\n",
       "      <td>0.026075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oil</th>\n",
       "      <td>0.062748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Util</th>\n",
       "      <td>0.049564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telcm</th>\n",
       "      <td>0.050868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Servs</th>\n",
       "      <td>0.057776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusEq</th>\n",
       "      <td>0.042774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper</th>\n",
       "      <td>0.046776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trans</th>\n",
       "      <td>0.051138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whlsl</th>\n",
       "      <td>0.057056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtail</th>\n",
       "      <td>0.064258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meals</th>\n",
       "      <td>0.063630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fin</th>\n",
       "      <td>0.056748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.024894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean Ann. Return\n",
       "Food           0.074020\n",
       "Beer           0.072005\n",
       "Smoke          0.100147\n",
       "Games          0.054031\n",
       "Books          0.043953\n",
       "Hshld          0.054098\n",
       "Clths          0.057170\n",
       "Hlth           0.065463\n",
       "Chems          0.044917\n",
       "Txtls          0.051888\n",
       "Cnstr          0.041836\n",
       "Steel          0.002802\n",
       "FabPr          0.045615\n",
       "ElcEq          0.062927\n",
       "Autos          0.027963\n",
       "Carry          0.063991\n",
       "Mines          0.032527\n",
       "Coal           0.026075\n",
       "Oil            0.062748\n",
       "Util           0.049564\n",
       "Telcm          0.050868\n",
       "Servs          0.057776\n",
       "BusEq          0.042774\n",
       "Paper          0.046776\n",
       "Trans          0.051138\n",
       "Whlsl          0.057056\n",
       "Rtail          0.064258\n",
       "Meals          0.063630\n",
       "Fin            0.056748\n",
       "Other          0.024894"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# annualized returns don't match Table 1, oddly\n",
    "# geometric mean, annualized\n",
    "pd.DataFrame((np.prod(data/100 + 1)**(12.0/len(data))-1)[:30], columns=['Mean Ann. Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Ann. Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>0.086108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beer</th>\n",
       "      <td>0.088687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>0.124460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Games</th>\n",
       "      <td>0.087532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>0.065268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hshld</th>\n",
       "      <td>0.068568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clths</th>\n",
       "      <td>0.083360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hlth</th>\n",
       "      <td>0.080966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chems</th>\n",
       "      <td>0.064188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Txtls</th>\n",
       "      <td>0.083096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnstr</th>\n",
       "      <td>0.064656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>0.035833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FabPr</th>\n",
       "      <td>0.069639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElcEq</th>\n",
       "      <td>0.087857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autos</th>\n",
       "      <td>0.055859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carry</th>\n",
       "      <td>0.089740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mines</th>\n",
       "      <td>0.067862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coal</th>\n",
       "      <td>0.091926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oil</th>\n",
       "      <td>0.080976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Util</th>\n",
       "      <td>0.059601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telcm</th>\n",
       "      <td>0.064437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Servs</th>\n",
       "      <td>0.085164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusEq</th>\n",
       "      <td>0.071925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper</th>\n",
       "      <td>0.062952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trans</th>\n",
       "      <td>0.072192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whlsl</th>\n",
       "      <td>0.077332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtail</th>\n",
       "      <td>0.082704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meals</th>\n",
       "      <td>0.088043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fin</th>\n",
       "      <td>0.075605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.046240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean Ann. Return\n",
       "Food           0.086108\n",
       "Beer           0.088687\n",
       "Smoke          0.124460\n",
       "Games          0.087532\n",
       "Books          0.065268\n",
       "Hshld          0.068568\n",
       "Clths          0.083360\n",
       "Hlth           0.080966\n",
       "Chems          0.064188\n",
       "Txtls          0.083096\n",
       "Cnstr          0.064656\n",
       "Steel          0.035833\n",
       "FabPr          0.069639\n",
       "ElcEq          0.087857\n",
       "Autos          0.055859\n",
       "Carry          0.089740\n",
       "Mines          0.067862\n",
       "Coal           0.091926\n",
       "Oil            0.080976\n",
       "Util           0.059601\n",
       "Telcm          0.064437\n",
       "Servs          0.085164\n",
       "BusEq          0.071925\n",
       "Paper          0.062952\n",
       "Trans          0.072192\n",
       "Whlsl          0.077332\n",
       "Rtail          0.082704\n",
       "Meals          0.088043\n",
       "Fin            0.075605\n",
       "Other          0.046240"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try this way, arithmetic mean then annualize (not very correct)\n",
    "#print(pd.DataFrame(((desc.loc['mean']/100+1)**12-1)[:30]))\n",
    "#nope\n",
    "\n",
    "# same\n",
    "pd.DataFrame(((1 + np.mean(data, axis=0)/100)**12 -1)[:30], columns=['Mean Ann. Return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Food</th>\n",
       "      <td>15.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beer</th>\n",
       "      <td>17.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke</th>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Games</th>\n",
       "      <td>24.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Books</th>\n",
       "      <td>20.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hshld</th>\n",
       "      <td>16.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clths</th>\n",
       "      <td>22.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hlth</th>\n",
       "      <td>17.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chems</th>\n",
       "      <td>19.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Txtls</th>\n",
       "      <td>24.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cnstr</th>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steel</th>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FabPr</th>\n",
       "      <td>21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElcEq</th>\n",
       "      <td>21.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autos</th>\n",
       "      <td>23.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carry</th>\n",
       "      <td>21.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mines</th>\n",
       "      <td>25.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coal</th>\n",
       "      <td>35.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oil</th>\n",
       "      <td>18.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Util</th>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telcm</th>\n",
       "      <td>16.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Servs</th>\n",
       "      <td>22.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusEq</th>\n",
       "      <td>23.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper</th>\n",
       "      <td>17.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trans</th>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whlsl</th>\n",
       "      <td>19.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rtail</th>\n",
       "      <td>18.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meals</th>\n",
       "      <td>21.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fin</th>\n",
       "      <td>18.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>20.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         std\n",
       "Food   15.03\n",
       "Beer   17.63\n",
       "Smoke  21.00\n",
       "Games  24.88\n",
       "Books  20.12\n",
       "Hshld  16.49\n",
       "Clths  22.12\n",
       "Hlth   17.07\n",
       "Chems  19.12\n",
       "Txtls  24.33\n",
       "Cnstr  20.75\n",
       "Steel  25.27\n",
       "FabPr  21.18\n",
       "ElcEq  21.52\n",
       "Autos  23.17\n",
       "Carry  21.80\n",
       "Mines  25.82\n",
       "Coal   35.31\n",
       "Oil    18.53\n",
       "Util   13.83\n",
       "Telcm  16.04\n",
       "Servs  22.61\n",
       "BusEq  23.34\n",
       "Paper  17.51\n",
       "Trans  19.88\n",
       "Whlsl  19.42\n",
       "Rtail  18.53\n",
       "Meals  21.15\n",
       "Fin    18.75\n",
       "Other  20.17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#annualized volatility \n",
    "pd.DataFrame((desc.loc['std']*np.sqrt(12))[:30].round(2))\n",
    "# lines up with table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip last row to better match published r-squared\n",
    "# looks like they forecast actuals 1960-2016 using 1959m12 to 2016m11\n",
    "# not exact matches to Table 2 R-squared but almost within rounding error \n",
    "X = data.values[:-1,:npredictors]\n",
    "Y = data.values[:-1,-nresponses:]\n",
    "nrows = X.shape[0]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.49  -5.71  -2.05   1.21  -5.47  -7.84  -8.53  -6.68 -10.03  -4.77\n",
      "  -6.67  -9.38  -4.42 -12.3  -11.71  -5.03  -3.81  -7.91  -7.82  -2.4\n",
      "   0.62  -6.18  -7.93  -9.41  -4.31  -5.33  -6.09 -10.08  -4.68  -3.98]\n",
      "[13 14 27  8 23 11  6 22 17  5 18  7 10 21 26  1  4 25 15  9 28  0 12 24\n",
      " 29 16 19  2 20  3]\n",
      "[-12.3  -11.71 -10.08 -10.03  -9.41  -9.38  -8.53  -7.93  -7.91  -7.84\n",
      "  -7.82  -6.68  -6.67  -6.18  -6.09  -5.71  -5.47  -5.33  -5.03  -4.77\n",
      "  -4.68  -4.49  -4.42  -4.31  -3.98  -3.81  -2.4   -2.05   0.62   1.21]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 2. 0. 0. 2. 0. 2. 2. 0. 1. 0. 0. 1. 1. 0. 0. 2.\n",
      " 0. 0. 0. 2. 0. 1.]\n",
      "[-2.05, 1.21, -3.81, -2.4, 0.6199999999999999, -3.98]\n",
      "[-10.03, -9.38, -12.3, -11.71, -9.41, -10.08]\n",
      "(684, 30)\n",
      "(684, 30)\n"
     ]
    }
   ],
   "source": [
    "# convert Ys to 3 classes\n",
    "# long = 1\n",
    "# short = 2\n",
    "# neither = 0\n",
    "ISLONG=1\n",
    "ISSHORT=2\n",
    "ISFLAT=0\n",
    "\n",
    "Y_sortindex = np.argsort(Y)\n",
    "print(Y[0])\n",
    "# sorted position\n",
    "print(Y_sortindex[0]) \n",
    "# sorted array\n",
    "print(Y[0,Y_sortindex[0]])\n",
    "# initialize class to 0\n",
    "Y_class=np.zeros_like(Y)\n",
    "for row in range(Y_class.shape[0]):\n",
    "    # if index in last 6, long\n",
    "    longlist = Y_sortindex[row,-6:]\n",
    "    Y_class[row, longlist]=ISLONG\n",
    "    # if index is in first 6, short\n",
    "    shortlist = Y_sortindex[row,:6]\n",
    "    Y_class[row, shortlist]=ISSHORT\n",
    "    \n",
    "print(Y_class[0])\n",
    "print([Y[0,i] for i in range(30) if Y_class[0,i]==1])\n",
    "print([Y[0,i] for i in range(30) if Y_class[0,i]==2])\n",
    "print(Y_class.shape)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all predictors - higher in-sample R-squared\n",
    "coef_dict_all = []\n",
    "for _ in responses:\n",
    "    coef_dict_all.append(range(len(predictors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -3.34  -1.95  -7.59  -7.76 -12.05  -7.5   -5.69  -7.71  -7.37  -5.26\n",
      "  -9.84  -6.31  -7.15  -6.89  -9.35 -12.49  -2.34  -0.77 -12.16  -4.83\n",
      "  -3.16 -11.17  -9.73  -8.89  -8.17  -8.28  -6.31 -13.12  -9.78  -6.2 ]\n",
      "Food     -3.34\n",
      "Beer     -1.95\n",
      "Smoke    -7.59\n",
      "Games    -7.76\n",
      "Books   -12.05\n",
      "Hshld    -7.50\n",
      "Clths    -5.69\n",
      "Hlth     -7.71\n",
      "Chems    -7.37\n",
      "Txtls    -5.26\n",
      "Cnstr    -9.84\n",
      "Steel    -6.31\n",
      "FabPr    -7.15\n",
      "ElcEq    -6.89\n",
      "Autos    -9.35\n",
      "Carry   -12.49\n",
      "Mines    -2.34\n",
      "Coal     -0.77\n",
      "Oil     -12.16\n",
      "Util     -4.83\n",
      "Telcm    -3.16\n",
      "Servs   -11.17\n",
      "BusEq    -9.73\n",
      "Paper    -8.89\n",
      "Trans    -8.17\n",
      "Whlsl    -8.28\n",
      "Rtail    -6.31\n",
      "Meals   -13.12\n",
      "Fin      -9.78\n",
      "Other    -6.20\n",
      "Name: 197001, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# first iteration will train up to including 196911\n",
    "# will use 196912 to predict 197001\n",
    "# 1970101 will be first month of performance to use\n",
    "# train on first 121 months up to 196912 (0:120), put first prediction in P[121] (122nd row)\n",
    "# first month of performance will be 197002\n",
    "FIRST_TRAIN_MONTHS = 121\n",
    "FIRST_PREDICT_MONTH = FIRST_TRAIN_MONTHS # This is stupid but keeps my head straight\n",
    "\n",
    "print(X[FIRST_TRAIN_MONTHS])\n",
    "print(data.iloc[FIRST_TRAIN_MONTHS][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BacktestModel():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 X, # predictors\n",
    "                 Y, # responses\n",
    "                 model=None, # model that supports fit(X,Y), predict(X) , predicts an entire row,\n",
    "                 create_model=None, # or create_model which returns a model (needed for 'timestep' but slows down so pass model if dynamic not needed)\n",
    "                 coef_dict_param=\"all\", # mapping of predictors to responses (\"all\", \"timestep\", or a list of lists)\n",
    "                 startindex=FIRST_TRAIN_MONTHS,\n",
    "                 scaler=None,\n",
    "                 fit_missing=None):\n",
    "        \n",
    "        self.Xrows, self.Xcols = X.shape\n",
    "        self.Yrows, self.Ycols = Y.shape\n",
    "        \n",
    "        if self.Xrows != self.Yrows:\n",
    "            raise(ValueError, \"Shapes differ: X %s, Y %s\" % (str(X.shape), str(Y.shape)))            \n",
    "            \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Xscale = X.copy()\n",
    "        self.Yscale = Y.copy()\n",
    "\n",
    "        if scaler:\n",
    "            # MinMaxScaler: each row (min->0, max->1) \n",
    "            # StandardScaler: each row (mean->0, SD->1)            \n",
    "            # transpose, scale, transpose back because scales by columns\n",
    "            print(\"scaler: %s \" %str(scaler))\n",
    "            self.Xscale = scaler().fit_transform(Xscale.transpose()).transpose()\n",
    "            self.Yscale = scaler().fit_transform(Yscale.transpose()).transpose()\n",
    "        \n",
    "        self.model = model\n",
    "        self.create_model = create_model\n",
    "        self.coef_dict_param = coef_dict_param\n",
    "        self.startindex = startindex\n",
    "        self.fit_missing = fit_missing\n",
    "\n",
    "    def fit_predict(self, ntrain, npredict=1, verbose=False):\n",
    "        \"\"\"for backtest, train model using Y v. X \n",
    "        train on first ntrain rows. if ntrain=121, fit 0:120\n",
    "        predict following npredict rows \n",
    "        if npredict=1, predict row 121\n",
    "        if npredict=12, predict rows 121-132\n",
    "        \"\"\"\n",
    "        \n",
    "        # fit first ntrain rows\n",
    "        X_fit = self.Xscale[:ntrain]  # e.g. 0:120\n",
    "        Y_fit = self.Yscale[:ntrain]\n",
    "        # predict npredict rows\n",
    "        X_predict = self.Xscale[ntrain:ntrain+npredict] # 121-122\n",
    "        X_predict = X_predict.reshape(npredict,self.Xcols)\n",
    "       \n",
    "        # if no coef_dict select predictors into coef_dict\n",
    "        if self.coef_dict_param == \"timestep\":\n",
    "            msg = \"Performing subset selection\"\n",
    "            coef_dict = subset_selection(X_fit, Y_fit, LassoLarsIC(criterion='aic'))\n",
    "        # if coef_dict == \"all\" use all predictors for each response        \n",
    "        elif self.coef_dict_param == 'all':\n",
    "            msg = \"Using all predictors\"\n",
    "            coef_dict = [range(self.Xcols) for _ in range(self.ycols)]\n",
    "        else: # should check valid dict\n",
    "            msg = \"Using coef_dict predictors\"\n",
    "            coef_dict = self.coef_dict_param\n",
    "        if verbose: \n",
    "            print(msg)\n",
    "\n",
    "        if self.create_model:\n",
    "            self.model = PredictWrapper(self.create_model, coef_dict, fit_missing=self.fit_missing)\n",
    "            \n",
    "        self.model.fit(X_fit, Y_fit, verbose=verbose)\n",
    "        return self.model.predict(X_predict, verbose=verbose)\n",
    "\n",
    "    # predict all months\n",
    "    # initial train_months = 120 -> train first model on 120 rows\n",
    "    # first prediction will be in P[120] (121st row)\n",
    "    # step = 6 -> predict following 6 rows, then step forward 6 months at a time\n",
    "    # initialize predictions matrix self.P\n",
    "    \n",
    "    # use either step or folds\n",
    "    # step, do range(self.startindex, nrows, step)\n",
    "    # folds, at each fold train 0:startfold, predict startfold+1:endfold\n",
    "    # store only out-of-sample predictions in P, calc out-of-sample MSE\n",
    "    \n",
    "    # using a step > 1 or folds is quicker, for quicker xval, or to speed up by not estimating model at each timestep\n",
    "\n",
    "    def gen_predictions(self,\n",
    "                        step=1, \n",
    "                        splits=None,\n",
    "                        verbose=False):\n",
    "\n",
    "        self.P_L = np.zeros((Y_class.shape[0],OUTPUT_DIM))\n",
    "        self.P_S = np.zeros((Y_class.shape[0],OUTPUT_DIM))\n",
    "        self.P_F = np.zeros((Y_class.shape[0],OUTPUT_DIM))\n",
    "        self.P = np.zeros((Y_class.shape[0],OUTPUT_DIM))\n",
    "\n",
    "        progress_i = 0\n",
    "        self.nrows, self.ycols = Y.shape\n",
    "        \n",
    "        if splits:\n",
    "            month_indexes = splits[:-1] # last index is nrows\n",
    "        else:\n",
    "            # create list of steps\n",
    "            month_indexes = list(range(self.startindex, nrows, step))\n",
    "        steps = [month_indexes[i+1]-month_indexes[i] for i in range(len(month_indexes)-1)]\n",
    "        # last step -> end\n",
    "        steps.append(self.nrows - month_indexes[-1])\n",
    "        \n",
    "        if verbose:\n",
    "            print (\"Steps: \" + str(month_indexes))\n",
    "\n",
    "        for month_index, forecast_rows in zip(month_indexes, steps):\n",
    "            if verbose:\n",
    "                print(\"Training on first %d rows (%d:%d), putting predictions in rows %s\" % (month_index, \n",
    "                                                                                            0, month_index-1, \n",
    "                                                                                            str(range(month_index,month_index+forecast_rows))))\n",
    "            longprobs, shortprobs, flatprobs = self.fit_predict(month_index, forecast_rows, verbose=False)\n",
    "\n",
    "            first_pred_row = month_index\n",
    "            for row_index in range(forecast_rows):\n",
    "                self.P_L[first_pred_row + row_index] = longprobs[row_index]\n",
    "                self.P_S[first_pred_row + row_index] = shortprobs[row_index]\n",
    "                self.P_F[first_pred_row + row_index] = flatprobs[row_index]\n",
    "                # do longprob - shortprob\n",
    "                self.P[first_pred_row + row_index] = longprobs[row_index] - shortprobs[row_index]\n",
    "            sys.stdout.write('.')\n",
    "            progress_i += 1\n",
    "            if progress_i % 80 == 0:\n",
    "                print(\"\")\n",
    "                print(\"%s Still training step %d of %d\" % (time.strftime(\"%H:%M:%S\"), progress_i, len(month_indexes)))\n",
    "            sys.stdout.flush()\n",
    "        print(\"\")\n",
    "        \n",
    "\n",
    "    def evaluate_predictions(self):\n",
    "        \n",
    "        # evaluate prediction (can move to separate function)\n",
    "        msetemp = (self.P[self.startindex:]-self.Yscale[self.startindex:])**2\n",
    "        #remove nans\n",
    "        msetemp = msetemp[~np.isnan(msetemp)]\n",
    "        mse = np.mean(msetemp)\n",
    "        print(\"MSE across all predictions: %.4f\" % mse)\n",
    "        \n",
    "        # force unpredicted ys to be nans, then remove nans\n",
    "        vartemp = self.Yscale[self.startindex:] - self.P[self.startindex:] + self.P[self.startindex:]\n",
    "        vartemp = vartemp[~np.isnan(vartemp)]\n",
    "        y_variance = np.var(vartemp[self.startindex:])\n",
    "        print(\"Variance: %.4f\" % (y_variance))\n",
    "        print(\"R-squared: %.4f\" % (1- mse/y_variance))\n",
    "        \n",
    "        return(mse)\n",
    "\n",
    "    def evaluate_quantiles(self, chart=False, verbose=False, Y=None):\n",
    "\n",
    "        if Y is None: #kludgey override Y\n",
    "            evalY = self.Y\n",
    "        else:\n",
    "            evalY = Y\n",
    "\n",
    "        self.P_quantiles = np.zeros_like(self.P)\n",
    "        self.Y_quantiles = np.zeros_like(evalY)\n",
    "        \n",
    "        # compute score for predicted quantiles vs. actual (expected) quantiles\n",
    "        N_QUANTILES=5\n",
    "        for row in range(self.startindex, self.P_quantiles.shape[0]):\n",
    "            #print(self.P[row])\n",
    "            self.P_quantiles[row] = pd.qcut(self.P[row], N_QUANTILES, range(N_QUANTILES))\n",
    "            self.Y_quantiles[row] = pd.qcut(evalY[row], N_QUANTILES, range(N_QUANTILES))\n",
    "\n",
    "        pred_quantiles = self.P_quantiles[self.startindex:]\n",
    "        true_quantiles = self.Y_quantiles[self.startindex:]\n",
    "\n",
    "        nrows, ncols = pred_quantiles.shape\n",
    "\n",
    "        pred_quantiles = pred_quantiles.reshape(nrows*ncols)\n",
    "        true_quantiles = true_quantiles.reshape(nrows*ncols) \n",
    "        \n",
    "        nrows = nrows * ncols\n",
    "        conf_mat = confusion_matrix(pred_quantiles, true_quantiles)\n",
    "        if chart:\n",
    "            fig, ax = plt.subplots(figsize=(10,10))\n",
    "            sns.heatmap(conf_mat, annot=True, fmt='d')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.show()\n",
    "            \n",
    "        if verbose:\n",
    "            print(chisquare(conf_mat))\n",
    "\n",
    "        conf_mat_expected = np.array([[0.64, 0.16],[0.16, 0.04]])\n",
    "\n",
    "        myscores = []\n",
    "        for q in range(5):\n",
    "            temp_pred = pred_quantiles == q\n",
    "            temp_actual = true_quantiles == q\n",
    "            conf_mat = confusion_matrix(temp_pred, temp_actual) / float(nrows)\n",
    "            diff_mat = conf_mat - conf_mat_expected\n",
    "            if verbose:\n",
    "                print(conf_mat)\n",
    "                print(diff_mat)\n",
    "                print(chisquare(conf_mat.reshape(4)*nrows, conf_mat_expected.reshape(4)*nrows))\n",
    "            # probably no valid statistical interpretation but \n",
    "            # average of improvement in true positive % and true negative %\n",
    "            myscore = (diff_mat[0][0] + diff_mat[1][1])/2\n",
    "            myscores.append(myscore)\n",
    "\n",
    "        # average of my score for top and bottom quintiles\n",
    "        finalscore = (myscores[0] + myscores[4])/2\n",
    "        if verbose:\n",
    "            print(\"Score: %f\" % (finalscore))\n",
    "            \n",
    "        return finalscore\n",
    "\n",
    "    def walkforward_xval (self, n_splits=5, verbose=False):\n",
    "        \"\"\"quick and dirty genreturns, with a step\"\"\"\n",
    "        # generate k-folds\n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        kf.get_n_splits(X)\n",
    "        last_indexes = []\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # use test_index as last index to train\n",
    "            last_index = test_index[-1] + 1\n",
    "            last_indexes.append(last_index)\n",
    "        print(\"%s Generate splits %s\" % (time.strftime(\"%H:%M:%S\"), str([i for i in last_indexes])))\n",
    "        #override startindex\n",
    "        self.startindex = last_indexes[0]\n",
    "        return self.gen_predictions(splits=last_indexes, verbose=verbose)\n",
    "    \n",
    "    def gen_returns(self, port_returns_func, verbose=False):\n",
    "\n",
    "        self.R = np.zeros(self.P.shape[0])\n",
    "        first_pred_month=self.startindex\n",
    "        \n",
    "        indcount = [0] * self.ycols\n",
    "        longcount = [0] * self.ycols\n",
    "        shortcount = [0] * self.ycols\n",
    "        \n",
    "        for month_index in range(first_pred_month, nrows-1):\n",
    "            return_month = month_index + 1\n",
    "            port_return, long_indexes, short_indexes = port_returns_func(self.P[month_index], \n",
    "                                                                         self.X[return_month])\n",
    "            self.R[return_month] = port_return\n",
    "            \n",
    "            for i in long_indexes:\n",
    "                indcount[i] += 1\n",
    "                longcount[i] += 1\n",
    "            for i in short_indexes:\n",
    "                indcount[i] += 1\n",
    "                shortcount[i] += 1\n",
    "                \n",
    "        for i in range(len(responses)):\n",
    "            print(\"%s: long %d times, short %d times, total %d times\" % (predictors[i], \n",
    "                                                                         longcount[i], \n",
    "                                                                         shortcount[i], \n",
    "                                                                         indcount[i]))\n",
    "        return self.R\n",
    "\n",
    "    def report_returns(self, start_date='01/01/1970', freq='M'):\n",
    "\n",
    "        first_pred_month=self.startindex        \n",
    "        results = self.R[first_pred_month:]\n",
    "        index = pd.date_range(start_date,periods=results.shape[0], freq=freq)\n",
    "        perfdata = pd.DataFrame(results,index=index,columns=['Returns'])\n",
    "        perfdata['Equity'] = 100 * np.cumprod(1 + results / 100)\n",
    "        self.cumulative_return = perfdata['Equity']\n",
    "\n",
    "        stats = perfdata['Equity'].calc_stats()\n",
    "        \n",
    "        retframe = pd.DataFrame([stats.stats.loc['start'],\n",
    "                                 stats.stats.loc['end'],\n",
    "                                 stats.stats.loc['cagr'],\n",
    "                                 stats.stats.loc['yearly_vol'],\n",
    "                                 stats.stats.loc['yearly_sharpe'],\n",
    "                                 stats.stats.loc['max_drawdown'],\n",
    "                                 ffn.core.calc_sortino_ratio(perfdata.Returns, rf=0, nperiods=564, annualize=False),\n",
    "                                ],\n",
    "                                index = ['start',\n",
    "                                         'end',\n",
    "                                         'cagr',\n",
    "                                         'yearly_vol',\n",
    "                                         'yearly_sharpe',\n",
    "                                         'max_drawdown',\n",
    "                                         'sortino',\n",
    "                                        ],\n",
    "                                columns=['Value'])   \n",
    "        return retframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMSTOCKS = 6 # top quintile (and bottom)\n",
    "\n",
    "def calc_returns(prediction_row, return_row, numstocks=NUMSTOCKS, verbose=False):\n",
    "\n",
    "    # ensure nan sorts to top for shorts\n",
    "    short_sort_array = [999999 if np.isnan(x) else x for x in prediction_row]\n",
    "    # pick bottom numstocks\n",
    "    select_array = np.argsort(short_sort_array)\n",
    "    short_indexes = select_array[:numstocks]\n",
    "\n",
    "    # ensure nan sorts to bottom for longs\n",
    "    long_sort_array = [-999999 if np.isnan(x) else x for x in prediction_row]\n",
    "    # pick top numstocks\n",
    "    select_array = np.argsort(long_sort_array)\n",
    "    long_indexes = select_array[-numstocks:]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Longs: %s\" %(str([(i,prediction_row[i]) for i in long_indexes])))\n",
    "        print(\"Shorts: %s\" %(str([(i,prediction_row[i]) for i in short_indexes])))\n",
    "\n",
    "    # compute equal weighted long/short return\n",
    "    return np.mean(return_row[long_indexes])/2 - np.mean(return_row[short_indexes])/2, long_indexes, short_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01/01/1970'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date_int = data.index[FIRST_TRAIN_MONTHS]\n",
    "start_year, start_month = start_date_int // 100, start_date_int % 100\n",
    "start_date_str = \"%02d/%02d/%d\" % (start_month, 1, start_year)\n",
    "start_date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# use keras instead of sklearn MLPRegressor\n",
    "# wrap keras model in a class \n",
    "# multioutput 30 predictions simultaneously to speed up \n",
    "# fit takes a list of response ys, predict returns a list of y_predict arrays\n",
    "# no coef_dict\n",
    "INPUT_DIM = X.shape[1]\n",
    "NCLASSES=3\n",
    "print(INPUT_DIM)\n",
    "OUTPUT_DIM = len(responses) # 30\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS=500\n",
    "\n",
    "# 500 is arbitrary, which bugs me\n",
    "# something one could do is backtest and walk-forward xval with an xval set\n",
    "# leave 30 months out of training fold, train until error on those 30 months is minimized, eval on following fold\n",
    "# the other thing that bugs me is higher epochs take longer and yield worse results, there's some 'regularization thruogh under-training' going on\n",
    "# but stochastically will never train at same speed, so you can pick a model and it might need more or less training than 100 in production\n",
    "\n",
    "class KerasBacktestModel(object):\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_hidden_layers = 2,\n",
    "                 hidden_layer_size = 32,\n",
    "                 reg_penalty = 0.0001,\n",
    "                 dropout = 0.25,\n",
    "                 epochs=EPOCHS,\n",
    "                 verbose=True):\n",
    "        \n",
    "        self.epochs=epochs\n",
    "        \n",
    "        \"\"\"initialize keras model\"\"\"\n",
    "        \n",
    "        main_input = Input(shape=(INPUT_DIM,),\n",
    "                           dtype='float32', \n",
    "                           name='main_input')\n",
    "        lastlayer=main_input\n",
    "        \n",
    "        for i in range(n_hidden_layers):\n",
    "            if verbose:\n",
    "                print(\"layer %d size %d, reg_penalty %.8f, dropout %.3f\" % (i + 1, \n",
    "                                                                            hidden_layer_size, \n",
    "                                                                            reg_penalty, \n",
    "                                                                            dropout))\n",
    "            lastlayer = Dense(units = hidden_layer_size, \n",
    "                              activation = 'relu',\n",
    "                              kernel_initializer = keras.initializers.glorot_uniform(),\n",
    "                              kernel_regularizer=keras.regularizers.l1(reg_penalty),\n",
    "                              name = \"Dense%02d\" % i)(lastlayer)\n",
    "            \n",
    "            if dropout:\n",
    "                lastlayer = Dropout(dropout, name = \"Dropout%02d\" % i)(lastlayer)\n",
    "                \n",
    "        outputs = []\n",
    "        for i in range(OUTPUT_DIM):\n",
    "            # OUTPUT_DIM outputs\n",
    "            outputs.append(Dense(NCLASSES, \n",
    "                                 activation='softmax',\n",
    "                                 name = \"Output%02d\" % (i+1))(lastlayer))\n",
    "            \n",
    "        self.model = Model(inputs=[main_input], outputs=outputs)\n",
    "        if verbose:\n",
    "            print(self.model.summary())\n",
    "            \n",
    "        self.model.compile(loss=\"categorical_crossentropy\", \n",
    "                           optimizer=\"rmsprop\", \n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "        \n",
    "    def fit(self, X, Y, epochs=None, verbose=False):\n",
    "        # convert Y to list of ys\n",
    "        nrows, npreds = Y.shape\n",
    "        Y_list = [keras.utils.to_categorical(Y[:,i], num_classes=NCLASSES) for i in range(OUTPUT_DIM)]\n",
    "\n",
    "        if epochs:\n",
    "            self.epochs = epochs\n",
    "            \n",
    "        fit = self.model.fit(X,\n",
    "                             Y_list,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             epochs=self.epochs,\n",
    "                             verbose=False)\n",
    "        #evaluate returns a list of overall loss, loss by column and then accuracy by column\n",
    "        evaluate = self.model.evaluate(X, Y_list, batch_size=BATCH_SIZE, verbose=1)\n",
    "        self.accuracy = np.mean(np.array(evaluate[-npreds:]))\n",
    "\n",
    "        return fit\n",
    "   \n",
    "    def predict(self, X, verbose=False):\n",
    "        \"\"\"predict classes using X\"\"\"\n",
    "        # convert list of ys to Y array\n",
    "        nrows, npreds = X.shape\n",
    "        y_list = self.model.predict(X)\n",
    "        longprobs = np.zeros([nrows, OUTPUT_DIM])\n",
    "        shortprobs = np.zeros([nrows, OUTPUT_DIM])\n",
    "        flatprobs = np.zeros([nrows, OUTPUT_DIM])\n",
    "\n",
    "        evaluate_array = self.model.evaluate(X, y_list, batch_size=BATCH_SIZE, verbose=1)\n",
    "        self.accuracy = np.mean(np.array(evaluate_array[-npreds:]))\n",
    "        \n",
    "        for response in range(OUTPUT_DIM):\n",
    "            for row in range(nrows):\n",
    "                longprobs[row, response] = y_list[response][row, ISLONG]\n",
    "                shortprobs[row, response] = y_list[response][row, ISSHORT]\n",
    "                flatprobs[row, response] = y_list[response][row, ISFLAT]\n",
    "                \n",
    "        return longprobs, shortprobs, flatprobs\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"predict classes using X\"\"\"\n",
    "        # convert list of ys to Y array\n",
    "        nrows, npreds = Y.shape\n",
    "        Y_list = [keras.utils.to_categorical(Y[:,i], num_classes=NCLASSES) for i in range(OUTPUT_DIM)]\n",
    "        evaluate_array = self.model.evaluate(X, Y_list, batch_size=BATCH_SIZE, verbose=False)\n",
    "        self.accuracy = np.mean(np.array(evaluate_array[-npreds:]))\n",
    "        \n",
    "        return self.accuracy\n",
    "     \n",
    "    def save(self, modelname):\n",
    "        self.model.save(\"%s.h5\" % modelname)\n",
    "        self.model.save_weights(\"%s_weights.h5\" % modelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Output01 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output02 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output03 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output04 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output05 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output06 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output07 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output08 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output09 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output10 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output11 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output12 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output13 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output14 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output15 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output16 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output17 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output18 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output19 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output20 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output21 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output22 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output23 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output24 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output25 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output26 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output27 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output28 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output29 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Output30 (Dense)                (None, 3)            93          main_input[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,790\n",
      "Trainable params: 2,790\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Using coef_dict predictors\n",
      "121/121 [==============================] - 1s 5ms/step\n",
      "3/3 [==============================] - 0s 7ms/step\n",
      "(array([[5.13826944e-02, 3.96276981e-01, 3.66905898e-01, 2.69625732e-03,\n",
      "        9.40401014e-03, 3.59372497e-01, 3.10762334e-05, 7.52863958e-02,\n",
      "        6.11134456e-05, 1.26818642e-01, 1.65771716e-03, 1.01529629e-04,\n",
      "        1.05394638e-05, 5.64748466e-01, 4.51076210e-01, 4.09296807e-03,\n",
      "        6.91479966e-02, 7.85558701e-01, 3.23741555e-01, 7.49692023e-01,\n",
      "        5.61963357e-02, 9.61943924e-01, 4.89716291e-01, 4.21424471e-02,\n",
      "        6.25607818e-02, 5.82359417e-06, 1.48435995e-01, 1.98292807e-02,\n",
      "        4.22313772e-02, 3.57796401e-02],\n",
      "       [6.84169354e-03, 7.04126418e-01, 9.41105008e-01, 6.64772873e-04,\n",
      "        3.60157788e-01, 8.32859541e-07, 9.17091686e-03, 1.57115728e-01,\n",
      "        6.02397602e-03, 9.98228848e-01, 7.37663686e-01, 2.69146858e-06,\n",
      "        3.23636550e-06, 8.75095278e-02, 9.86448452e-02, 8.67442880e-03,\n",
      "        5.15028834e-01, 5.82153872e-02, 9.51668561e-01, 1.13279279e-02,\n",
      "        1.02724684e-02, 1.97359128e-03, 9.62729275e-04, 2.19487250e-01,\n",
      "        3.51408846e-03, 2.17751349e-05, 8.40056300e-01, 9.22487397e-03,\n",
      "        9.93278205e-01, 3.94068778e-01],\n",
      "       [1.49133921e-04, 3.83105595e-03, 3.95370908e-02, 6.63455248e-01,\n",
      "        1.44759014e-01, 7.21995950e-01, 5.52563521e-04, 1.47290472e-02,\n",
      "        9.65291113e-02, 2.63237208e-01, 1.25869988e-02, 4.61822987e-04,\n",
      "        4.10905704e-05, 1.31544322e-01, 6.82778776e-01, 5.59255719e-01,\n",
      "        3.22934911e-02, 1.14434622e-01, 5.74157596e-01, 8.82604122e-02,\n",
      "        4.45647687e-02, 8.53144079e-02, 9.84948575e-01, 3.61466289e-01,\n",
      "        1.14495903e-01, 1.17101530e-02, 4.98395711e-01, 1.58110056e-02,\n",
      "        2.31456663e-02, 2.72264361e-01]]), array([[1.89569220e-02, 3.18054438e-01, 5.06167114e-02, 8.96862030e-01,\n",
      "        1.62346847e-02, 5.36312582e-03, 5.93732744e-02, 8.73281806e-06,\n",
      "        4.43220488e-04, 6.01017058e-01, 3.36866906e-05, 2.38104761e-01,\n",
      "        7.24052966e-01, 1.58710387e-02, 4.73167241e-01, 1.49487212e-01,\n",
      "        1.25084877e-01, 1.29541988e-02, 1.54107437e-02, 3.62559850e-03,\n",
      "        1.40331201e-02, 6.56470610e-03, 4.79944889e-03, 9.71790962e-03,\n",
      "        1.93990782e-01, 9.81705070e-01, 7.30550615e-04, 5.22534430e-01,\n",
      "        1.12285269e-02, 9.62291002e-01],\n",
      "       [1.10471901e-03, 3.32553089e-02, 1.45845301e-02, 3.06717455e-01,\n",
      "        2.07151356e-03, 9.99546945e-01, 1.01174521e-06, 4.47154850e-01,\n",
      "        3.65818739e-02, 3.93928902e-04, 1.38146831e-02, 9.91590440e-01,\n",
      "        3.04260880e-07, 1.45845406e-03, 5.75833581e-02, 4.32765990e-01,\n",
      "        5.27212434e-02, 4.26684394e-02, 2.77640851e-04, 8.50909054e-01,\n",
      "        7.90746570e-01, 2.12123722e-01, 9.33222353e-01, 1.09105895e-05,\n",
      "        1.02014840e-03, 7.29948878e-01, 2.13360443e-04, 9.66654778e-01,\n",
      "        8.47657793e-06, 2.25194860e-02],\n",
      "       [1.84649944e-01, 1.20498359e-01, 4.19103354e-01, 3.88162062e-02,\n",
      "        1.08231373e-01, 3.39547195e-03, 1.27965389e-02, 5.65023907e-03,\n",
      "        9.18539837e-02, 1.88217163e-02, 5.19229565e-04, 9.62885916e-01,\n",
      "        2.68891096e-01, 4.07489315e-02, 1.42918527e-01, 7.47739077e-02,\n",
      "        8.52285847e-02, 2.04431340e-01, 1.05931656e-02, 1.65794432e-01,\n",
      "        4.11179774e-02, 5.82208753e-01, 1.88943604e-03, 1.16497139e-02,\n",
      "        6.27697587e-01, 3.36003341e-02, 3.77177275e-05, 6.06832206e-01,\n",
      "        2.18831981e-03, 2.49546068e-03]]), array([[9.29660380e-01, 2.85668582e-01, 5.82477331e-01, 1.00441724e-01,\n",
      "        9.74361360e-01, 6.35264277e-01, 9.40595627e-01, 9.24704850e-01,\n",
      "        9.99495625e-01, 2.72164345e-01, 9.98308539e-01, 7.61793733e-01,\n",
      "        2.75936544e-01, 4.19380486e-01, 7.57566243e-02, 8.46419811e-01,\n",
      "        8.05767119e-01, 2.01487124e-01, 6.60847783e-01, 2.46682391e-01,\n",
      "        9.29770589e-01, 3.14913914e-02, 5.05484223e-01, 9.48139548e-01,\n",
      "        7.43448436e-01, 1.82891116e-02, 8.50833416e-01, 4.57636327e-01,\n",
      "        9.46540058e-01, 1.92935322e-03],\n",
      "       [9.92053628e-01, 2.62618303e-01, 4.43104953e-02, 6.92617834e-01,\n",
      "        6.37770653e-01, 4.52150998e-04, 9.90828037e-01, 3.95729423e-01,\n",
      "        9.57394123e-01, 1.37727847e-03, 2.48521596e-01, 8.40690732e-03,\n",
      "        9.99996424e-01, 9.11032021e-01, 8.43771815e-01, 5.58559597e-01,\n",
      "        4.32249874e-01, 8.99116158e-01, 4.80538644e-02, 1.37762964e-01,\n",
      "        1.98981002e-01, 7.85902679e-01, 6.58149272e-02, 7.80501842e-01,\n",
      "        9.95465696e-01, 2.70029336e-01, 1.59730285e-01, 2.41203755e-02,\n",
      "        6.71330700e-03, 5.83411694e-01],\n",
      "       [8.15200925e-01, 8.75670552e-01, 5.41359544e-01, 2.97728568e-01,\n",
      "        7.47009635e-01, 2.74608582e-01, 9.86650825e-01, 9.79620636e-01,\n",
      "        8.11616957e-01, 7.17940986e-01, 9.86893773e-01, 3.66523303e-02,\n",
      "        7.31067836e-01, 8.27706695e-01, 1.74302652e-01, 3.65970314e-01,\n",
      "        8.82477880e-01, 6.81134105e-01, 4.15249228e-01, 7.45945156e-01,\n",
      "        9.14317310e-01, 3.32476825e-01, 1.31620048e-02, 6.26883984e-01,\n",
      "        2.57806510e-01, 9.54689562e-01, 5.01566589e-01, 3.77356768e-01,\n",
      "        9.74665999e-01, 7.25240171e-01]]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras_model = KerasBacktestModel(n_hidden_layers = 0,\n",
    "                                 reg_penalty = 0.0,\n",
    "                                 verbose=True,\n",
    "                                 epochs=2000)\n",
    "\n",
    "backtestmodel = BacktestModel(X, Y_class, \n",
    "                              model=keras_model, \n",
    "                              coef_dict_param=coef_dict_all, \n",
    "                              startindex=FIRST_TRAIN_MONTHS)\n",
    "print(backtestmodel.fit_predict(121, npredict=3, verbose=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49083820662913263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.evaluate(X,Y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run linear model,compare results\n",
    "def create_keras_model(n_hidden_layers, layer_size, reg_penalty, verbose=False):\n",
    "    return KerasBacktestModel(n_hidden_layers = n_hidden_layers,\n",
    "                              hidden_layer_size = layer_size,\n",
    "                              reg_penalty = reg_penalty,\n",
    "                              epochs=500,\n",
    "                              verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:56:37 Running 27 experiments\n",
      "14:56:37 Running experiment 1 of 27\n",
      "14:56:37 n_hidden_layers = 1, hidden_layer_size = 1, reg_penalty = 0.000000\n",
      "14:56:38 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 1s 8ms/step\n",
      "137/137 [==============================] - 0s 574us/step\n",
      "274/274 [==============================] - 0s 515us/step\n",
      "137/137 [==============================] - 0s 562us/step\n",
      "411/411 [==============================] - 0s 514us/step\n",
      "137/137 [==============================] - 0s 572us/step\n",
      "548/548 [==============================] - 0s 531us/step\n",
      "136/136 [==============================] - 0s 548us/step\n",
      ".\n",
      "MSE across all predictions: 1.0106\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5795\n",
      "Food: long 36 times, short 0 times, total 36 times\n",
      "Beer: long 250 times, short 0 times, total 250 times\n",
      "Smoke: long 189 times, short 0 times, total 189 times\n",
      "Games: long 83 times, short 0 times, total 83 times\n",
      "Books: long 64 times, short 0 times, total 64 times\n",
      "Hshld: long 125 times, short 98 times, total 223 times\n",
      "Clths: long 434 times, short 9 times, total 443 times\n",
      "Hlth: long 416 times, short 0 times, total 416 times\n",
      "Chems: long 0 times, short 288 times, total 288 times\n",
      "Txtls: long 308 times, short 53 times, total 361 times\n",
      "Cnstr: long 0 times, short 171 times, total 171 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 99 times, total 99 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 180 times, total 180 times\n",
      "Carry: long 6 times, short 113 times, total 119 times\n",
      "Mines: long 141 times, short 39 times, total 180 times\n",
      "Coal: long 235 times, short 4 times, total 239 times\n",
      "Oil: long 343 times, short 48 times, total 391 times\n",
      "Util: long 10 times, short 114 times, total 124 times\n",
      "Telcm: long 9 times, short 449 times, total 458 times\n",
      "Servs: long 84 times, short 0 times, total 84 times\n",
      "BusEq: long 34 times, short 244 times, total 278 times\n",
      "Paper: long 0 times, short 250 times, total 250 times\n",
      "Trans: long 0 times, short 13 times, total 13 times\n",
      "Whlsl: long 233 times, short 0 times, total 233 times\n",
      "Rtail: long 96 times, short 127 times, total 223 times\n",
      "Meals: long 56 times, short 98 times, total 154 times\n",
      "Fin: long 124 times, short 0 times, total 124 times\n",
      "Other: long 0 times, short 333 times, total 333 times\n",
      "(1, 1, 0.0) Quantile score: 0.000966\n",
      "(1, 1, 0.0) Sharpe: -0.020003\n",
      "15:17:13 Running experiment 2 of 27\n",
      "15:17:13 n_hidden_layers = 1, hidden_layer_size = 1, reg_penalty = 0.010000\n",
      "15:17:14 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 1s 10ms/step\n",
      "137/137 [==============================] - 0s 563us/step\n",
      "274/274 [==============================] - 0s 547us/step\n",
      "137/137 [==============================] - 0s 608us/step\n",
      "411/411 [==============================] - 0s 479us/step\n",
      "137/137 [==============================] - 0s 541us/step\n",
      "548/548 [==============================] - 0s 490us/step\n",
      "136/136 [==============================] - 0s 541us/step\n",
      ".\n",
      "MSE across all predictions: 1.0063\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5728\n",
      "Food: long 12 times, short 0 times, total 12 times\n",
      "Beer: long 256 times, short 25 times, total 281 times\n",
      "Smoke: long 373 times, short 49 times, total 422 times\n",
      "Games: long 346 times, short 49 times, total 395 times\n",
      "Books: long 50 times, short 0 times, total 50 times\n",
      "Hshld: long 108 times, short 0 times, total 108 times\n",
      "Clths: long 355 times, short 0 times, total 355 times\n",
      "Hlth: long 470 times, short 39 times, total 509 times\n",
      "Chems: long 0 times, short 385 times, total 385 times\n",
      "Txtls: long 66 times, short 0 times, total 66 times\n",
      "Cnstr: long 9 times, short 339 times, total 348 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 267 times, total 267 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 131 times, total 131 times\n",
      "Carry: long 5 times, short 115 times, total 120 times\n",
      "Mines: long 156 times, short 8 times, total 164 times\n",
      "Coal: long 124 times, short 124 times, total 248 times\n",
      "Oil: long 313 times, short 0 times, total 313 times\n",
      "Util: long 0 times, short 39 times, total 39 times\n",
      "Telcm: long 31 times, short 356 times, total 387 times\n",
      "Servs: long 63 times, short 0 times, total 63 times\n",
      "BusEq: long 4 times, short 308 times, total 312 times\n",
      "Paper: long 0 times, short 130 times, total 130 times\n",
      "Trans: long 24 times, short 19 times, total 43 times\n",
      "Whlsl: long 371 times, short 1 times, total 372 times\n",
      "Rtail: long 129 times, short 118 times, total 247 times\n",
      "Meals: long 2 times, short 0 times, total 2 times\n",
      "Fin: long 9 times, short 0 times, total 9 times\n",
      "Other: long 0 times, short 228 times, total 228 times\n",
      "(1, 1, 0.01) Quantile score: 0.000570\n",
      "(1, 1, 0.01) Sharpe: -0.046705\n",
      "15:37:59 Running experiment 3 of 27\n",
      "15:37:59 n_hidden_layers = 1, hidden_layer_size = 1, reg_penalty = 1.000000\n",
      "15:38:00 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 2s 12ms/step\n",
      "137/137 [==============================] - 0s 562us/step\n",
      "274/274 [==============================] - 0s 497us/step\n",
      "137/137 [==============================] - 0s 557us/step\n",
      "411/411 [==============================] - 0s 482us/step\n",
      "137/137 [==============================] - 0s 579us/step\n",
      "548/548 [==============================] - 0s 523us/step\n",
      "136/136 [==============================] - 0s 539us/step\n",
      ".\n",
      "MSE across all predictions: 0.9995\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5621\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 0 times, short 0 times, total 0 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 411 times, total 411 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 409 times, total 409 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 135 times, total 135 times\n",
      "(1, 1, 1) Quantile score: 0.001210\n",
      "(1, 1, 1) Sharpe: -0.111656\n",
      "15:58:46 Running experiment 4 of 27\n",
      "15:58:46 n_hidden_layers = 1, hidden_layer_size = 2, reg_penalty = 0.000000\n",
      "15:58:47 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 2s 14ms/step\n",
      "137/137 [==============================] - 0s 583us/step\n",
      "274/274 [==============================] - 0s 510us/step\n",
      "137/137 [==============================] - 0s 535us/step\n",
      "411/411 [==============================] - 0s 499us/step\n",
      "137/137 [==============================] - 0s 592us/step\n",
      "548/548 [==============================] - 0s 492us/step\n",
      "136/136 [==============================] - 0s 534us/step\n",
      ".\n",
      "MSE across all predictions: 1.0217\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5969\n",
      "Food: long 28 times, short 1 times, total 29 times\n",
      "Beer: long 214 times, short 68 times, total 282 times\n",
      "Smoke: long 375 times, short 65 times, total 440 times\n",
      "Games: long 115 times, short 96 times, total 211 times\n",
      "Books: long 120 times, short 0 times, total 120 times\n",
      "Hshld: long 116 times, short 193 times, total 309 times\n",
      "Clths: long 315 times, short 1 times, total 316 times\n",
      "Hlth: long 184 times, short 0 times, total 184 times\n",
      "Chems: long 0 times, short 207 times, total 207 times\n",
      "Txtls: long 140 times, short 3 times, total 143 times\n",
      "Cnstr: long 0 times, short 72 times, total 72 times\n",
      "Steel: long 0 times, short 386 times, total 386 times\n",
      "FabPr: long 0 times, short 65 times, total 65 times\n",
      "ElcEq: long 21 times, short 85 times, total 106 times\n",
      "Autos: long 167 times, short 235 times, total 402 times\n",
      "Carry: long 65 times, short 121 times, total 186 times\n",
      "Mines: long 188 times, short 72 times, total 260 times\n",
      "Coal: long 297 times, short 57 times, total 354 times\n",
      "Oil: long 371 times, short 74 times, total 445 times\n",
      "Util: long 95 times, short 63 times, total 158 times\n",
      "Telcm: long 0 times, short 285 times, total 285 times\n",
      "Servs: long 15 times, short 0 times, total 15 times\n",
      "BusEq: long 52 times, short 307 times, total 359 times\n",
      "Paper: long 0 times, short 220 times, total 220 times\n",
      "Trans: long 40 times, short 17 times, total 57 times\n",
      "Whlsl: long 66 times, short 8 times, total 74 times\n",
      "Rtail: long 91 times, short 42 times, total 133 times\n",
      "Meals: long 100 times, short 157 times, total 257 times\n",
      "Fin: long 0 times, short 13 times, total 13 times\n",
      "Other: long 101 times, short 363 times, total 464 times\n",
      "(1, 2, 0.0) Quantile score: 0.003099\n",
      "(1, 2, 0.0) Sharpe: -0.033453\n",
      "16:19:35 Running experiment 5 of 27\n",
      "16:19:35 n_hidden_layers = 1, hidden_layer_size = 2, reg_penalty = 0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:19:36 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 2s 16ms/step\n",
      "137/137 [==============================] - 0s 564us/step\n",
      "274/274 [==============================] - 0s 501us/step\n",
      "137/137 [==============================] - 0s 541us/step\n",
      "411/411 [==============================] - 0s 490us/step\n",
      "137/137 [==============================] - 0s 553us/step\n",
      "548/548 [==============================] - 0s 518us/step\n",
      "136/136 [==============================] - 0s 544us/step\n",
      ".\n",
      "MSE across all predictions: 1.0157\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5876\n",
      "Food: long 304 times, short 45 times, total 349 times\n",
      "Beer: long 220 times, short 38 times, total 258 times\n",
      "Smoke: long 319 times, short 46 times, total 365 times\n",
      "Games: long 124 times, short 97 times, total 221 times\n",
      "Books: long 44 times, short 0 times, total 44 times\n",
      "Hshld: long 75 times, short 37 times, total 112 times\n",
      "Clths: long 228 times, short 5 times, total 233 times\n",
      "Hlth: long 408 times, short 3 times, total 411 times\n",
      "Chems: long 0 times, short 254 times, total 254 times\n",
      "Txtls: long 36 times, short 43 times, total 79 times\n",
      "Cnstr: long 18 times, short 91 times, total 109 times\n",
      "Steel: long 26 times, short 498 times, total 524 times\n",
      "FabPr: long 15 times, short 130 times, total 145 times\n",
      "ElcEq: long 28 times, short 0 times, total 28 times\n",
      "Autos: long 74 times, short 195 times, total 269 times\n",
      "Carry: long 90 times, short 286 times, total 376 times\n",
      "Mines: long 77 times, short 120 times, total 197 times\n",
      "Coal: long 135 times, short 16 times, total 151 times\n",
      "Oil: long 352 times, short 14 times, total 366 times\n",
      "Util: long 80 times, short 87 times, total 167 times\n",
      "Telcm: long 0 times, short 308 times, total 308 times\n",
      "Servs: long 73 times, short 0 times, total 73 times\n",
      "BusEq: long 80 times, short 307 times, total 387 times\n",
      "Paper: long 6 times, short 40 times, total 46 times\n",
      "Trans: long 19 times, short 96 times, total 115 times\n",
      "Whlsl: long 94 times, short 12 times, total 106 times\n",
      "Rtail: long 248 times, short 79 times, total 327 times\n",
      "Meals: long 40 times, short 0 times, total 40 times\n",
      "Fin: long 1 times, short 49 times, total 50 times\n",
      "Other: long 62 times, short 380 times, total 442 times\n",
      "(1, 2, 0.01) Quantile score: 0.001606\n",
      "(1, 2, 0.01) Sharpe: -0.226896\n",
      "16:40:30 Running experiment 6 of 27\n",
      "16:40:30 n_hidden_layers = 1, hidden_layer_size = 2, reg_penalty = 1.000000\n",
      "16:40:32 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 2s 18ms/step\n",
      "137/137 [==============================] - 0s 570us/step\n",
      "274/274 [==============================] - 0s 504us/step\n",
      "137/137 [==============================] - 0s 583us/step\n",
      "411/411 [==============================] - 0s 505us/step\n",
      "137/137 [==============================] - 0s 608us/step\n",
      "548/548 [==============================] - 0s 507us/step\n",
      "136/136 [==============================] - 0s 548us/step\n",
      ".\n",
      "MSE across all predictions: 1.0033\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5681\n",
      "Food: long 67 times, short 0 times, total 67 times\n",
      "Beer: long 185 times, short 0 times, total 185 times\n",
      "Smoke: long 250 times, short 71 times, total 321 times\n",
      "Games: long 241 times, short 54 times, total 295 times\n",
      "Books: long 170 times, short 0 times, total 170 times\n",
      "Hshld: long 132 times, short 83 times, total 215 times\n",
      "Clths: long 193 times, short 0 times, total 193 times\n",
      "Hlth: long 356 times, short 0 times, total 356 times\n",
      "Chems: long 0 times, short 407 times, total 407 times\n",
      "Txtls: long 193 times, short 58 times, total 251 times\n",
      "Cnstr: long 0 times, short 242 times, total 242 times\n",
      "Steel: long 0 times, short 505 times, total 505 times\n",
      "FabPr: long 0 times, short 155 times, total 155 times\n",
      "ElcEq: long 99 times, short 1 times, total 100 times\n",
      "Autos: long 10 times, short 100 times, total 110 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 156 times, short 134 times, total 290 times\n",
      "Coal: long 196 times, short 83 times, total 279 times\n",
      "Oil: long 220 times, short 0 times, total 220 times\n",
      "Util: long 115 times, short 201 times, total 316 times\n",
      "Telcm: long 0 times, short 337 times, total 337 times\n",
      "Servs: long 97 times, short 0 times, total 97 times\n",
      "BusEq: long 0 times, short 192 times, total 192 times\n",
      "Paper: long 0 times, short 83 times, total 83 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 213 times, short 0 times, total 213 times\n",
      "Rtail: long 94 times, short 78 times, total 172 times\n",
      "Meals: long 186 times, short 135 times, total 321 times\n",
      "Fin: long 76 times, short 17 times, total 93 times\n",
      "Other: long 27 times, short 203 times, total 230 times\n",
      "(1, 2, 1) Quantile score: 0.003160\n",
      "(1, 2, 1) Sharpe: 0.163102\n",
      "17:01:33 Running experiment 7 of 27\n",
      "17:01:33 n_hidden_layers = 1, hidden_layer_size = 4, reg_penalty = 0.000000\n",
      "17:01:34 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 3s 20ms/step\n",
      "137/137 [==============================] - 0s 549us/step\n",
      "274/274 [==============================] - 0s 496us/step\n",
      "137/137 [==============================] - 0s 545us/step\n",
      "411/411 [==============================] - 0s 507us/step\n",
      "137/137 [==============================] - 0s 576us/step\n",
      "548/548 [==============================] - 0s 516us/step\n",
      "136/136 [==============================] - 0s 559us/step\n",
      ".\n",
      "MSE across all predictions: 1.0303\n",
      "Variance: 0.6398\n",
      "R-squared: -0.6102\n",
      "Food: long 103 times, short 62 times, total 165 times\n",
      "Beer: long 202 times, short 53 times, total 255 times\n",
      "Smoke: long 189 times, short 40 times, total 229 times\n",
      "Games: long 150 times, short 93 times, total 243 times\n",
      "Books: long 158 times, short 71 times, total 229 times\n",
      "Hshld: long 84 times, short 66 times, total 150 times\n",
      "Clths: long 283 times, short 74 times, total 357 times\n",
      "Hlth: long 242 times, short 21 times, total 263 times\n",
      "Chems: long 12 times, short 243 times, total 255 times\n",
      "Txtls: long 218 times, short 117 times, total 335 times\n",
      "Cnstr: long 8 times, short 68 times, total 76 times\n",
      "Steel: long 7 times, short 348 times, total 355 times\n",
      "FabPr: long 13 times, short 68 times, total 81 times\n",
      "ElcEq: long 106 times, short 68 times, total 174 times\n",
      "Autos: long 115 times, short 139 times, total 254 times\n",
      "Carry: long 175 times, short 197 times, total 372 times\n",
      "Mines: long 76 times, short 83 times, total 159 times\n",
      "Coal: long 150 times, short 198 times, total 348 times\n",
      "Oil: long 157 times, short 50 times, total 207 times\n",
      "Util: long 120 times, short 137 times, total 257 times\n",
      "Telcm: long 85 times, short 238 times, total 323 times\n",
      "Servs: long 129 times, short 51 times, total 180 times\n",
      "BusEq: long 66 times, short 229 times, total 295 times\n",
      "Paper: long 24 times, short 68 times, total 92 times\n",
      "Trans: long 28 times, short 117 times, total 145 times\n",
      "Whlsl: long 158 times, short 77 times, total 235 times\n",
      "Rtail: long 63 times, short 71 times, total 134 times\n",
      "Meals: long 77 times, short 58 times, total 135 times\n",
      "Fin: long 13 times, short 6 times, total 19 times\n",
      "Other: long 65 times, short 165 times, total 230 times\n",
      "(1, 4, 0.0) Quantile score: 0.004013\n",
      "(1, 4, 0.0) Sharpe: 0.308034\n",
      "17:22:38 Running experiment 8 of 27\n",
      "17:22:38 n_hidden_layers = 1, hidden_layer_size = 4, reg_penalty = 0.010000\n",
      "17:22:39 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 3s 23ms/step\n",
      "137/137 [==============================] - 0s 560us/step\n",
      "274/274 [==============================] - 0s 494us/step\n",
      "137/137 [==============================] - 0s 589us/step\n",
      "411/411 [==============================] - 0s 502us/step\n",
      "137/137 [==============================] - 0s 568us/step\n",
      "548/548 [==============================] - 0s 498us/step\n",
      "136/136 [==============================] - 0s 562us/step\n",
      ".\n",
      "MSE across all predictions: 1.0271\n",
      "Variance: 0.6398\n",
      "R-squared: -0.6053\n",
      "Food: long 57 times, short 54 times, total 111 times\n",
      "Beer: long 180 times, short 26 times, total 206 times\n",
      "Smoke: long 253 times, short 111 times, total 364 times\n",
      "Games: long 140 times, short 178 times, total 318 times\n",
      "Books: long 86 times, short 25 times, total 111 times\n",
      "Hshld: long 125 times, short 85 times, total 210 times\n",
      "Clths: long 78 times, short 3 times, total 81 times\n",
      "Hlth: long 305 times, short 24 times, total 329 times\n",
      "Chems: long 29 times, short 198 times, total 227 times\n",
      "Txtls: long 108 times, short 36 times, total 144 times\n",
      "Cnstr: long 10 times, short 173 times, total 183 times\n",
      "Steel: long 5 times, short 342 times, total 347 times\n",
      "FabPr: long 0 times, short 36 times, total 36 times\n",
      "ElcEq: long 46 times, short 29 times, total 75 times\n",
      "Autos: long 78 times, short 162 times, total 240 times\n",
      "Carry: long 7 times, short 116 times, total 123 times\n",
      "Mines: long 134 times, short 35 times, total 169 times\n",
      "Coal: long 262 times, short 85 times, total 347 times\n",
      "Oil: long 334 times, short 100 times, total 434 times\n",
      "Util: long 267 times, short 167 times, total 434 times\n",
      "Telcm: long 71 times, short 270 times, total 341 times\n",
      "Servs: long 49 times, short 1 times, total 50 times\n",
      "BusEq: long 56 times, short 196 times, total 252 times\n",
      "Paper: long 0 times, short 24 times, total 24 times\n",
      "Trans: long 42 times, short 85 times, total 127 times\n",
      "Whlsl: long 147 times, short 98 times, total 245 times\n",
      "Rtail: long 107 times, short 73 times, total 180 times\n",
      "Meals: long 140 times, short 193 times, total 333 times\n",
      "Fin: long 35 times, short 70 times, total 105 times\n",
      "Other: long 125 times, short 281 times, total 406 times\n",
      "(1, 4, 0.01) Quantile score: 0.003464\n",
      "(1, 4, 0.01) Sharpe: 0.038674\n",
      "17:43:37 Running experiment 9 of 27\n",
      "17:43:37 n_hidden_layers = 1, hidden_layer_size = 4, reg_penalty = 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:43:38 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 3s 24ms/step\n",
      "137/137 [==============================] - 0s 565us/step\n",
      "274/274 [==============================] - 0s 545us/step\n",
      "137/137 [==============================] - 0s 623us/step\n",
      "411/411 [==============================] - 0s 483us/step\n",
      "137/137 [==============================] - 0s 541us/step\n",
      "137/137 [==============================] - 4s 26ms/step\n",
      "137/137 [==============================] - 0s 589us/step\n",
      "274/274 [==============================] - 0s 504us/step\n",
      "137/137 [==============================] - 0s 535us/step\n",
      "411/411 [==============================] - 0s 498us/step\n",
      "137/137 [==============================] - 0s 580us/step\n",
      "548/548 [==============================] - 0s 532us/step\n",
      "136/136 [==============================] - 0s 555us/step\n",
      ".\n",
      "MSE across all predictions: 1.0046\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5701\n",
      "Food: long 0 times, short 3 times, total 3 times\n",
      "Beer: long 248 times, short 0 times, total 248 times\n",
      "Smoke: long 362 times, short 66 times, total 428 times\n",
      "Games: long 247 times, short 44 times, total 291 times\n",
      "Books: long 148 times, short 6 times, total 154 times\n",
      "Hshld: long 110 times, short 49 times, total 159 times\n",
      "Clths: long 350 times, short 2 times, total 352 times\n",
      "Hlth: long 481 times, short 12 times, total 493 times\n",
      "Chems: long 0 times, short 403 times, total 403 times\n",
      "Txtls: long 51 times, short 0 times, total 51 times\n",
      "Cnstr: long 0 times, short 124 times, total 124 times\n",
      "Steel: long 0 times, short 509 times, total 509 times\n",
      "FabPr: long 0 times, short 237 times, total 237 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 21 times, short 128 times, total 149 times\n",
      "Carry: long 41 times, short 112 times, total 153 times\n",
      "Mines: long 79 times, short 247 times, total 326 times\n",
      "Coal: long 128 times, short 119 times, total 247 times\n",
      "Oil: long 193 times, short 0 times, total 193 times\n",
      "Util: long 2 times, short 104 times, total 106 times\n",
      "Telcm: long 7 times, short 363 times, total 370 times\n",
      "Servs: long 243 times, short 45 times, total 288 times\n",
      "BusEq: long 105 times, short 173 times, total 278 times\n",
      "Paper: long 37 times, short 361 times, total 398 times\n",
      "Trans: long 8 times, short 1 times, total 9 times\n",
      "Whlsl: long 249 times, short 0 times, total 249 times\n",
      "Rtail: long 113 times, short 121 times, total 234 times\n",
      "Meals: long 21 times, short 0 times, total 21 times\n",
      "Fin: long 32 times, short 0 times, total 32 times\n",
      "Other: long 0 times, short 47 times, total 47 times\n",
      "(2, 1, 0.0) Quantile score: 0.002398\n",
      "(2, 1, 0.0) Sharpe: 0.075309\n",
      "18:25:51 Running experiment 11 of 27\n",
      "18:25:51 n_hidden_layers = 2, hidden_layer_size = 1, reg_penalty = 0.010000\n",
      "18:25:53 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 4s 28ms/step\n",
      "137/137 [==============================] - 0s 593us/step\n",
      "274/274 [==============================] - 0s 524us/step\n",
      "137/137 [==============================] - 0s 549us/step\n",
      "411/411 [==============================] - 0s 507us/step\n",
      "137/137 [==============================] - 0s 565us/step\n",
      "548/548 [==============================] - 0s 527us/step\n",
      "136/136 [==============================] - 0s 544us/step\n",
      ".\n",
      "MSE across all predictions: 1.0017\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5656\n",
      "Food: long 125 times, short 0 times, total 125 times\n",
      "Beer: long 256 times, short 5 times, total 261 times\n",
      "Smoke: long 383 times, short 31 times, total 414 times\n",
      "Games: long 46 times, short 0 times, total 46 times\n",
      "Books: long 43 times, short 0 times, total 43 times\n",
      "Hshld: long 136 times, short 382 times, total 518 times\n",
      "Clths: long 375 times, short 0 times, total 375 times\n",
      "Hlth: long 398 times, short 0 times, total 398 times\n",
      "Chems: long 0 times, short 269 times, total 269 times\n",
      "Txtls: long 2 times, short 0 times, total 2 times\n",
      "Cnstr: long 0 times, short 127 times, total 127 times\n",
      "Steel: long 0 times, short 535 times, total 535 times\n",
      "FabPr: long 0 times, short 133 times, total 133 times\n",
      "ElcEq: long 8 times, short 0 times, total 8 times\n",
      "Autos: long 111 times, short 166 times, total 277 times\n",
      "Carry: long 2 times, short 120 times, total 122 times\n",
      "Mines: long 5 times, short 0 times, total 5 times\n",
      "Coal: long 246 times, short 9 times, total 255 times\n",
      "Oil: long 407 times, short 15 times, total 422 times\n",
      "Util: long 1 times, short 27 times, total 28 times\n",
      "Telcm: long 0 times, short 412 times, total 412 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 257 times, total 257 times\n",
      "Paper: long 0 times, short 11 times, total 11 times\n",
      "Trans: long 41 times, short 251 times, total 292 times\n",
      "Whlsl: long 254 times, short 0 times, total 254 times\n",
      "Rtail: long 113 times, short 11 times, total 124 times\n",
      "Meals: long 31 times, short 0 times, total 31 times\n",
      "Fin: long 131 times, short 21 times, total 152 times\n",
      "Other: long 25 times, short 494 times, total 519 times\n",
      "(2, 1, 0.01) Quantile score: 0.000844\n",
      "(2, 1, 0.01) Sharpe: 0.014342\n",
      "18:47:13 Running experiment 12 of 27\n",
      "18:47:13 n_hidden_layers = 2, hidden_layer_size = 1, reg_penalty = 1.000000\n",
      "18:47:14 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 4s 30ms/step\n",
      "137/137 [==============================] - 0s 572us/step\n",
      "274/274 [==============================] - 0s 564us/step\n",
      "137/137 [==============================] - 0s 618us/step\n",
      "411/411 [==============================] - 0s 493us/step\n",
      "137/137 [==============================] - 0s 547us/step\n",
      "548/548 [==============================] - 0s 495us/step\n",
      "136/136 [==============================] - 0s 561us/step\n",
      ".\n",
      "MSE across all predictions: 0.9996\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5623\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 135 times, short 0 times, total 135 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 0 times, total 0 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 0 times, short 0 times, total 0 times\n",
      "Other: long 0 times, short 272 times, total 272 times\n",
      "(2, 1, 1) Quantile score: 0.000935\n",
      "(2, 1, 1) Sharpe: -0.087380\n",
      "19:08:19 Running experiment 13 of 27\n",
      "19:08:19 n_hidden_layers = 2, hidden_layer_size = 2, reg_penalty = 0.000000\n",
      "19:08:22 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 4s 32ms/step\n",
      "137/137 [==============================] - 0s 625us/step\n",
      "274/274 [==============================] - 0s 547us/step\n",
      "137/137 [==============================] - 0s 564us/step\n",
      "411/411 [==============================] - 0s 488us/step\n",
      "137/137 [==============================] - 0s 544us/step\n",
      "548/548 [==============================] - 0s 502us/step\n",
      "136/136 [==============================] - 0s 525us/step\n",
      ".\n",
      "MSE across all predictions: 1.0033\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5682\n",
      "Food: long 1 times, short 0 times, total 1 times\n",
      "Beer: long 286 times, short 0 times, total 286 times\n",
      "Smoke: long 271 times, short 0 times, total 271 times\n",
      "Games: long 370 times, short 35 times, total 405 times\n",
      "Books: long 146 times, short 0 times, total 146 times\n",
      "Hshld: long 123 times, short 0 times, total 123 times\n",
      "Clths: long 254 times, short 1 times, total 255 times\n",
      "Hlth: long 415 times, short 0 times, total 415 times\n",
      "Chems: long 7 times, short 519 times, total 526 times\n",
      "Txtls: long 117 times, short 13 times, total 130 times\n",
      "Cnstr: long 0 times, short 374 times, total 374 times\n",
      "Steel: long 0 times, short 521 times, total 521 times\n",
      "FabPr: long 0 times, short 252 times, total 252 times\n",
      "ElcEq: long 22 times, short 0 times, total 22 times\n",
      "Autos: long 15 times, short 135 times, total 150 times\n",
      "Carry: long 0 times, short 124 times, total 124 times\n",
      "Mines: long 41 times, short 0 times, total 41 times\n",
      "Coal: long 159 times, short 117 times, total 276 times\n",
      "Oil: long 280 times, short 0 times, total 280 times\n",
      "Util: long 8 times, short 120 times, total 128 times\n",
      "Telcm: long 0 times, short 406 times, total 406 times\n",
      "Servs: long 251 times, short 31 times, total 282 times\n",
      "BusEq: long 0 times, short 257 times, total 257 times\n",
      "Paper: long 0 times, short 135 times, total 135 times\n",
      "Trans: long 0 times, short 8 times, total 8 times\n",
      "Whlsl: long 386 times, short 28 times, total 414 times\n",
      "Rtail: long 124 times, short 136 times, total 260 times\n",
      "Meals: long 0 times, short 12 times, total 12 times\n",
      "Fin: long 0 times, short 15 times, total 15 times\n",
      "Other: long 0 times, short 37 times, total 37 times\n",
      "(2, 2, 0.0) Quantile score: -0.000040\n",
      "(2, 2, 0.0) Sharpe: -0.124004\n",
      "19:29:38 Running experiment 14 of 27\n",
      "19:29:38 n_hidden_layers = 2, hidden_layer_size = 2, reg_penalty = 0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:39 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 5s 35ms/step\n",
      "137/137 [==============================] - 0s 570us/step\n",
      "274/274 [==============================] - 0s 519us/step\n",
      "137/137 [==============================] - 0s 570us/step\n",
      "411/411 [==============================] - 0s 480us/step\n",
      "137/137 [==============================] - 0s 545us/step\n",
      "548/548 [==============================] - 0s 498us/step\n",
      "136/136 [==============================] - 0s 550us/step\n",
      ".\n",
      "MSE across all predictions: 1.0059\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5721\n",
      "Food: long 5 times, short 0 times, total 5 times\n",
      "Beer: long 215 times, short 0 times, total 215 times\n",
      "Smoke: long 104 times, short 15 times, total 119 times\n",
      "Games: long 366 times, short 92 times, total 458 times\n",
      "Books: long 266 times, short 61 times, total 327 times\n",
      "Hshld: long 154 times, short 102 times, total 256 times\n",
      "Clths: long 383 times, short 68 times, total 451 times\n",
      "Hlth: long 135 times, short 0 times, total 135 times\n",
      "Chems: long 7 times, short 358 times, total 365 times\n",
      "Txtls: long 126 times, short 76 times, total 202 times\n",
      "Cnstr: long 0 times, short 144 times, total 144 times\n",
      "Steel: long 0 times, short 499 times, total 499 times\n",
      "FabPr: long 0 times, short 106 times, total 106 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 2 times, short 34 times, total 36 times\n",
      "Carry: long 0 times, short 102 times, total 102 times\n",
      "Mines: long 65 times, short 116 times, total 181 times\n",
      "Coal: long 198 times, short 118 times, total 316 times\n",
      "Oil: long 154 times, short 0 times, total 154 times\n",
      "Util: long 128 times, short 352 times, total 480 times\n",
      "Telcm: long 78 times, short 385 times, total 463 times\n",
      "Servs: long 285 times, short 36 times, total 321 times\n",
      "BusEq: long 2 times, short 156 times, total 158 times\n",
      "Paper: long 9 times, short 128 times, total 137 times\n",
      "Trans: long 0 times, short 18 times, total 18 times\n",
      "Whlsl: long 300 times, short 10 times, total 310 times\n",
      "Rtail: long 56 times, short 101 times, total 157 times\n",
      "Meals: long 200 times, short 112 times, total 312 times\n",
      "Fin: long 38 times, short 5 times, total 43 times\n",
      "Other: long 0 times, short 82 times, total 82 times\n",
      "(2, 2, 0.01) Quantile score: 0.003068\n",
      "(2, 2, 0.01) Sharpe: 0.273458\n",
      "19:50:56 Running experiment 15 of 27\n",
      "19:50:56 n_hidden_layers = 2, hidden_layer_size = 2, reg_penalty = 1.000000\n",
      "19:50:57 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 5s 36ms/step\n",
      "137/137 [==============================] - 0s 573us/step\n",
      "274/274 [==============================] - 0s 525us/step\n",
      "137/137 [==============================] - 0s 583us/step\n",
      "411/411 [==============================] - 0s 522us/step\n",
      "137/137 [==============================] - 0s 546us/step\n",
      "548/548 [==============================] - 0s 506us/step\n",
      "136/136 [==============================] - 0s 560us/step\n",
      ".\n",
      "MSE across all predictions: 0.9995\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5621\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 0 times, short 0 times, total 0 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 411 times, total 411 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 409 times, total 409 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 135 times, total 135 times\n",
      "(2, 2, 1) Quantile score: 0.001210\n",
      "(2, 2, 1) Sharpe: -0.111656\n",
      "20:12:17 Running experiment 16 of 27\n",
      "20:12:17 n_hidden_layers = 2, hidden_layer_size = 4, reg_penalty = 0.000000\n",
      "20:12:18 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 5s 40ms/step\n",
      "137/137 [==============================] - 0s 558us/step\n",
      "274/274 [==============================] - 0s 550us/step\n",
      "137/137 [==============================] - 0s 642us/step\n",
      "411/411 [==============================] - 0s 512us/step\n",
      "137/137 [==============================] - 0s 583us/step\n",
      "548/548 [==============================] - 0s 565us/step\n",
      "136/136 [==============================] - 0s 588us/step\n",
      ".\n",
      "MSE across all predictions: 1.0049\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5706\n",
      "Food: long 110 times, short 0 times, total 110 times\n",
      "Beer: long 212 times, short 28 times, total 240 times\n",
      "Smoke: long 317 times, short 35 times, total 352 times\n",
      "Games: long 97 times, short 95 times, total 192 times\n",
      "Books: long 109 times, short 9 times, total 118 times\n",
      "Hshld: long 117 times, short 50 times, total 167 times\n",
      "Clths: long 112 times, short 2 times, total 114 times\n",
      "Hlth: long 420 times, short 0 times, total 420 times\n",
      "Chems: long 6 times, short 332 times, total 338 times\n",
      "Txtls: long 114 times, short 1 times, total 115 times\n",
      "Cnstr: long 0 times, short 156 times, total 156 times\n",
      "Steel: long 0 times, short 497 times, total 497 times\n",
      "FabPr: long 0 times, short 121 times, total 121 times\n",
      "ElcEq: long 5 times, short 0 times, total 5 times\n",
      "Autos: long 22 times, short 139 times, total 161 times\n",
      "Carry: long 0 times, short 208 times, total 208 times\n",
      "Mines: long 123 times, short 92 times, total 215 times\n",
      "Coal: long 210 times, short 11 times, total 221 times\n",
      "Oil: long 324 times, short 47 times, total 371 times\n",
      "Util: long 290 times, short 103 times, total 393 times\n",
      "Telcm: long 9 times, short 232 times, total 241 times\n",
      "Servs: long 68 times, short 3 times, total 71 times\n",
      "BusEq: long 0 times, short 231 times, total 231 times\n",
      "Paper: long 0 times, short 71 times, total 71 times\n",
      "Trans: long 0 times, short 104 times, total 104 times\n",
      "Whlsl: long 221 times, short 18 times, total 239 times\n",
      "Rtail: long 108 times, short 18 times, total 126 times\n",
      "Meals: long 116 times, short 283 times, total 399 times\n",
      "Fin: long 98 times, short 9 times, total 107 times\n",
      "Other: long 68 times, short 381 times, total 449 times\n",
      "(2, 4, 0.0) Quantile score: 0.004287\n",
      "(2, 4, 0.0) Sharpe: 0.257697\n",
      "20:33:44 Running experiment 17 of 27\n",
      "20:33:44 n_hidden_layers = 2, hidden_layer_size = 4, reg_penalty = 0.010000\n",
      "20:33:45 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 6s 41ms/step\n",
      "137/137 [==============================] - 0s 608us/step\n",
      "274/274 [==============================] - 0s 532us/step\n",
      "137/137 [==============================] - 0s 587us/step\n",
      "411/411 [==============================] - 0s 542us/step\n",
      "137/137 [==============================] - 0s 656us/step\n",
      "548/548 [==============================] - 0s 548us/step\n",
      "136/136 [==============================] - 0s 582us/step\n",
      ".\n",
      "MSE across all predictions: 1.0173\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5899\n",
      "Food: long 223 times, short 61 times, total 284 times\n",
      "Beer: long 209 times, short 39 times, total 248 times\n",
      "Smoke: long 305 times, short 93 times, total 398 times\n",
      "Games: long 100 times, short 77 times, total 177 times\n",
      "Books: long 109 times, short 10 times, total 119 times\n",
      "Hshld: long 142 times, short 102 times, total 244 times\n",
      "Clths: long 75 times, short 0 times, total 75 times\n",
      "Hlth: long 307 times, short 9 times, total 316 times\n",
      "Chems: long 23 times, short 309 times, total 332 times\n",
      "Txtls: long 101 times, short 87 times, total 188 times\n",
      "Cnstr: long 17 times, short 86 times, total 103 times\n",
      "Steel: long 23 times, short 415 times, total 438 times\n",
      "FabPr: long 22 times, short 189 times, total 211 times\n",
      "ElcEq: long 46 times, short 3 times, total 49 times\n",
      "Autos: long 81 times, short 138 times, total 219 times\n",
      "Carry: long 51 times, short 178 times, total 229 times\n",
      "Mines: long 116 times, short 208 times, total 324 times\n",
      "Coal: long 142 times, short 71 times, total 213 times\n",
      "Oil: long 311 times, short 56 times, total 367 times\n",
      "Util: long 298 times, short 149 times, total 447 times\n",
      "Telcm: long 31 times, short 190 times, total 221 times\n",
      "Servs: long 63 times, short 0 times, total 63 times\n",
      "BusEq: long 39 times, short 243 times, total 282 times\n",
      "Paper: long 0 times, short 19 times, total 19 times\n",
      "Trans: long 29 times, short 48 times, total 77 times\n",
      "Whlsl: long 107 times, short 76 times, total 183 times\n",
      "Rtail: long 80 times, short 92 times, total 172 times\n",
      "Meals: long 98 times, short 97 times, total 195 times\n",
      "Fin: long 69 times, short 19 times, total 88 times\n",
      "Other: long 59 times, short 212 times, total 271 times\n",
      "(2, 4, 0.01) Quantile score: 0.003647\n",
      "(2, 4, 0.01) Sharpe: 0.005026\n",
      "20:55:16 Running experiment 18 of 27\n",
      "20:55:16 n_hidden_layers = 2, hidden_layer_size = 4, reg_penalty = 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:55:17 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 6s 44ms/step\n",
      "137/137 [==============================] - 0s 572us/step\n",
      "274/274 [==============================] - 0s 578us/step\n",
      "137/137 [==============================] - 0s 564us/step\n",
      "411/411 [==============================] - 0s 497us/step\n",
      "137/137 [==============================] - 0s 548us/step\n",
      "548/548 [==============================] - 0s 581us/step\n",
      "136/136 [==============================] - 0s 623us/step\n",
      ".\n",
      "MSE across all predictions: 0.9994\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5620\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 0 times, short 0 times, total 0 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 274 times, short 0 times, total 274 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 411 times, total 411 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 135 times, total 135 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 409 times, short 0 times, total 409 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 135 times, total 135 times\n",
      "(2, 4, 1) Quantile score: 0.000143\n",
      "(2, 4, 1) Sharpe: -0.122855\n",
      "21:17:01 Running experiment 19 of 27\n",
      "21:17:01 n_hidden_layers = 3, hidden_layer_size = 1, reg_penalty = 0.000000\n",
      "21:17:02 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 6s 46ms/step\n",
      "137/137 [==============================] - 0s 577us/step\n",
      "274/274 [==============================] - 0s 522us/step\n",
      "137/137 [==============================] - 0s 581us/step\n",
      "411/411 [==============================] - 0s 547us/step\n",
      "137/137 [==============================] - 0s 625us/step\n",
      "548/548 [==============================] - 0s 523us/step\n",
      "136/136 [==============================] - 0s 554us/step\n",
      ".\n",
      "MSE across all predictions: 0.9995\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5622\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 0 times, short 0 times, total 0 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 135 times, total 135 times\n",
      "(3, 1, 0.0) Quantile score: 0.001088\n",
      "(3, 1, 0.0) Sharpe: -0.120132\n",
      "21:38:44 Running experiment 20 of 27\n",
      "21:38:44 n_hidden_layers = 3, hidden_layer_size = 1, reg_penalty = 0.010000\n",
      "21:38:45 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 6s 47ms/step\n",
      "137/137 [==============================] - 0s 622us/step\n",
      "274/274 [==============================] - 0s 522us/step\n",
      "137/137 [==============================] - 0s 586us/step\n",
      "411/411 [==============================] - 0s 539us/step\n",
      "137/137 [==============================] - 0s 616us/step\n",
      "548/548 [==============================] - 0s 541us/step\n",
      "136/136 [==============================] - 0s 567us/step\n",
      ".\n",
      "MSE across all predictions: 0.9996\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5624\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 135 times, short 0 times, total 135 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 274 times, short 0 times, total 274 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 135 times, total 135 times\n",
      "(3, 1, 0.01) Quantile score: 0.001362\n",
      "(3, 1, 0.01) Sharpe: -0.129414\n",
      "22:00:32 Running experiment 21 of 27\n",
      "22:00:32 n_hidden_layers = 3, hidden_layer_size = 1, reg_penalty = 1.000000\n",
      "22:00:33 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 7s 50ms/step\n",
      "137/137 [==============================] - 0s 620us/step\n",
      "274/274 [==============================] - 0s 535us/step\n",
      "137/137 [==============================] - 0s 624us/step\n",
      "411/411 [==============================] - 0s 499us/step\n",
      "137/137 [==============================] - 0s 561us/step\n",
      "548/548 [==============================] - 0s 546us/step\n",
      "136/136 [==============================] - 0s 576us/step\n",
      ".\n",
      "MSE across all predictions: 0.9995\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5622\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 135 times, short 0 times, total 135 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 135 times, total 135 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 0 times, short 0 times, total 0 times\n",
      "Other: long 0 times, short 0 times, total 0 times\n",
      "(3, 1, 1) Quantile score: 0.001179\n",
      "(3, 1, 1) Sharpe: -0.109156\n",
      "22:22:28 Running experiment 22 of 27\n",
      "22:22:28 n_hidden_layers = 3, hidden_layer_size = 2, reg_penalty = 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:22:29 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 7s 52ms/step\n",
      "137/137 [==============================] - 0s 565us/step\n",
      "274/274 [==============================] - 0s 558us/step\n",
      "137/137 [==============================] - 0s 586us/step\n",
      "411/411 [==============================] - 0s 502us/step\n",
      "137/137 [==============================] - 0s 566us/step\n",
      "548/548 [==============================] - 0s 563us/step\n",
      "136/136 [==============================] - 0s 636us/step\n",
      ".\n",
      "MSE across all predictions: 0.9994\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5619\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 135 times, short 0 times, total 135 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 274 times, short 0 times, total 274 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 0 times, total 0 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 272 times, total 272 times\n",
      "(3, 2, 0.0) Quantile score: 0.000692\n",
      "(3, 2, 0.0) Sharpe: -0.122862\n",
      "22:44:13 Running experiment 23 of 27\n",
      "22:44:13 n_hidden_layers = 3, hidden_layer_size = 2, reg_penalty = 0.010000\n",
      "22:44:14 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 7s 55ms/step\n",
      "137/137 [==============================] - 0s 615us/step\n",
      "274/274 [==============================] - 0s 521us/step\n",
      "137/137 [==============================] - 0s 553us/step\n",
      "411/411 [==============================] - 0s 504us/step\n",
      "137/137 [==============================] - 0s 561us/step\n",
      "548/548 [==============================] - 0s 525us/step\n",
      "136/136 [==============================] - 0s 592us/step\n",
      ".\n",
      "MSE across all predictions: 1.0014\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5652\n",
      "Food: long 0 times, short 20 times, total 20 times\n",
      "Beer: long 233 times, short 40 times, total 273 times\n",
      "Smoke: long 365 times, short 41 times, total 406 times\n",
      "Games: long 341 times, short 58 times, total 399 times\n",
      "Books: long 340 times, short 47 times, total 387 times\n",
      "Hshld: long 105 times, short 23 times, total 128 times\n",
      "Clths: long 282 times, short 6 times, total 288 times\n",
      "Hlth: long 487 times, short 4 times, total 491 times\n",
      "Chems: long 29 times, short 485 times, total 514 times\n",
      "Txtls: long 62 times, short 0 times, total 62 times\n",
      "Cnstr: long 0 times, short 139 times, total 139 times\n",
      "Steel: long 8 times, short 520 times, total 528 times\n",
      "FabPr: long 6 times, short 346 times, total 352 times\n",
      "ElcEq: long 14 times, short 0 times, total 14 times\n",
      "Autos: long 30 times, short 126 times, total 156 times\n",
      "Carry: long 34 times, short 226 times, total 260 times\n",
      "Mines: long 136 times, short 105 times, total 241 times\n",
      "Coal: long 183 times, short 109 times, total 292 times\n",
      "Oil: long 96 times, short 0 times, total 96 times\n",
      "Util: long 35 times, short 33 times, total 68 times\n",
      "Telcm: long 0 times, short 384 times, total 384 times\n",
      "Servs: long 117 times, short 0 times, total 117 times\n",
      "BusEq: long 0 times, short 278 times, total 278 times\n",
      "Paper: long 0 times, short 10 times, total 10 times\n",
      "Trans: long 0 times, short 9 times, total 9 times\n",
      "Whlsl: long 246 times, short 0 times, total 246 times\n",
      "Rtail: long 110 times, short 129 times, total 239 times\n",
      "Meals: long 8 times, short 42 times, total 50 times\n",
      "Fin: long 9 times, short 0 times, total 9 times\n",
      "Other: long 0 times, short 96 times, total 96 times\n",
      "(3, 2, 0.01) Quantile score: 0.001514\n",
      "(3, 2, 0.01) Sharpe: -0.036521\n",
      "23:06:11 Running experiment 24 of 27\n",
      "23:06:11 n_hidden_layers = 3, hidden_layer_size = 2, reg_penalty = 1.000000\n",
      "23:06:12 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 8s 57ms/step\n",
      "137/137 [==============================] - 0s 558us/step\n",
      "274/274 [==============================] - 0s 543us/step\n",
      "137/137 [==============================] - 0s 570us/step\n",
      "411/411 [==============================] - 0s 503us/step\n",
      "137/137 [==============================] - 0s 564us/step\n",
      "548/548 [==============================] - 0s 536us/step\n",
      "136/136 [==============================] - 0s 602us/step\n",
      ".\n",
      "MSE across all predictions: 0.9994\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5620\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 0 times, short 0 times, total 0 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 137 times, total 137 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 135 times, total 135 times\n",
      "(3, 2, 1) Quantile score: 0.001088\n",
      "(3, 2, 1) Sharpe: -0.120132\n",
      "23:28:13 Running experiment 25 of 27\n",
      "23:28:13 n_hidden_layers = 3, hidden_layer_size = 4, reg_penalty = 0.000000\n",
      "23:28:14 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 8s 60ms/step\n",
      "137/137 [==============================] - 0s 625us/step\n",
      "274/274 [==============================] - 0s 523us/step\n",
      "137/137 [==============================] - 0s 575us/step\n",
      "411/411 [==============================] - 0s 566us/step\n",
      "137/137 [==============================] - 0s 578us/step\n",
      "548/548 [==============================] - 0s 541us/step\n",
      "136/136 [==============================] - 0s 589us/step\n",
      ".\n",
      "MSE across all predictions: 1.0053\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5712\n",
      "Food: long 286 times, short 27 times, total 313 times\n",
      "Beer: long 228 times, short 34 times, total 262 times\n",
      "Smoke: long 339 times, short 44 times, total 383 times\n",
      "Games: long 201 times, short 77 times, total 278 times\n",
      "Books: long 71 times, short 0 times, total 71 times\n",
      "Hshld: long 108 times, short 2 times, total 110 times\n",
      "Clths: long 73 times, short 0 times, total 73 times\n",
      "Hlth: long 416 times, short 9 times, total 425 times\n",
      "Chems: long 0 times, short 321 times, total 321 times\n",
      "Txtls: long 68 times, short 12 times, total 80 times\n",
      "Cnstr: long 0 times, short 196 times, total 196 times\n",
      "Steel: long 1 times, short 517 times, total 518 times\n",
      "FabPr: long 0 times, short 234 times, total 234 times\n",
      "ElcEq: long 7 times, short 16 times, total 23 times\n",
      "Autos: long 10 times, short 90 times, total 100 times\n",
      "Carry: long 4 times, short 220 times, total 224 times\n",
      "Mines: long 84 times, short 189 times, total 273 times\n",
      "Coal: long 138 times, short 93 times, total 231 times\n",
      "Oil: long 422 times, short 23 times, total 445 times\n",
      "Util: long 214 times, short 90 times, total 304 times\n",
      "Telcm: long 22 times, short 260 times, total 282 times\n",
      "Servs: long 115 times, short 1 times, total 116 times\n",
      "BusEq: long 1 times, short 259 times, total 260 times\n",
      "Paper: long 0 times, short 51 times, total 51 times\n",
      "Trans: long 3 times, short 123 times, total 126 times\n",
      "Whlsl: long 173 times, short 7 times, total 180 times\n",
      "Rtail: long 151 times, short 92 times, total 243 times\n",
      "Meals: long 37 times, short 10 times, total 47 times\n",
      "Fin: long 83 times, short 0 times, total 83 times\n",
      "Other: long 21 times, short 279 times, total 300 times\n",
      "(3, 4, 0.0) Quantile score: 0.004378\n",
      "(3, 4, 0.0) Sharpe: 0.057526\n",
      "23:50:10 Running experiment 26 of 27\n",
      "23:50:10 n_hidden_layers = 3, hidden_layer_size = 4, reg_penalty = 0.010000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:50:12 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 8s 61ms/step\n",
      "137/137 [==============================] - 0s 573us/step\n",
      "274/274 [==============================] - 0s 541us/step\n",
      "137/137 [==============================] - 0s 573us/step\n",
      "411/411 [==============================] - 0s 507us/step\n",
      "137/137 [==============================] - 0s 596us/step\n",
      "548/548 [==============================] - 0s 520us/step\n",
      "136/136 [==============================] - 0s 584us/step\n",
      ".\n",
      "MSE across all predictions: 1.0024\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5668\n",
      "Food: long 178 times, short 8 times, total 186 times\n",
      "Beer: long 203 times, short 22 times, total 225 times\n",
      "Smoke: long 310 times, short 38 times, total 348 times\n",
      "Games: long 140 times, short 91 times, total 231 times\n",
      "Books: long 96 times, short 25 times, total 121 times\n",
      "Hshld: long 135 times, short 108 times, total 243 times\n",
      "Clths: long 158 times, short 18 times, total 176 times\n",
      "Hlth: long 389 times, short 0 times, total 389 times\n",
      "Chems: long 17 times, short 332 times, total 349 times\n",
      "Txtls: long 56 times, short 6 times, total 62 times\n",
      "Cnstr: long 1 times, short 221 times, total 222 times\n",
      "Steel: long 5 times, short 492 times, total 497 times\n",
      "FabPr: long 0 times, short 150 times, total 150 times\n",
      "ElcEq: long 46 times, short 4 times, total 50 times\n",
      "Autos: long 144 times, short 147 times, total 291 times\n",
      "Carry: long 8 times, short 218 times, total 226 times\n",
      "Mines: long 77 times, short 97 times, total 174 times\n",
      "Coal: long 177 times, short 104 times, total 281 times\n",
      "Oil: long 388 times, short 60 times, total 448 times\n",
      "Util: long 266 times, short 80 times, total 346 times\n",
      "Telcm: long 31 times, short 335 times, total 366 times\n",
      "Servs: long 58 times, short 0 times, total 58 times\n",
      "BusEq: long 10 times, short 233 times, total 243 times\n",
      "Paper: long 0 times, short 5 times, total 5 times\n",
      "Trans: long 4 times, short 12 times, total 16 times\n",
      "Whlsl: long 126 times, short 10 times, total 136 times\n",
      "Rtail: long 108 times, short 12 times, total 120 times\n",
      "Meals: long 117 times, short 153 times, total 270 times\n",
      "Fin: long 20 times, short 6 times, total 26 times\n",
      "Other: long 8 times, short 289 times, total 297 times\n",
      "(3, 4, 0.01) Quantile score: 0.004835\n",
      "(3, 4, 0.01) Sharpe: 0.236504\n",
      "00:12:16 Running experiment 27 of 27\n",
      "00:12:16 n_hidden_layers = 3, hidden_layer_size = 4, reg_penalty = 1.000000\n",
      "00:12:18 Generate splits [137, 274, 411, 548, 684]\n",
      "137/137 [==============================] - 9s 63ms/step\n",
      "137/137 [==============================] - 0s 577us/step\n",
      "274/274 [==============================] - 0s 564us/step\n",
      "137/137 [==============================] - 0s 629us/step\n",
      "411/411 [==============================] - 0s 504us/step\n",
      "137/137 [==============================] - 0s 582us/step\n",
      "548/548 [==============================] - 0s 556us/step\n",
      "136/136 [==============================] - 0s 662us/step\n",
      ".\n",
      "MSE across all predictions: 0.9996\n",
      "Variance: 0.6398\n",
      "R-squared: -0.5623\n",
      "Food: long 0 times, short 0 times, total 0 times\n",
      "Beer: long 272 times, short 0 times, total 272 times\n",
      "Smoke: long 409 times, short 0 times, total 409 times\n",
      "Games: long 0 times, short 0 times, total 0 times\n",
      "Books: long 0 times, short 0 times, total 0 times\n",
      "Hshld: long 137 times, short 0 times, total 137 times\n",
      "Clths: long 409 times, short 0 times, total 409 times\n",
      "Hlth: long 546 times, short 0 times, total 546 times\n",
      "Chems: long 0 times, short 546 times, total 546 times\n",
      "Txtls: long 137 times, short 0 times, total 137 times\n",
      "Cnstr: long 0 times, short 411 times, total 411 times\n",
      "Steel: long 0 times, short 546 times, total 546 times\n",
      "FabPr: long 0 times, short 274 times, total 274 times\n",
      "ElcEq: long 0 times, short 0 times, total 0 times\n",
      "Autos: long 0 times, short 135 times, total 135 times\n",
      "Carry: long 0 times, short 137 times, total 137 times\n",
      "Mines: long 137 times, short 0 times, total 137 times\n",
      "Coal: long 137 times, short 137 times, total 274 times\n",
      "Oil: long 409 times, short 0 times, total 409 times\n",
      "Util: long 0 times, short 0 times, total 0 times\n",
      "Telcm: long 0 times, short 409 times, total 409 times\n",
      "Servs: long 137 times, short 0 times, total 137 times\n",
      "BusEq: long 0 times, short 272 times, total 272 times\n",
      "Paper: long 0 times, short 0 times, total 0 times\n",
      "Trans: long 0 times, short 0 times, total 0 times\n",
      "Whlsl: long 274 times, short 0 times, total 274 times\n",
      "Rtail: long 137 times, short 137 times, total 274 times\n",
      "Meals: long 0 times, short 0 times, total 0 times\n",
      "Fin: long 135 times, short 0 times, total 135 times\n",
      "Other: long 0 times, short 272 times, total 272 times\n",
      "(3, 4, 1) Quantile score: 0.000417\n",
      "(3, 4, 1) Sharpe: -0.113753\n"
     ]
    }
   ],
   "source": [
    "MODELPREFIX = \"NN\"\n",
    "\n",
    "n_hiddens = [1, 2, 3]\n",
    "layer_sizes = [1, 2, 4]\n",
    "reg_penalties = [0.0, 0.01, 1]\n",
    "hyperparameter_combos = list(product(n_hiddens, layer_sizes, reg_penalties))\n",
    "\n",
    "print(\"%s Running %d experiments\" % (time.strftime(\"%H:%M:%S\"), len(hyperparameter_combos)))\n",
    "# should really just use a list and convert to dataframe\n",
    "experiments = {}\n",
    "sharpes = {}\n",
    "quantile_scores = {}\n",
    "\n",
    "for counter, param_list in enumerate(hyperparameter_combos):\n",
    "    n_hidden_layers, layer_size, reg_penalty = param_list\n",
    "    print(\"%s Running experiment %d of %d\" % (time.strftime(\"%H:%M:%S\"), counter+1, len(hyperparameter_combos)))\n",
    "    key = (n_hidden_layers, layer_size, reg_penalty)\n",
    "    print(\"%s n_hidden_layers = %d, hidden_layer_size = %d, reg_penalty = %.6f\" % \n",
    "          (time.strftime(\"%H:%M:%S\"), n_hidden_layers, layer_size, reg_penalty))\n",
    "    \n",
    "    experiment_model = BacktestModel(X, Y_class, \n",
    "                                     create_keras_model(n_hidden_layers,layer_size,reg_penalty), \n",
    "                                     coef_dict_param=\"all\", \n",
    "                                     startindex=FIRST_TRAIN_MONTHS)\n",
    "    experiment_model.walkforward_xval(n_splits=5)\n",
    "    score = experiment_model.evaluate_predictions()\n",
    "    experiments[key] = score\n",
    "    quantile_score = experiment_model.evaluate_quantiles(chart=True, verbose=True, Y=Y)\n",
    "    quantile_scores[key] = quantile_score\n",
    "\n",
    "    experiment_model.gen_returns(calc_returns, verbose=False)\n",
    "    retframe = experiment_model.report_returns(start_date=start_date_str, freq='M')\n",
    "    sharpe = retframe.loc['yearly_sharpe']\n",
    "    sharpes[key] = sharpe.values[0]\n",
    "    \n",
    "    print(\"%s Quantile score: %f\" % (str(key), quantile_score))\n",
    "    print(\"%s Sharpe: %f\" % (str(key), sharpe))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden_layers</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>reg_penalty</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.999352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.999547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.999571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.999635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.001677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.003269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.003346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.004589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.004895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.005218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.005868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.006282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.010594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.015738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.017250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.021698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.027084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.030255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden_layers  layer_size  reg_penalty       MSE\n",
       "12                3           2         0.00  0.999352\n",
       "16                3           2         1.00  0.999369\n",
       "4                 2           4         1.00  0.999383\n",
       "23                2           2         1.00  0.999457\n",
       "20                1           1         1.00  0.999463\n",
       "15                3           1         1.00  0.999535\n",
       "18                3           1         0.00  0.999547\n",
       "24                2           1         1.00  0.999562\n",
       "2                 3           4         1.00  0.999571\n",
       "19                3           1         0.01  0.999635\n",
       "3                 3           2         0.01  1.001424\n",
       "26                2           1         0.01  1.001677\n",
       "17                3           4         0.01  1.002440\n",
       "13                1           2         1.00  1.003269\n",
       "25                2           2         0.00  1.003346\n",
       "22                2           1         0.00  1.004589\n",
       "6                 2           4         0.00  1.004895\n",
       "8                 1           4         1.00  1.005218\n",
       "1                 3           4         0.00  1.005275\n",
       "10                2           2         0.01  1.005868\n",
       "14                1           1         0.01  1.006282\n",
       "21                1           1         0.00  1.010594\n",
       "5                 1           2         0.01  1.015738\n",
       "0                 2           4         0.01  1.017250\n",
       "11                1           2         0.00  1.021698\n",
       "9                 1           4         0.01  1.027084\n",
       "7                 1           4         0.00  1.030255"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list and chart experiments\n",
    "flatlist = [list(l[0]) + [l[1]] for l in experiments.items()]\n",
    " \n",
    "lossframe = pd.DataFrame(flatlist, columns=[\"n_hidden_layers\", \"layer_size\", \"reg_penalty\", \"MSE\"])\n",
    "# one row didn't converge properly - messes up plotly scales\n",
    "#for i in list(lossframe.loc[lossframe['loss']> 1000].index):\n",
    "#    lossframe.at[i, 'loss'] = 100\n",
    "lossframe.sort_values(['MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden_layers</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>reg_penalty</th>\n",
       "      <th>sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.226896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.129414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.124004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.122862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.122855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.120132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.113753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.111656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.111656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.109156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.087380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.046705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.036521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.033453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.020003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.005026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.014342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.038674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.075309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.137273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.163102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.236504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.257697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.273458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.308034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden_layers  layer_size  reg_penalty    sharpe\n",
       "5                 1           2         0.01 -0.226896\n",
       "19                3           1         0.01 -0.129414\n",
       "25                2           2         0.00 -0.124004\n",
       "12                3           2         0.00 -0.122862\n",
       "4                 2           4         1.00 -0.122855\n",
       "18                3           1         0.00 -0.120132\n",
       "16                3           2         1.00 -0.120132\n",
       "2                 3           4         1.00 -0.113753\n",
       "20                1           1         1.00 -0.111656\n",
       "23                2           2         1.00 -0.111656\n",
       "15                3           1         1.00 -0.109156\n",
       "24                2           1         1.00 -0.087380\n",
       "14                1           1         0.01 -0.046705\n",
       "3                 3           2         0.01 -0.036521\n",
       "11                1           2         0.00 -0.033453\n",
       "21                1           1         0.00 -0.020003\n",
       "0                 2           4         0.01  0.005026\n",
       "26                2           1         0.01  0.014342\n",
       "9                 1           4         0.01  0.038674\n",
       "1                 3           4         0.00  0.057526\n",
       "22                2           1         0.00  0.075309\n",
       "8                 1           4         1.00  0.137273\n",
       "13                1           2         1.00  0.163102\n",
       "17                3           4         0.01  0.236504\n",
       "6                 2           4         0.00  0.257697\n",
       "10                2           2         0.01  0.273458\n",
       "7                 1           4         0.00  0.308034"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list sharpes\n",
    "flatlist = [list(l[0]) + [l[1]] for l in sharpes.items()]\n",
    " \n",
    "sharpeframe = pd.DataFrame(flatlist, columns=[\"n_hidden_layers\", \"layer_size\", \"reg_penalty\", \"sharpe\"])\n",
    "# one row didn't converge properly - messes up plotly scales\n",
    "#for i in list(lossframe.loc[lossframe['loss']> 1000].index):\n",
    "#    lossframe.at[i, 'loss'] = 100\n",
    "#list(l) +\n",
    "sharpeframe.sort_values(['sharpe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden_layers</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>reg_penalty</th>\n",
       "      <th>qscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.001088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.003068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.003099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.003160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.003464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.003647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.004835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden_layers  layer_size  reg_penalty    qscore\n",
       "25                2           2         0.00 -0.000040\n",
       "4                 2           4         1.00  0.000143\n",
       "2                 3           4         1.00  0.000417\n",
       "14                1           1         0.01  0.000570\n",
       "12                3           2         0.00  0.000692\n",
       "26                2           1         0.01  0.000844\n",
       "24                2           1         1.00  0.000935\n",
       "21                1           1         0.00  0.000966\n",
       "16                3           2         1.00  0.001088\n",
       "18                3           1         0.00  0.001088\n",
       "15                3           1         1.00  0.001179\n",
       "23                2           2         1.00  0.001210\n",
       "20                1           1         1.00  0.001210\n",
       "19                3           1         0.01  0.001362\n",
       "3                 3           2         0.01  0.001514\n",
       "5                 1           2         0.01  0.001606\n",
       "22                2           1         0.00  0.002398\n",
       "10                2           2         0.01  0.003068\n",
       "11                1           2         0.00  0.003099\n",
       "13                1           2         1.00  0.003160\n",
       "9                 1           4         0.01  0.003464\n",
       "0                 2           4         0.01  0.003647\n",
       "8                 1           4         1.00  0.003952\n",
       "7                 1           4         0.00  0.004013\n",
       "6                 2           4         0.00  0.004287\n",
       "1                 3           4         0.00  0.004378\n",
       "17                3           4         0.01  0.004835"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list quantile scores\n",
    "flatlist = [list(l[0]) + [l[1]] for l in quantile_scores.items()]\n",
    " \n",
    "qframe = pd.DataFrame(flatlist, columns=[\"n_hidden_layers\", \"layer_size\", \"reg_penalty\", \"qscore\"])\n",
    "# one row didn't converge properly - messes up plotly scales\n",
    "#for i in list(lossframe.loc[lossframe['loss']> 1000].index):\n",
    "#    lossframe.at[i, 'loss'] = 100\n",
    "#list(l) +\n",
    "qframe.sort_values(['qscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27,)\n",
      "(27,)\n",
      "(27,)\n"
     ]
    }
   ],
   "source": [
    "sharpes_array = sharpeframe.values[:,3]\n",
    "print(sharpes_array.shape)\n",
    "mses_array = lossframe.values[:,3]\n",
    "print(mses_array.shape)\n",
    "qscore_array = qframe.values[:,3]\n",
    "print(qscore_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.005025745143172034,
          0.057526074705898794,
          -0.11375295536117326,
          -0.036520925082363334,
          -0.1228548747228826,
          -0.22689550206212605,
          0.25769732123616523,
          0.30803356168419066,
          0.13727336672465898,
          0.03867401756114749,
          0.2734584023598271,
          -0.03345340985581407,
          -0.12286210737147539,
          0.16310205023355612,
          -0.0467053467635583,
          -0.10915609837698681,
          -0.12013243815776879,
          0.23650376328541842,
          -0.12013243815776896,
          -0.12941382530253323,
          -0.11165630158999516,
          -0.020002590961241407,
          0.07530916010496518,
          -0.11165630158999516,
          -0.08738020407533659,
          -0.12400390266164485,
          0.014342332524163257
         ],
         "y": [
          1.0172504852515203,
          1.0052752849209172,
          0.9995708312284066,
          1.0014241083160873,
          0.9993827858826019,
          1.0157384795641562,
          1.004895380497925,
          1.0302552633159998,
          1.005218113888147,
          1.0270843044978717,
          1.0058678709691569,
          1.021697578808349,
          0.9993524732478707,
          1.0032687264064364,
          1.0062821916916558,
          0.999535162355076,
          0.9993694178275637,
          1.002439524717799,
          0.9995470606955118,
          0.9996347873506026,
          0.9994632881956118,
          1.010594454186756,
          1.0045890094909071,
          0.9994573978748458,
          0.9995622627800609,
          1.0033463655139154,
          1.0016772059664205
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 480,
        "width": 600,
        "yaxis": {
         "autorange": true,
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div id=\"8731ca8a-361a-4f23-bd2b-582e5c5fae4b\" style=\"height: 480px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8731ca8a-361a-4f23-bd2b-582e5c5fae4b\", [{\"y\": [1.0172504852515203, 1.0052752849209172, 0.9995708312284066, 1.0014241083160873, 0.9993827858826019, 1.0157384795641562, 1.004895380497925, 1.0302552633159998, 1.005218113888147, 1.0270843044978717, 1.0058678709691569, 1.021697578808349, 0.9993524732478707, 1.0032687264064364, 1.0062821916916558, 0.999535162355076, 0.9993694178275637, 1.002439524717799, 0.9995470606955118, 0.9996347873506026, 0.9994632881956118, 1.010594454186756, 1.0045890094909071, 0.9994573978748458, 0.9995622627800609, 1.0033463655139154, 1.0016772059664205], \"x\": [0.005025745143172034, 0.057526074705898794, -0.11375295536117326, -0.036520925082363334, -0.1228548747228826, -0.22689550206212605, 0.25769732123616523, 0.30803356168419066, 0.13727336672465898, 0.03867401756114749, 0.2734584023598271, -0.03345340985581407, -0.12286210737147539, 0.16310205023355612, -0.0467053467635583, -0.10915609837698681, -0.12013243815776879, 0.23650376328541842, -0.12013243815776896, -0.12941382530253323, -0.11165630158999516, -0.020002590961241407, 0.07530916010496518, -0.11165630158999516, -0.08738020407533659, -0.12400390266164485, 0.014342332524163257], \"type\": \"scatter\", \"mode\": \"markers\"}], {\"width\": 600, \"autosize\": false, \"height\": 480, \"yaxis\": {\"type\": \"log\", \"autorange\": true}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"8731ca8a-361a-4f23-bd2b-582e5c5fae4b\" style=\"height: 480px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"8731ca8a-361a-4f23-bd2b-582e5c5fae4b\", [{\"y\": [1.0172504852515203, 1.0052752849209172, 0.9995708312284066, 1.0014241083160873, 0.9993827858826019, 1.0157384795641562, 1.004895380497925, 1.0302552633159998, 1.005218113888147, 1.0270843044978717, 1.0058678709691569, 1.021697578808349, 0.9993524732478707, 1.0032687264064364, 1.0062821916916558, 0.999535162355076, 0.9993694178275637, 1.002439524717799, 0.9995470606955118, 0.9996347873506026, 0.9994632881956118, 1.010594454186756, 1.0045890094909071, 0.9994573978748458, 0.9995622627800609, 1.0033463655139154, 1.0016772059664205], \"x\": [0.005025745143172034, 0.057526074705898794, -0.11375295536117326, -0.036520925082363334, -0.1228548747228826, -0.22689550206212605, 0.25769732123616523, 0.30803356168419066, 0.13727336672465898, 0.03867401756114749, 0.2734584023598271, -0.03345340985581407, -0.12286210737147539, 0.16310205023355612, -0.0467053467635583, -0.10915609837698681, -0.12013243815776879, 0.23650376328541842, -0.12013243815776896, -0.12941382530253323, -0.11165630158999516, -0.020002590961241407, 0.07530916010496518, -0.11165630158999516, -0.08738020407533659, -0.12400390266164485, 0.014342332524163257], \"type\": \"scatter\", \"mode\": \"markers\"}], {\"width\": 600, \"autosize\": false, \"height\": 480, \"yaxis\": {\"type\": \"log\", \"autorange\": true}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def myscatter(arg1, arg2, names=None):\n",
    "    \n",
    "    plotdata = []\n",
    "    \n",
    "    plotdata.append(Scatter(\n",
    "        x = arg1,\n",
    "        y = arg2,\n",
    "        mode = 'markers'\n",
    "    ))\n",
    "    \n",
    "    layout = Layout(\n",
    "        autosize=False,\n",
    "        width=600,\n",
    "        height=480,\n",
    "        yaxis=dict(\n",
    "            type='log',\n",
    "            autorange=True\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig = Figure(data=plotdata, layout=layout)\n",
    "    \n",
    "    return iplot(fig)\n",
    "    \n",
    "myscatter(sharpes_array, mses_array)\n",
    "# MSEs worse than linear regression\n",
    "# no very good Sharpes\n",
    "# weak correlation between MSEs, Sharpes, which is perplexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "markers",
         "type": "scatter",
         "x": [
          0.005025745143172034,
          0.057526074705898794,
          -0.11375295536117326,
          -0.036520925082363334,
          -0.1228548747228826,
          -0.22689550206212605,
          0.25769732123616523,
          0.30803356168419066,
          0.13727336672465898,
          0.03867401756114749,
          0.2734584023598271,
          -0.03345340985581407,
          -0.12286210737147539,
          0.16310205023355612,
          -0.0467053467635583,
          -0.10915609837698681,
          -0.12013243815776879,
          0.23650376328541842,
          -0.12013243815776896,
          -0.12941382530253323,
          -0.11165630158999516,
          -0.020002590961241407,
          0.07530916010496518,
          -0.11165630158999516,
          -0.08738020407533659,
          -0.12400390266164485,
          0.014342332524163257
         ],
         "y": [
          0.003647166361974383,
          0.004378427787934177,
          0.00041742839731871186,
          0.0015143205362583758,
          0.00014320536258377592,
          0.0016057282145033342,
          0.004287020109689215,
          0.004012797074954307,
          0.003951858622790964,
          0.0034643510054844333,
          0.003068251066422922,
          0.003098720292504565,
          0.0006916514320536218,
          0.003159658744667882,
          0.0005697745277269892,
          0.0011791590493601505,
          0.0010877513711151608,
          0.004835466179159063,
          0.0010877513711151608,
          0.0013619744058500707,
          0.0012096282754417934,
          0.00096587446678853,
          0.0023979280926264453,
          0.0012096282754417934,
          0.0009354052407068852,
          -3.9609993906144364e-05,
          0.0008439975624619251
         ]
        }
       ],
       "layout": {
        "autosize": false,
        "height": 480,
        "width": 600,
        "yaxis": {
         "autorange": true,
         "type": "log"
        }
       }
      },
      "text/html": [
       "<div id=\"6a685e25-ed91-4390-8fcf-7692a90d10b9\" style=\"height: 480px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"6a685e25-ed91-4390-8fcf-7692a90d10b9\", [{\"y\": [0.003647166361974383, 0.004378427787934177, 0.00041742839731871186, 0.0015143205362583758, 0.00014320536258377592, 0.0016057282145033342, 0.004287020109689215, 0.004012797074954307, 0.003951858622790964, 0.0034643510054844333, 0.003068251066422922, 0.003098720292504565, 0.0006916514320536218, 0.003159658744667882, 0.0005697745277269892, 0.0011791590493601505, 0.0010877513711151608, 0.004835466179159063, 0.0010877513711151608, 0.0013619744058500707, 0.0012096282754417934, 0.00096587446678853, 0.0023979280926264453, 0.0012096282754417934, 0.0009354052407068852, -3.9609993906144364e-05, 0.0008439975624619251], \"x\": [0.005025745143172034, 0.057526074705898794, -0.11375295536117326, -0.036520925082363334, -0.1228548747228826, -0.22689550206212605, 0.25769732123616523, 0.30803356168419066, 0.13727336672465898, 0.03867401756114749, 0.2734584023598271, -0.03345340985581407, -0.12286210737147539, 0.16310205023355612, -0.0467053467635583, -0.10915609837698681, -0.12013243815776879, 0.23650376328541842, -0.12013243815776896, -0.12941382530253323, -0.11165630158999516, -0.020002590961241407, 0.07530916010496518, -0.11165630158999516, -0.08738020407533659, -0.12400390266164485, 0.014342332524163257], \"type\": \"scatter\", \"mode\": \"markers\"}], {\"width\": 600, \"autosize\": false, \"height\": 480, \"yaxis\": {\"type\": \"log\", \"autorange\": true}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"6a685e25-ed91-4390-8fcf-7692a90d10b9\" style=\"height: 480px; width: 600px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"6a685e25-ed91-4390-8fcf-7692a90d10b9\", [{\"y\": [0.003647166361974383, 0.004378427787934177, 0.00041742839731871186, 0.0015143205362583758, 0.00014320536258377592, 0.0016057282145033342, 0.004287020109689215, 0.004012797074954307, 0.003951858622790964, 0.0034643510054844333, 0.003068251066422922, 0.003098720292504565, 0.0006916514320536218, 0.003159658744667882, 0.0005697745277269892, 0.0011791590493601505, 0.0010877513711151608, 0.004835466179159063, 0.0010877513711151608, 0.0013619744058500707, 0.0012096282754417934, 0.00096587446678853, 0.0023979280926264453, 0.0012096282754417934, 0.0009354052407068852, -3.9609993906144364e-05, 0.0008439975624619251], \"x\": [0.005025745143172034, 0.057526074705898794, -0.11375295536117326, -0.036520925082363334, -0.1228548747228826, -0.22689550206212605, 0.25769732123616523, 0.30803356168419066, 0.13727336672465898, 0.03867401756114749, 0.2734584023598271, -0.03345340985581407, -0.12286210737147539, 0.16310205023355612, -0.0467053467635583, -0.10915609837698681, -0.12013243815776879, 0.23650376328541842, -0.12013243815776896, -0.12941382530253323, -0.11165630158999516, -0.020002590961241407, 0.07530916010496518, -0.11165630158999516, -0.08738020407533659, -0.12400390266164485, 0.014342332524163257], \"type\": \"scatter\", \"mode\": \"markers\"}], {\"width\": 600, \"autosize\": false, \"height\": 480, \"yaxis\": {\"type\": \"log\", \"autorange\": true}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myscatter(sharpes_array, qscore_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hidden_layers</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   qscore\n",
       "n_hidden_layers          \n",
       "1                0.002449\n",
       "2                0.001833\n",
       "3                0.001839"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can pick lowest loss , but first we look at patterns by hyperparameter\n",
    "pd.DataFrame(qframe.groupby(['n_hidden_layers'])['qscore'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_size</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              qscore\n",
       "layer_size          \n",
       "1           0.001172\n",
       "2           0.001711\n",
       "4           0.003238"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(qframe.groupby(['layer_size'])['qscore'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qscore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_penalty</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.002320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               qscore\n",
       "reg_penalty          \n",
       "0.00         0.002320\n",
       "0.01         0.002323\n",
       "1.00         0.001477"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(qframe.groupby(['reg_penalty'])['qscore'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(0,0,255)",
           [
            1,
            "rgb(255,0,0)"
           ]
          ]
         ],
         "type": "heatmap",
         "x": [
          "1  layers",
          "2  layers",
          "3  layers"
         ],
         "y": [
          "1  units",
          "2  units",
          "4  units"
         ],
         "z": [
          [
           0.0009150924233191042,
           0.0013924436319317519,
           0.001209628275441794
          ],
          [
           0.002621369083891927,
           0.0014127564493195237,
           0.0010979077798090528
          ],
          [
           0.003809668901076568,
           0.002692463944749125,
           0.0032104407881373173
          ]
         ]
        }
       ],
       "layout": {
        "height": 480,
        "margin": {
         "b": 120,
         "l": 150,
         "r": 30,
         "t": 100
        },
        "title": "n_hidden_layers v. layer_size",
        "width": 640,
        "xaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "n_hidden_layers"
        },
        "yaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "layer_size"
        }
       }
      },
      "text/html": [
       "<div id=\"b51c6353-19dd-48e4-a6bb-dd7e075c5966\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b51c6353-19dd-48e4-a6bb-dd7e075c5966\", [{\"y\": [\"1  units\", \"2  units\", \"4  units\"], \"x\": [\"1  layers\", \"2  layers\", \"3  layers\"], \"z\": [[0.0009150924233191042, 0.0013924436319317519, 0.001209628275441794], [0.002621369083891927, 0.0014127564493195237, 0.0010979077798090528], [0.003809668901076568, 0.002692463944749125, 0.0032104407881373173]], \"type\": \"heatmap\", \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"n_hidden_layers v. layer_size\", \"yaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"layer_size\"}, \"height\": 480, \"width\": 640, \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"n_hidden_layers\"}, \"margin\": {\"r\": 30, \"b\": 120, \"t\": 100, \"l\": 150}}, {\"linkText\": \"\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"b51c6353-19dd-48e4-a6bb-dd7e075c5966\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"b51c6353-19dd-48e4-a6bb-dd7e075c5966\", [{\"y\": [\"1  units\", \"2  units\", \"4  units\"], \"x\": [\"1  layers\", \"2  layers\", \"3  layers\"], \"z\": [[0.0009150924233191042, 0.0013924436319317519, 0.001209628275441794], [0.002621369083891927, 0.0014127564493195237, 0.0010979077798090528], [0.003809668901076568, 0.002692463944749125, 0.0032104407881373173]], \"type\": \"heatmap\", \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"n_hidden_layers v. layer_size\", \"yaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"layer_size\"}, \"height\": 480, \"width\": 640, \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"n_hidden_layers\"}, \"margin\": {\"r\": 30, \"b\": 120, \"t\": 100, \"l\": 150}}, {\"linkText\": \"\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_matrix(lossframe, x_labels, y_labels, x_suffix=\"\", y_suffix=\"\"):\n",
    "\n",
    "    pivot = lossframe.pivot_table(index=[y_labels], columns=[x_labels], values=['qscore'])\n",
    "#    print(pivot)\n",
    "    # specify labels as strings, to force plotly to use a discrete axis\n",
    "#    print(pivot.columns.levels[1]).values\n",
    "#    print(lossframe[x_labels].dtype)\n",
    "    \n",
    "    if lossframe[x_labels].dtype == np.float64 or lossframe[x_labels].dtype == np.float32:\n",
    "        xaxis = [\"%f %s\" % (i, x_suffix) for i in pivot.columns.levels[1].values]\n",
    "    else:\n",
    "        xaxis = [\"%d %s\" % (i, x_suffix) for i in pivot.columns.levels[1].values]\n",
    "    if lossframe[y_labels].dtype == np.float64 or lossframe[y_labels].dtype == np.float32:\n",
    "        yaxis = [\"%f %s\" % (i, y_suffix) for i in pivot.index.values]\n",
    "    else:\n",
    "        yaxis = [\"%d %s\" % (i, y_suffix) for i in pivot.index.values]\n",
    "        \n",
    "#    print(xaxis, yaxis)\n",
    "    \"\"\"plot a heat map of a matrix\"\"\"\n",
    "    chart_width=640\n",
    "    chart_height=480\n",
    "    \n",
    "    layout = Layout(\n",
    "        title=\"%s v. %s\" % (x_labels, y_labels),\n",
    "        height=chart_height,\n",
    "        width=chart_width,     \n",
    "        margin=dict(\n",
    "            l=150,\n",
    "            r=30,\n",
    "            b=120,\n",
    "            t=100,\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title=x_labels,\n",
    "            tickfont=dict(\n",
    "                family='Arial, sans-serif',\n",
    "                size=10,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=y_labels,\n",
    "            tickfont=dict(\n",
    "                family='Arial, sans-serif',\n",
    "                size=10,\n",
    "                color='black'\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    data = [Heatmap(z=pivot.values,\n",
    "                    x=xaxis,\n",
    "                    y=yaxis,\n",
    "                    colorscale=[[0, 'rgb(0,0,255)', [1, 'rgb(255,0,0)']]],\n",
    "                   )\n",
    "           ]\n",
    "\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    return iplot(fig, link_text=\"\")\n",
    "\n",
    "plot_matrix(qframe, \"n_hidden_layers\", \"layer_size\", x_suffix=\" layers\", y_suffix=\" units\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(0,0,255)",
           [
            1,
            "rgb(255,0,0)"
           ]
          ]
         ],
         "type": "heatmap",
         "x": [
          "1  layers",
          "2  layers",
          "3  layers"
         ],
         "y": [
          "0.000000  p",
          "0.010000  p",
          "1.000000  p"
         ],
         "z": [
          [
           0.002692463944749134,
           0.0022151127361365055,
           0.0020526101970343197
          ],
          [
           0.0018799512492382521,
           0.0025198049969530766,
           0.002570587040422503
          ],
          [
           0.002773715214300213,
           0.0007627462929108182,
           0.0008947796059313411
          ]
         ]
        }
       ],
       "layout": {
        "height": 480,
        "margin": {
         "b": 120,
         "l": 150,
         "r": 30,
         "t": 100
        },
        "title": "n_hidden_layers v. reg_penalty",
        "width": 640,
        "xaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "n_hidden_layers"
        },
        "yaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "reg_penalty"
        }
       }
      },
      "text/html": [
       "<div id=\"79b87c11-3555-493d-8d7d-7afa46650d43\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"79b87c11-3555-493d-8d7d-7afa46650d43\", [{\"y\": [\"0.000000  p\", \"0.010000  p\", \"1.000000  p\"], \"x\": [\"1  layers\", \"2  layers\", \"3  layers\"], \"z\": [[0.002692463944749134, 0.0022151127361365055, 0.0020526101970343197], [0.0018799512492382521, 0.0025198049969530766, 0.002570587040422503], [0.002773715214300213, 0.0007627462929108182, 0.0008947796059313411]], \"type\": \"heatmap\", \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"n_hidden_layers v. reg_penalty\", \"yaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"reg_penalty\"}, \"height\": 480, \"width\": 640, \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"n_hidden_layers\"}, \"margin\": {\"r\": 30, \"b\": 120, \"t\": 100, \"l\": 150}}, {\"linkText\": \"\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"79b87c11-3555-493d-8d7d-7afa46650d43\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"79b87c11-3555-493d-8d7d-7afa46650d43\", [{\"y\": [\"0.000000  p\", \"0.010000  p\", \"1.000000  p\"], \"x\": [\"1  layers\", \"2  layers\", \"3  layers\"], \"z\": [[0.002692463944749134, 0.0022151127361365055, 0.0020526101970343197], [0.0018799512492382521, 0.0025198049969530766, 0.002570587040422503], [0.002773715214300213, 0.0007627462929108182, 0.0008947796059313411]], \"type\": \"heatmap\", \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"n_hidden_layers v. reg_penalty\", \"yaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"reg_penalty\"}, \"height\": 480, \"width\": 640, \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"n_hidden_layers\"}, \"margin\": {\"r\": 30, \"b\": 120, \"t\": 100, \"l\": 150}}, {\"linkText\": \"\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_matrix(qframe, \"n_hidden_layers\", \"reg_penalty\", x_suffix=\" layers\", y_suffix=\" p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(0,0,255)",
           [
            1,
            "rgb(255,0,0)"
           ]
          ]
         ],
         "type": "heatmap",
         "x": [
          "0.000000  p",
          "0.010000  p",
          "1.000000  p"
         ],
         "y": [
          "1 units",
          "2 units",
          "4 units"
         ],
         "z": [
          [
           0.001483851310176712,
           0.000925248832012995,
           0.001108064188502943
          ],
          [
           0.0012502539102173475,
           0.002062766605728211,
           0.0018190127970749454
          ],
          [
           0.0042260816575259,
           0.003982327848872627,
           0.0015041641275644838
          ]
         ]
        }
       ],
       "layout": {
        "height": 480,
        "margin": {
         "b": 120,
         "l": 150,
         "r": 30,
         "t": 100
        },
        "title": "reg_penalty v. layer_size",
        "width": 640,
        "xaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "reg_penalty"
        },
        "yaxis": {
         "tickfont": {
          "color": "black",
          "family": "Arial, sans-serif",
          "size": 10
         },
         "title": "layer_size"
        }
       }
      },
      "text/html": [
       "<div id=\"559f1afc-e484-4738-b07a-03d11bc8fe46\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"559f1afc-e484-4738-b07a-03d11bc8fe46\", [{\"y\": [\"1 units\", \"2 units\", \"4 units\"], \"x\": [\"0.000000  p\", \"0.010000  p\", \"1.000000  p\"], \"z\": [[0.001483851310176712, 0.000925248832012995, 0.001108064188502943], [0.0012502539102173475, 0.002062766605728211, 0.0018190127970749454], [0.0042260816575259, 0.003982327848872627, 0.0015041641275644838]], \"type\": \"heatmap\", \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"reg_penalty v. layer_size\", \"yaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"layer_size\"}, \"height\": 480, \"width\": 640, \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"reg_penalty\"}, \"margin\": {\"r\": 30, \"b\": 120, \"t\": 100, \"l\": 150}}, {\"linkText\": \"\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"559f1afc-e484-4738-b07a-03d11bc8fe46\" style=\"height: 480px; width: 640px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"559f1afc-e484-4738-b07a-03d11bc8fe46\", [{\"y\": [\"1 units\", \"2 units\", \"4 units\"], \"x\": [\"0.000000  p\", \"0.010000  p\", \"1.000000  p\"], \"z\": [[0.001483851310176712, 0.000925248832012995, 0.001108064188502943], [0.0012502539102173475, 0.002062766605728211, 0.0018190127970749454], [0.0042260816575259, 0.003982327848872627, 0.0015041641275644838]], \"type\": \"heatmap\", \"colorscale\": [[0, \"rgb(0,0,255)\", [1, \"rgb(255,0,0)\"]]]}], {\"title\": \"reg_penalty v. layer_size\", \"yaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"layer_size\"}, \"height\": 480, \"width\": 640, \"xaxis\": {\"tickfont\": {\"color\": \"black\", \"family\": \"Arial, sans-serif\", \"size\": 10}, \"title\": \"reg_penalty\"}, \"margin\": {\"r\": 30, \"b\": 120, \"t\": 100, \"l\": 150}}, {\"linkText\": \"\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_matrix(qframe, \"reg_penalty\", \"layer_size\", x_suffix=\" p\", y_suffix=\"units\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 9s 74ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "122/122 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "123/123 [==============================] - 0s 573us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "124/124 [==============================] - 0s 583us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "125/125 [==============================] - 0s 539us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "126/126 [==============================] - 0s 557us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "127/127 [==============================] - 0s 553us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "128/128 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "129/129 [==============================] - 0s 650us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "130/130 [==============================] - 0s 624us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "131/131 [==============================] - 0s 602us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "132/132 [==============================] - 0s 666us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "133/133 [==============================] - 0s 674us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "134/134 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "135/135 [==============================] - 0s 668us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "136/136 [==============================] - 0s 620us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "137/137 [==============================] - 0s 588us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "138/138 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "139/139 [==============================] - 0s 630us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "140/140 [==============================] - 0s 573us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "141/141 [==============================] - 0s 640us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "142/142 [==============================] - 0s 617us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "143/143 [==============================] - 0s 566us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "144/144 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "145/145 [==============================] - 0s 553us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "146/146 [==============================] - 0s 552us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "147/147 [==============================] - 0s 545us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "148/148 [==============================] - 0s 590us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "149/149 [==============================] - 0s 593us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "150/150 [==============================] - 0s 531us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "151/151 [==============================] - 0s 543us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "152/152 [==============================] - 0s 529us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "153/153 [==============================] - 0s 540us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "154/154 [==============================] - 0s 552us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "155/155 [==============================] - 0s 568us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "156/156 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "157/157 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "158/158 [==============================] - 0s 587us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "159/159 [==============================] - 0s 548us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "160/160 [==============================] - 0s 485us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "161/161 [==============================] - 0s 625us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "162/162 [==============================] - 0s 626us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "163/163 [==============================] - 0s 625us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "164/164 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "165/165 [==============================] - 0s 657us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "166/166 [==============================] - 0s 577us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "167/167 [==============================] - 0s 641us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "168/168 [==============================] - 0s 654us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "169/169 [==============================] - 0s 677us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "170/170 [==============================] - 0s 587us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "171/171 [==============================] - 0s 564us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "172/172 [==============================] - 0s 565us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "173/173 [==============================] - 0s 581us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "174/174 [==============================] - 0s 596us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "175/175 [==============================] - 0s 599us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "176/176 [==============================] - 0s 539us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "177/177 [==============================] - 0s 609us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "178/178 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "179/179 [==============================] - 0s 577us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "180/180 [==============================] - 0s 565us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "181/181 [==============================] - 0s 533us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "182/182 [==============================] - 0s 559us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "183/183 [==============================] - 0s 564us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "184/184 [==============================] - 0s 545us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "185/185 [==============================] - 0s 538us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "186/186 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "187/187 [==============================] - 0s 572us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "188/188 [==============================] - 0s 542us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "189/189 [==============================] - 0s 532us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "190/190 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "191/191 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "192/192 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "193/193 [==============================] - 0s 658us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "194/194 [==============================] - 0s 611us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "195/195 [==============================] - 0s 599us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "197/197 [==============================] - 0s 600us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "198/198 [==============================] - 0s 565us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "199/199 [==============================] - 0s 569us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "200/200 [==============================] - 0s 603us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      ".\n",
      "04:34:13 Still training step 80 of 563\n",
      "201/201 [==============================] - 0s 571us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "202/202 [==============================] - 0s 586us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "203/203 [==============================] - 0s 551us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "204/204 [==============================] - 0s 556us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "205/205 [==============================] - 0s 550us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "206/206 [==============================] - 0s 620us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "207/207 [==============================] - 0s 573us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "208/208 [==============================] - 0s 626us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "209/209 [==============================] - 0s 550us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "210/210 [==============================] - 0s 548us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "211/211 [==============================] - 0s 637us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "212/212 [==============================] - 0s 544us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "213/213 [==============================] - 0s 531us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "214/214 [==============================] - 0s 556us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "215/215 [==============================] - 0s 596us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "216/216 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "217/217 [==============================] - 0s 586us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "218/218 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "219/219 [==============================] - 0s 528us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "220/220 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "221/221 [==============================] - 0s 578us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "222/222 [==============================] - 0s 560us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "223/223 [==============================] - 0s 554us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "224/224 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "225/225 [==============================] - 0s 580us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "226/226 [==============================] - 0s 670us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "227/227 [==============================] - 0s 657us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "228/228 [==============================] - 0s 655us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "229/229 [==============================] - 0s 553us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "230/230 [==============================] - 0s 615us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "231/231 [==============================] - 0s 554us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "232/232 [==============================] - 0s 632us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "233/233 [==============================] - 0s 570us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "234/234 [==============================] - 0s 595us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "235/235 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "236/236 [==============================] - 0s 609us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "237/237 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "238/238 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "239/239 [==============================] - 0s 541us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "240/240 [==============================] - 0s 611us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "241/241 [==============================] - 0s 606us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "242/242 [==============================] - 0s 598us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "243/243 [==============================] - 0s 534us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "244/244 [==============================] - 0s 617us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "245/245 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "246/246 [==============================] - 0s 538us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "247/247 [==============================] - 0s 522us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "248/248 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "249/249 [==============================] - 0s 531us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "250/250 [==============================] - 0s 598us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "251/251 [==============================] - 0s 522us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "252/252 [==============================] - 0s 523us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "253/253 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "254/254 [==============================] - 0s 571us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "255/255 [==============================] - 0s 535us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "256/256 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "257/257 [==============================] - 0s 565us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "258/258 [==============================] - 0s 613us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "259/259 [==============================] - 0s 552us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "260/260 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "261/261 [==============================] - 0s 613us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "262/262 [==============================] - 0s 541us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "263/263 [==============================] - 0s 657us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "264/264 [==============================] - 0s 559us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "265/265 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "266/266 [==============================] - 0s 639us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "267/267 [==============================] - 0s 519us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "268/268 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "269/269 [==============================] - 0s 540us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "270/270 [==============================] - 0s 539us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/271 [==============================] - 0s 572us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "272/272 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "273/273 [==============================] - 0s 590us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "274/274 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "275/275 [==============================] - 0s 588us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "276/276 [==============================] - 0s 591us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "277/277 [==============================] - 0s 547us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "278/278 [==============================] - 0s 568us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "279/279 [==============================] - 0s 591us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "280/280 [==============================] - 0s 573us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ".\n",
      "09:39:41 Still training step 160 of 563\n",
      "281/281 [==============================] - 0s 549us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "282/282 [==============================] - 0s 567us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "283/283 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "284/284 [==============================] - 0s 556us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "285/285 [==============================] - 0s 595us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "286/286 [==============================] - 0s 548us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "287/287 [==============================] - 0s 564us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "288/288 [==============================] - 0s 548us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "289/289 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "290/290 [==============================] - 0s 564us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "291/291 [==============================] - 0s 562us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "292/292 [==============================] - 0s 544us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "293/293 [==============================] - 0s 550us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "294/294 [==============================] - 0s 542us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "295/295 [==============================] - 0s 563us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "296/296 [==============================] - 0s 569us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "297/297 [==============================] - 0s 551us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "298/298 [==============================] - 0s 598us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "299/299 [==============================] - 0s 525us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "300/300 [==============================] - 0s 609us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "301/301 [==============================] - 0s 528us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "302/302 [==============================] - 0s 539us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "303/303 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "304/304 [==============================] - 0s 529us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "305/305 [==============================] - 0s 526us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "306/306 [==============================] - 0s 532us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "307/307 [==============================] - 0s 546us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "308/308 [==============================] - 0s 555us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "309/309 [==============================] - 0s 547us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "310/310 [==============================] - 0s 525us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "311/311 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "312/312 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "313/313 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "314/314 [==============================] - 0s 534us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "315/315 [==============================] - 0s 572us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "316/316 [==============================] - 0s 530us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "317/317 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "318/318 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "319/319 [==============================] - 0s 564us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "320/320 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "321/321 [==============================] - 0s 621us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "322/322 [==============================] - 0s 569us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "323/323 [==============================] - 0s 601us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "324/324 [==============================] - 0s 645us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "325/325 [==============================] - 0s 550us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "326/326 [==============================] - 0s 544us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "327/327 [==============================] - 0s 575us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "328/328 [==============================] - 0s 541us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "329/329 [==============================] - 0s 531us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "330/330 [==============================] - 0s 555us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "331/331 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "332/332 [==============================] - 0s 536us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "333/333 [==============================] - 0s 541us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "334/334 [==============================] - 0s 550us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "335/335 [==============================] - 0s 548us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "336/336 [==============================] - 0s 581us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "337/337 [==============================] - 0s 533us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "338/338 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "339/339 [==============================] - 0s 530us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "340/340 [==============================] - 0s 543us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "341/341 [==============================] - 0s 586us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "342/342 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "343/343 [==============================] - 0s 542us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "344/344 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "345/345 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "347/347 [==============================] - 0s 548us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "348/348 [==============================] - 0s 538us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "349/349 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "350/350 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "351/351 [==============================] - 0s 519us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "352/352 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "353/353 [==============================] - 0s 619us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "354/354 [==============================] - 0s 568us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "355/355 [==============================] - 0s 575us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "356/356 [==============================] - 0s 579us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "357/357 [==============================] - 0s 577us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "358/358 [==============================] - 0s 540us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "359/359 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "360/360 [==============================] - 0s 541us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ".\n",
      "16:17:53 Still training step 240 of 563\n",
      "361/361 [==============================] - 0s 585us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "362/362 [==============================] - 0s 540us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "363/363 [==============================] - 0s 533us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "364/364 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "365/365 [==============================] - 0s 546us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "366/366 [==============================] - 0s 547us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "367/367 [==============================] - 0s 556us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "368/368 [==============================] - 0s 583us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "369/369 [==============================] - 0s 601us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "370/370 [==============================] - 0s 605us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "371/371 [==============================] - 0s 522us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "372/372 [==============================] - 0s 515us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "373/373 [==============================] - 0s 532us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "374/374 [==============================] - 0s 525us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "375/375 [==============================] - 0s 589us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "376/376 [==============================] - 0s 552us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "377/377 [==============================] - 0s 550us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "378/378 [==============================] - 0s 546us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "379/379 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "380/380 [==============================] - 0s 544us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "381/381 [==============================] - 0s 581us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "382/382 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "383/383 [==============================] - 0s 501us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "384/384 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "385/385 [==============================] - 0s 561us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "386/386 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "387/387 [==============================] - 0s 579us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "388/388 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "389/389 [==============================] - 0s 540us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "390/390 [==============================] - 0s 608us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "391/391 [==============================] - 0s 526us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "392/392 [==============================] - 0s 535us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "393/393 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "394/394 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "395/395 [==============================] - 0s 565us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "396/396 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "397/397 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "398/398 [==============================] - 0s 526us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "399/399 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "400/400 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "401/401 [==============================] - 0s 567us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "402/402 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "403/403 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "404/404 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "405/405 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "406/406 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "407/407 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "408/408 [==============================] - 0s 501us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "409/409 [==============================] - 0s 494us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "410/410 [==============================] - 0s 496us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "411/411 [==============================] - 0s 498us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "412/412 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "413/413 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "414/414 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "415/415 [==============================] - 0s 585us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "416/416 [==============================] - 0s 497us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "417/417 [==============================] - 0s 536us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "418/418 [==============================] - 0s 530us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "419/419 [==============================] - 0s 532us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "420/420 [==============================] - 0s 526us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 0s 535us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "422/422 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "423/423 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "424/424 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "425/425 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "426/426 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "427/427 [==============================] - 0s 516us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "428/428 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "429/429 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "430/430 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "431/431 [==============================] - 0s 525us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "432/432 [==============================] - 0s 542us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "433/433 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "434/434 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "435/435 [==============================] - 0s 553us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "436/436 [==============================] - 0s 526us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "437/437 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "438/438 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "439/439 [==============================] - 0s 528us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "440/440 [==============================] - 0s 493us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ".\n",
      "00:22:37 Still training step 320 of 563\n",
      "441/441 [==============================] - 0s 528us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "442/442 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "443/443 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "444/444 [==============================] - 0s 498us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "445/445 [==============================] - 0s 542us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "446/446 [==============================] - 0s 567us/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "447/447 [==============================] - 0s 501us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "448/448 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "449/449 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "450/450 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "451/451 [==============================] - 0s 525us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "452/452 [==============================] - 0s 549us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "453/453 [==============================] - 0s 519us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "454/454 [==============================] - 0s 528us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "455/455 [==============================] - 0s 582us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "456/456 [==============================] - 0s 530us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "457/457 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "458/458 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "459/459 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "460/460 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "461/461 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "462/462 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "463/463 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "464/464 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "465/465 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "466/466 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "467/467 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "468/468 [==============================] - 0s 534us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "469/469 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "470/470 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "471/471 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "472/472 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "473/473 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "474/474 [==============================] - 0s 516us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "475/475 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "476/476 [==============================] - 0s 491us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "477/477 [==============================] - 0s 493us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "478/478 [==============================] - 0s 488us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "479/479 [==============================] - 0s 491us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "480/480 [==============================] - 0s 492us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "481/481 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "482/482 [==============================] - 0s 530us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "483/483 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "484/484 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "485/485 [==============================] - 0s 516us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "486/486 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "487/487 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "488/488 [==============================] - 0s 531us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "489/489 [==============================] - 0s 542us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "490/490 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "491/491 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "492/492 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "493/493 [==============================] - 0s 519us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "494/494 [==============================] - 0s 515us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "495/495 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496/496 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "497/497 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "498/498 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "499/499 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "500/500 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "501/501 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "502/502 [==============================] - 0s 492us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "503/503 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "504/504 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "505/505 [==============================] - 0s 492us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "506/506 [==============================] - 0s 576us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "507/507 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "508/508 [==============================] - 0s 558us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "509/509 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "510/510 [==============================] - 0s 496us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "511/511 [==============================] - 0s 488us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "512/512 [==============================] - 0s 491us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "513/513 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "514/514 [==============================] - 0s 532us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "515/515 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "516/516 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "517/517 [==============================] - 0s 588us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "518/518 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "519/519 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "520/520 [==============================] - 0s 567us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      ".\n",
      "09:52:27 Still training step 400 of 563\n",
      "521/521 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "522/522 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "523/523 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "524/524 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "525/525 [==============================] - 0s 522us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "526/526 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "527/527 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "528/528 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "529/529 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "530/530 [==============================] - 0s 495us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "531/531 [==============================] - 0s 516us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "532/532 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "533/533 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "534/534 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "535/535 [==============================] - 0s 588us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "536/536 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "537/537 [==============================] - 0s 497us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "538/538 [==============================] - 0s 491us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "539/539 [==============================] - 0s 492us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "540/540 [==============================] - 0s 493us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "541/541 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "542/542 [==============================] - 0s 495us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "543/543 [==============================] - 0s 492us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "544/544 [==============================] - 0s 490us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "545/545 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "546/546 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "547/547 [==============================] - 0s 515us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "548/548 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "549/549 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "550/550 [==============================] - 0s 523us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "551/551 [==============================] - 0s 539us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "552/552 [==============================] - 0s 515us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "553/553 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "554/554 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "555/555 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "556/556 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "557/557 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "558/558 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "559/559 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "560/560 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "561/561 [==============================] - 0s 531us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "562/562 [==============================] - 0s 515us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "563/563 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "564/564 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "565/565 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "566/566 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "567/567 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "568/568 [==============================] - 0s 522us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "569/569 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "570/570 [==============================] - 0s 495us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 0s 498us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "572/572 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "573/573 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "574/574 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "575/575 [==============================] - 0s 539us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "576/576 [==============================] - 0s 495us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "577/577 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "578/578 [==============================] - 0s 530us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "579/579 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "580/580 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "581/581 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "582/582 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "583/583 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "584/584 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "585/585 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "586/586 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "587/587 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "588/588 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "589/589 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "590/590 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "591/591 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "592/592 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "593/593 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "594/594 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "595/595 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "596/596 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "597/597 [==============================] - 0s 501us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "598/598 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "599/599 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "600/600 [==============================] - 0s 495us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ".\n",
      "20:55:55 Still training step 480 of 563\n",
      "601/601 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "602/602 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "603/603 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "604/604 [==============================] - 0s 493us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "605/605 [==============================] - 0s 497us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "606/606 [==============================] - 0s 496us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "607/607 [==============================] - 0s 490us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "608/608 [==============================] - 0s 485us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "609/609 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "610/610 [==============================] - 0s 517us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "611/611 [==============================] - 0s 521us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "612/612 [==============================] - 0s 536us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "613/613 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "614/614 [==============================] - 0s 527us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "615/615 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "616/616 [==============================] - 0s 511us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "617/617 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "618/618 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "619/619 [==============================] - 0s 500us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "620/620 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "621/621 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "622/622 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "623/623 [==============================] - 0s 509us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "624/624 [==============================] - 0s 520us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "625/625 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "626/626 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "627/627 [==============================] - 0s 547us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "628/628 [==============================] - 0s 538us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "629/629 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "630/630 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "631/631 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "632/632 [==============================] - 0s 529us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "633/633 [==============================] - 0s 523us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "634/634 [==============================] - 0s 525us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "635/635 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "636/636 [==============================] - 0s 524us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "637/637 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "638/638 [==============================] - 0s 523us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "639/639 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "640/640 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "641/641 [==============================] - 0s 537us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "642/642 [==============================] - 0s 562us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "643/643 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "644/644 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "645/645 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646/646 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "647/647 [==============================] - 0s 519us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "648/648 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "649/649 [==============================] - 0s 541us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "650/650 [==============================] - 0s 505us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "651/651 [==============================] - 0s 497us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "652/652 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "653/653 [==============================] - 0s 513us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "654/654 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "655/655 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "656/656 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "657/657 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "658/658 [==============================] - 0s 507us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "659/659 [==============================] - 0s 562us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "660/660 [==============================] - 0s 498us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "661/661 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "662/662 [==============================] - 0s 487us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "663/663 [==============================] - 0s 499us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "664/664 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "665/665 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "666/666 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "667/667 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "668/668 [==============================] - 0s 554us/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "669/669 [==============================] - 0s 502us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "670/670 [==============================] - 0s 488us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "671/671 [==============================] - 0s 504us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "672/672 [==============================] - 0s 488us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "673/673 [==============================] - 0s 529us/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "674/674 [==============================] - 0s 512us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "675/675 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "676/676 [==============================] - 0s 510us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "677/677 [==============================] - 0s 515us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "678/678 [==============================] - 0s 503us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "679/679 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "680/680 [==============================] - 0s 506us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      ".\n",
      "09:37:56 Still training step 560 of 563\n",
      "681/681 [==============================] - 0s 514us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "682/682 [==============================] - 0s 508us/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "683/683 [==============================] - 0s 600us/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      ".\n",
      "MSE across all predictions: 1.0142\n",
      "Variance: 0.6400\n",
      "R-squared: -0.5847\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=array([ 7.12773507, 13.6133807 ,  8.35520095,  7.26534243, 16.90068189]), pvalue=array([0.12929003, 0.00863692, 0.07939985, 0.12251307, 0.00202074]))\n",
      "[[0.64333925 0.15666075]\n",
      " [0.15642392 0.04357608]]\n",
      "[[ 0.00333925 -0.00333925]\n",
      " [-0.00357608  0.00357608]]\n",
      "Power_divergenceResult(statistic=8.221210775606867, pvalue=0.04165447253192978)\n",
      "[[0.64185909 0.15814091]\n",
      " [0.15814091 0.04185909]]\n",
      "[[ 0.00185909 -0.00185909]\n",
      " [-0.00185909  0.00185909]]\n",
      "Power_divergenceResult(statistic=2.2802878922439316, pvalue=0.5163077383715216)\n",
      "[[0.64091178 0.15908822]\n",
      " [0.15873298 0.04126702]]\n",
      "[[ 0.00091178 -0.00091178]\n",
      " [-0.00126702  0.00126702]]\n",
      "Power_divergenceResult(statistic=0.9570196862048549, pvalue=0.8116502984876561)\n",
      "[[0.64292481 0.15707519]\n",
      " [0.15737123 0.04262877]]\n",
      "[[ 0.00292481 -0.00292481]\n",
      " [-0.00262877  0.00262877]]\n",
      "Power_divergenceResult(statistic=4.776217436352871, pvalue=0.188936392455147)\n",
      "[[0.64476021 0.15523979]\n",
      " [0.15553582 0.04446418]]\n",
      "[[ 0.00476021 -0.00476021]\n",
      " [-0.00446418  0.00446418]]\n",
      "Power_divergenceResult(statistic=13.508732978093546, pvalue=0.003656173783944084)\n",
      "Score: 0.004035\n",
      "Food: long 148 times, short 27 times, total 175 times\n",
      "Beer: long 87 times, short 39 times, total 126 times\n",
      "Smoke: long 272 times, short 55 times, total 327 times\n",
      "Games: long 267 times, short 212 times, total 479 times\n",
      "Books: long 152 times, short 49 times, total 201 times\n",
      "Hshld: long 56 times, short 129 times, total 185 times\n",
      "Clths: long 278 times, short 79 times, total 357 times\n",
      "Hlth: long 163 times, short 0 times, total 163 times\n",
      "Chems: long 0 times, short 199 times, total 199 times\n",
      "Txtls: long 98 times, short 44 times, total 142 times\n",
      "Cnstr: long 0 times, short 61 times, total 61 times\n",
      "Steel: long 5 times, short 484 times, total 489 times\n",
      "FabPr: long 1 times, short 66 times, total 67 times\n",
      "ElcEq: long 32 times, short 17 times, total 49 times\n",
      "Autos: long 56 times, short 83 times, total 139 times\n",
      "Carry: long 121 times, short 100 times, total 221 times\n",
      "Mines: long 47 times, short 34 times, total 81 times\n",
      "Coal: long 99 times, short 147 times, total 246 times\n",
      "Oil: long 253 times, short 95 times, total 348 times\n",
      "Util: long 220 times, short 242 times, total 462 times\n",
      "Telcm: long 109 times, short 302 times, total 411 times\n",
      "Servs: long 199 times, short 23 times, total 222 times\n",
      "BusEq: long 21 times, short 188 times, total 209 times\n",
      "Paper: long 2 times, short 136 times, total 138 times\n",
      "Trans: long 53 times, short 186 times, total 239 times\n",
      "Whlsl: long 296 times, short 55 times, total 351 times\n",
      "Rtail: long 32 times, short 18 times, total 50 times\n",
      "Meals: long 246 times, short 129 times, total 375 times\n",
      "Fin: long 22 times, short 27 times, total 49 times\n",
      "Other: long 37 times, short 146 times, total 183 times\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>1970-01-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>2016-11-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cagr</th>\n",
       "      <td>0.0147221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearly_vol</th>\n",
       "      <td>0.0633497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearly_sharpe</th>\n",
       "      <td>0.262254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_drawdown</th>\n",
       "      <td>-0.324603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sortino</th>\n",
       "      <td>0.126035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "start          1970-01-31 00:00:00\n",
       "end            2016-11-30 00:00:00\n",
       "cagr                     0.0147221\n",
       "yearly_vol               0.0633497\n",
       "yearly_sharpe             0.262254\n",
       "max_drawdown             -0.324603\n",
       "sortino                   0.126035"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtestmodel = BacktestModel(X, Y_class, \n",
    "                              model=create_keras_model(3,4,0.01), \n",
    "                              coef_dict_param=coef_dict_all, \n",
    "                              startindex=FIRST_TRAIN_MONTHS,\n",
    "                              fit_missing='mean')\n",
    "backtestmodel.gen_predictions(verbose=False)\n",
    "backtestmodel.evaluate_predictions()\n",
    "backtestmodel.evaluate_quantiles(chart=True, verbose=True, Y=Y)\n",
    "backtestmodel.gen_returns(calc_returns, verbose=False)\n",
    "backtestmodel.report_returns(start_date=start_date_str, freq='M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
